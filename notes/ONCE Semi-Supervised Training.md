---
title: ONCE Semi-supervised Training
tags:
  - ONCE
  - Semi-supervised
categories:
  - ç¼–ç¨‹
  - OpenMMLab
mathjax: true
abbrlink: 313cd849
---

# ONCE Semi-Supervised Training

å­¦ä¹ è§„åˆ’ï¼š

1. **dataset ç»“æ„æ•´ç†**
2. detector ç»“æ„æ•´ç†ï¼ˆalmost doneï¼‰ï¼Œæ¨¡å‹åè€Œæ˜¯æœ€å¥½ç†è§£çš„éƒ¨åˆ†
3. **semi-supervised æµç¨‹æ•´ç†ï¼ŒSESS + mean teacher**

## Dataset

### build_semi_dataset

é€šè¿‡æ•°æ®é›†é…ç½®å»ºé€  datasets, dataloaders, samplers

1. input params

   ```python
   def build_semi_dataloader(dataset_cfg, 
                             class_names,
                             batch_size,
                             dist, 
                             root_path,
                             workers,
                             logger):
   ```

2. output

   ```python
       return datasets, dataloaders, samplers
   ```

   è¿™ä¸‰ä¸ªè¿”å›çš„éƒ½æ˜¯å­—å…¸ï¼Œå­˜å‚¨å››ç§ç±»å‹çš„æ•°æ®é›† `pretrain, labeled, unlabeled, test`

   ```python
       datasets = {
           'pretrain': pretrain_dataset,
           'labeled': labeled_dataset,
           'unlabeled': unlabeled_dataset,
           'test': test_dataset
       }
       dataloaders = {
           'pretrain': pretrain_dataloader,
           'labeled': labeled_dataloader,
           'unlabeled': unlabeled_dataloader,
           'test': test_dataloader
       }
       samplers = {
           'pretrain': pretrain_sampler,
           'labeled': labeled_sampler,
           'unlabeled': unlabeled_sampler,
           'test': test_sampler
       }
   ```

3. used functions

   1. `split_once_semi_data`ï¼Œå°±æ˜¯è½½å…¥ `once_infos_***.pkl` æ–‡ä»¶ï¼Œé‡Œé¢å­˜å‚¨äº†ä¸€äº›åŸºæœ¬ä¿¡æ¯ï¼Œæ¯”å¦‚ frame_id, meta_info, lidar, pose, calib...

      ```python
      def split_once_semi_data(info_paths, data_splits, root_path, logger):
          return once_pretrain_infos, once_test_infos, once_labeled_infos, once_unlabeled_infos
      # pretrain & labeled are the same
      ```

### SemiDatasetTemplate

è¿™ä¸ªç±»æ˜¯æ‰€æœ‰ semi-dataset çš„ç¥–å…ˆï¼Œè¯¥ç±»è¦å¤„ç†ç›‘ç£æƒ…å†µä¸‹çš„æ•°æ®é›†ï¼Œä¹Ÿè¦å¤„ç†åŠç›‘ç£æƒ…å†µä¸‹çš„æ•°æ®é›†ã€‚åŒæ—¶åŠç›‘ç£æƒ…å†µä¸‹ä¹Ÿåˆ†ä¸º teacher & student ä¸¤ä¸ªç±»å‹ã€‚è€Œè¿™äº›ä»£ç ä¼¼ä¹éƒ½æ˜¯ç”¨ numpy åœ¨ cpu ä¸Šè¿è¡Œï¼Œå¯èƒ½ numpy åœ¨ cpu ä¸Šæ›´å¿«è·Ÿè½»é‡

#### init

1. input params

   ```python
   class SemiDatasetTemplate(torch_data.Dataset):
       def __init__(self, dataset_cfg=None, class_names=None, training=True, root_path=None, logger=None):
   ```

2. attributes

   ä¸€äº›åŸºç¡€çš„å±æ€§

   ```python
           self.dataset_cfg
           self.training
           self.class_names
           self.logger
           self.point_cloud_range
           self.grid_size = self.data_processor.grid_size
           self.voxel_size = self.data_processor.voxel_size
   ```

   ç”±ç±»ç»„æˆçš„å±æ€§

   ```python
   self.point_feature_encoder	# PointFeatureEncoder
   self.data_augmentor			# DataAugmentor
   self.data_processor			# DataProcessor
   
   self.teacher_augmentor		# Different augmentation for teacher & student
   self.student_augmentor
   ```

   æœ‰å¿…è¦ä»‹ç»ä¸€ä¸‹ä¸‰ä¸ªç±»çš„åŠŸèƒ½

   1. `PointFeatureEncoder` åŸºæœ¬ä¸Šä¸åšä»€ä¹ˆäº‹æƒ…ï¼Œçœ‹ä¸€çœ‹ `used_feature_list` å°±å¥½

   2. `DataAugmentor` æŠŠéœ€è¦çš„ augmentation æ”¾åˆ° `self. data_augmentor_queue` ä¹‹åè°ƒç”¨ï¼Œé€šå¸¸æœ‰ä¸‰ä¸ªæ“ä½œ

      1. random_world_flipï¼ŒALONG_AXIS_LIST: ['x', 'y']
      2. random_world_rotationï¼ŒWORLD_ROT_ANGLE: [-0.78539816, 0.78539816]
      3. random_world_scalingï¼ŒWORLD_SCALE_RANGE: [0.95, 1.05]

   3. `DataProcessor` å¤„ç†ç‚¹äº‘ï¼Œä¸€èˆ¬æœ‰ä¸‰æ­¥

      1. mask_points_and_boxes_outside_range

      2. shuffile_points

      3. transform_points_to_voxelsï¼Œè¿™ä¸€æ­¥ç”± spconv çš„ `VoxelGenerator` å®Œæˆ

         ```python
                 points = data_dict['points']
                 voxel_output = self.voxel_generator.generate(points)
                 voxels, coordinates, num_points = voxel_output
         ```

#### prepare_data

ç»™ç›‘ç£å­¦ä¹ å‡†å¤‡æ•°æ®ï¼ˆæ•°æ®å¢å¼ºï¼Œä½“ç´ åŒ–ç­‰ï¼‰

1. input params & output

   ```python
       def prepare_data(self, data_dict):
           """
           Args:
               data_dict:
                   points: (N, 3 + C_in)
                   gt_boxes: optional, (N, 7 + C) [x, y, z, dx, dy, dz, heading, ...]
                   gt_names: optional, (N), string
                   ...
           Returns:
               data_dict:
                   points: (N, 3 + C_in)
                   gt_boxes: optional, (N, 7 + C + 1) [x, y, z, dx, dy, dz, heading, ..., class]
                   gt_names: optional, (N), string
                   voxels: optional (num_voxels, max_points_per_voxel, 3 + C)
                   voxel_coords: optional (num_voxels, 3)
                   voxel_num_points: optional (num_voxels)
                   ...
           """
   ```

2. used functions

   1. `self.data_augmentor`ï¼Œæ•°æ®å¢å¼º
   2. è¿‡æ»¤æ‰ä¸å…³æ³¨çš„ gt ç±»åˆ«ï¼Œå¹¶ä¸”å°†å…³æ³¨ç±»åˆ«è½¬æ¢ä¸º digitã€‚è™½ç„¶è¿™ä¸æ˜¯ functionsï¼Œä½†æˆ‘ä¹Ÿæ•´ç†åœ¨æ­¤
   3. `self.point_feature_encoder & self.data_processor`ï¼Œä½“ç´ åŒ–

#### prepare_datset_ssl

ä¸å¸¸è§„ prepare_dataset ç›¸æ¯”ï¼Œssl è¦è¾“å‡ºä¸¤ä¸ª data_dictï¼Œä¸€ä¸ªç»™ teacherï¼Œä¸€ä¸ªç»™ studentï¼Œå¹¶ä¸”è¦å¯¹æœ‰æ—  `gt_boxes` æ ‡ç­¾è¿›è¡Œåˆ†åˆ«å¤„ç†

1. input params

   ```python
       def prepare_data_ssl(self, data_dict, output_dicts):
           # output_dicts is a list: ['teacher', 'student']
   ```

2. output

   ```python
   return teacher_data_dict, student_data_dict
   ```

3. used functions

   1. `self.teacher_augmentor & self.student_augmentor`ï¼Œä¸å¸¸è§„ augmentor ä¸åŒçš„æ˜¯ï¼š

      1. äº‹å…ˆå°† data_dict è¿›è¡Œäº† deepcopyï¼Œåˆ†åˆ«é€å…¥äºŒè€…çš„ augmentor ä¸­

      2. augmentor è®°å½•äº† augmentation çš„å‚æ•°ï¼Œåœ¨ä¹‹åä¼š inverse augmentation

         ```python
                 data_dict['augmentation_list'] = copy.deepcopy(self.aug_list)
                 data_dict['augmentation_params'] = {}
         ```

   2. ï¼ˆå¦‚æœæœ‰ gtï¼‰è¿‡æ»¤æ‰ä¸å…³æ³¨çš„ gt ç±»åˆ«

   3. `self.point_feature_encoder & self.data_processor`ï¼Œä½“ç´ åŒ–

#### collate_batch

pytorch `Dataset` é€šè¿‡ `collat_fn` å°†å¤šä¸ª sample ç»„åˆåˆ°ä¸€ä¸ª batch å½“ä¸­ï¼ŒOpencPCDet å°†å¤šä¸ªæ•°æ®å­—å…¸ï¼Œæ‰“åŒ…ä¸ºä¸€ä¸ªæ•°æ®å­—å…¸ã€‚è¿™é‡Œéœ€è¦é¢å¤–å¤„ç† student & teacher ä¸¤ä¸ª data_dict çš„æƒ…å†µ

1. input params: batch_list

2. output: 

   1. return teacher_batch, student_batchï¼Œå¦‚æœæ˜¯ `prepare_dataset_ssl`
   2. return single_batchï¼Œå¦‚æœæ˜¯ `prepare_dataset`

   æ¯ä¸€ä¸ª batch è¿˜åšäº†ä¸€äº›å½¢çŠ¶ä¸Šçš„å¤„ç†ï¼š

   1. å¯¹äº `voxels, voxel_num_points` ç›´æ¥ concatï¼Œ(N1+N2+..., max_points_per_voxel, 3+C)
   2. å¯¹äº `points, voxel_coords` åŠ å…¥äº† batch åºå·ï¼Œç„¶åå† concatï¼Œ(N1+N2+..., 1+3+C)
   3. å¯¹äº `gt_boxes` åˆ™è¦å…¼é¡¾æ¯ä¸ª sample gt æ•°é‡ä¸åŒçš„æƒ…å†µï¼Œç”¨ (batch_size, max_gt, 7+C+1) å½¢çŠ¶çš„ array å­˜å‚¨èµ·æ¥ã€‚ç©º gt ç”¨ 0 å¡«è¡¥
   4. å…¶ä»–çš„ç›´æ¥ stackï¼Œæˆ–è€…ä¸å˜

å­¦ä¹ ç‚¹ï¼š

1. `np.pad(array, ...)` å¯¹æ•°æ®è¿›è¡Œ paddingã€‚ç±»ä¼¼çš„æ•ˆæœä¹Ÿå¯ä»¥å…ˆåˆ›å»º zero matrixï¼Œç„¶åå†èµ‹å€¼

### ONCESemiDataset

è¯¥ç±»ç»§æ‰¿äº† `SemiDatasetTemplate`ï¼Œå¹¶å®ç°ä¸‰ä¸ªåŸºæœ¬åŠŸèƒ½

1. **åŸå§‹æ•°æ®çš„è·å–**
2. **å°è£…é¢„æµ‹å¾—åˆ°çš„ pred_dicts**
3. **evaluation code**

ä¸€èˆ¬å¯¹äºç›‘ç£å­¦ä¹ çš„ Datasetï¼Œè¿˜éœ€è¦å®ç° `__getitem__`  è·å¾—æ•°æ®ï¼Œè€Œè¿™é‡Œä¸ºäº†å…¼é¡¾åŠç›‘ç£å­¦ä¹ ï¼ŒæŠŠè¿™ä¸¤ä¸ªæ–¹æ³•ä¸‹æ”¾åˆ°å­ç±»å»å®ç°äº†

#### init

1. input params

   ```python
   class ONCESemiDataset(SemiDatasetTemplate):
       def __init__(self, dataset_cfg, class_names, infos=None, training=True, root_path=None, logger=None):
   ```

#### methods

1. `get_lidar` & `get_image` & `project_lidar_to_image`
2. `generate_prediction_dicts` è¿”å›ä¸€ä¸ª once-style annos listï¼Œ
3. `evaluation`ï¼Œæ ¹æ® det_annos & class_names ç”Ÿæˆç»“æœ

### ONCEPretrainDataset & ONCELabeledDataset & ONCEUnlabeledDataset & ONCETestDataset

è¿™å››ä¸ªç±»éƒ½ç»§æ‰¿äº† `ONCESemiDataset`ï¼Œå¹¶å„è‡ªå®ç° `__getitem__`ï¼Œæ„æˆ input_dictï¼Œç„¶åè¾“å…¥ `prepare_data or prepare_data_ssl`ï¼Œæœ€åè¿”å›æœ€ç»ˆçš„ data_dict

å…¶ä¸­ Pretrain å’Œ Test ä¸¤ä¸ª Dataset æ˜¯ä¸€æ¨¡ä¸€æ ·çš„ï¼Œè¿”å›å¸¸è§„çš„ data_dict

Labeled å’Œ Unlabeled ä¸¤ä¸ª Dataset è¿”å› (teacher_dict, student_dict)

## ONCEDataset Infos & Database Processing

ä¸ºäº†åŠ é€Ÿè®­ç»ƒè¿‡ç¨‹ï¼Œæˆ‘éœ€è¦åŠ å…¥è‡ªå·±å…³æ³¨çš„ database ä¿¡æ¯ï¼Œæ‰€ä»¥å¿…é¡»è¦å­¦ä¹ å¦‚ä½•æ„å»ºè‡ªå·±çš„ database info

ä¹‹å‰åœ¨çœ‹ `ONCEDataset` çš„æ—¶å€™å°±çœ‹åˆ° `__getitem` å°±åœæ­¢äº†ï¼Œå¯¹äº `get_infos & create_ground_truth_database` è¿™ä¸¤ä¸ªæ–¹æ³•å¹¶æ²¡æœ‰ä»”ç»†çœ‹äº†ï¼Œç°åœ¨æ˜¯å¿…é¡»è¦ä¸Šäº†ï¼Œåœ¨ç„¶åå°±æ˜¯ `DatabaseSampler` çš„åŠŸèƒ½æ•´ç†ä¸€ä¸‹ï¼Œå°±åŸºæœ¬æ‰“é€šäº†æ•°æ®é›†çš„å¤„ç†æµç¨‹ï¼Œç„¶åå°±å¯ä»¥åŠ å…¥è‡ªå·±æƒ³è¦çš„ç‰¹å¾äº†

### get_infos

ç”Ÿæˆå„ä¸ª split ç”Ÿæˆ info ä¿¡æ¯ï¼Œåœ¨ä¹‹åå°†è¿™äº› info å­˜å‚¨ä¸º `once_infos_***.pkl` æ–‡ä»¶

1. input paramsï¼ŒåŸºæœ¬ä¸éœ€è¦

2. outputï¼Œä¸€ä¸ªåˆ—è¡¨ `all_infos`ï¼Œå­˜å‚¨äº†æ‰€æœ‰ frames çš„ä¿¡æ¯

3. used functions

   1. `process_single_sequence`ï¼Œè¿”å›ä¸€ä¸ª list of dictï¼Œæ¯ä¸€ä¸ª dict ä»£è¡¨ä¸€ä¸ª frameï¼Œé‡Œé¢å­—å…¸åŒ…æ‹¬å¾ˆå¤šä¿¡æ¯

      ```python
                      frame_dict = {
                          'sequence_id': seq_idx,
                          'frame_id': frame_id,
                          'timestamp': int(frame_id),
                          'prev_id': prev_id,
                          'next_id': next_id,
                          'meta_info': meta_info,
                          'lidar': pc_path,
                          'pose': pose,
                          'annos':
                          	{
                                  'name':
                                  'boxes_3d':
                                  'boxes_2d':
                                  'num_points_in_gt':
                              }
                      }
      ```

      æœ€ç»ˆçš„ `all_infos` å°±æ˜¯å¤šä¸ª `process_single_sequence` çš„ç»“æœåˆåœ¨ä¸€èµ·ï¼Œå½¢æˆä¸€ä¸ªå¤§çš„ list of dict

### create_groundtruth_database

è¿™ä¸€æ­¥æ˜¯ä¸º data augmentation å‡†å¤‡çš„ï¼Œåªé’ˆå¯¹è®­ç»ƒé›†ç”Ÿæˆ databaseã€‚æŠŠæ¯ä¸ªç±»åˆ«çš„ç‰©ä½“éƒ½æ”¾åœ¨äº†ä¸€èµ·ï¼Œåœ¨ä¹‹åå¥½é’ˆå¯¹ç±»åˆ«è¿›è¡Œé‡‡æ ·

1. input paramsï¼Œä¸»è¦æœ‰ä¸¤ä¸ªï¼š`info_path & split`ï¼Œå…·ä½“ä¸€ç‚¹æ¥è¯´å°±æ˜¯ `once_infos_train.pkl & train`ã€‚

2. output å¯ä»¥è®¤ä¸ºæœ‰ä¸¤ä¸ªï¼š

   1. `once_dbinfos_train.pkl` æ˜¯ä¸€ä¸ª dict of list of dictï¼Œå­˜å‚¨æ‰€æœ‰ç±»åˆ«çš„ä¿¡æ¯

      ```python
                      db_info = {'name': names[i], 'path': db_path, 'gt_idx': i,
                                  'box3d_lidar': gt_boxes[i], 'num_points_in_gt': gt_points.shape[0]}
      ```

   2. `'%s_%s_%d.bin' % (frame_id, names[i], i)`ï¼Œç›´æ¥å­˜å‚¨æ¯ä¸ªåœºæ™¯çš„æ¯ä¸ªç‰©ä½“ï¼Œé€šè¿‡ä¸Šé¢çš„ `db_path` å°±å¯ä»¥æ‰¾åˆ°å¯¹åº”çš„ç‰©ä½“

### å¦‚ä½•æ„å»ºå¤æ‚é¡¹ç›®ï¼Ÿ

æ•´ç†å®Œäº†ä»£ç ï¼Œè™½ç„¶çŸ¥é“æ¯ä¸€ä¸ªæ¨¡å—çš„åŠŸèƒ½ï¼Œä½†æ˜¯è¿˜æ˜¯ç¨å¾®æœ‰ç‚¹æ··ä¹±çš„æ„Ÿè§‰ã€‚è¿™ç§æ„Ÿè§‰æ¥è‡ªäºä¸€ä¸ªé—®é¢˜ï¼šå¦‚æœè®©æˆ‘è‡ªå·±æ¥è®¾è®¡æµç¨‹åº”è¯¥æ€ä¹ˆå»æ„å»ºä»£ç çš„ç»“æ„ï¼Ÿç°åœ¨æˆ‘åªèƒ½æœ‰ä¸€ä¸ªç®€å•çš„æƒ³æ³•ï¼š

1. æ¸…æ™°åœ°æ„å»ºæˆ‘ä»¬éœ€è¦å®Œæˆçš„æ‰€æœ‰æµç¨‹çº¿
2. æ„å»ºæ¯ä¸€æ¡æµç¨‹çº¿éœ€è¦çš„ä»£ç 
3. å¯¹äºå¹³è¡Œåº¦/ç›¸ä¼¼åº¦é«˜çš„æµç¨‹çº¿ï¼Œæ¯”è¾ƒä¸€ä¸‹æœ‰æ— å…±åŒç‚¹ï¼Œå°†å…±åŒç‚¹ç”¨ä¸€ä¸ªï¼ˆåŸºï¼‰ç±»å®ç°ã€‚é«˜åº¦çš„æ¨¡å—åŒ–èƒ½åœ¨ä¹‹åå±•ç°æ›´å¥½çš„çµæ´»æ€§å’Œè§„èŒƒæ€§
4. å®ç°å„ä¸ªå·®å¼‚åŒ–å­ç±»

å¦‚æœæŠŠè¿™ä¸ª semi-supervised dataset ç”»ä¸€ä¸ªæµç¨‹å›¾çš„ç”»ï¼Œæˆ‘ä¼šç”¨ä¸‹å›¾è¡¨ç¤º

```mermaid
graph LR
    labeled(labeled)
    unlabeled(unlabeled)
    getitem(student dict & teacher dict)
    prepare_data(prepare_data_ssl)
    semi-supervise --> labeled & unlabeled --> getitem --> prepare_data
    subgraph DatasetTemplate
    prepare_data
    collate_fn(collate_batch)
    end
    subgraph ONCESemiDataset
    getitem
    others(generate_pred_dicts & evaluation)
    end
    style semi-supervise fill:pink
```

OpenPCDet çš„ä¸€ä¸ªä¼˜åŠ¿å°±åœ¨äºå°† `prepare_dataset` è¿™ä¸€éƒ¨åˆ†ä½¿ç”¨ä¸€ä¸ª DatasetTemplate å®ç°ï¼Œä¸å…·ä½“æ•°æ®é›†åˆ†ç¦»ï¼Œå„ä¸ªæ•°æ®é›†æ‰€è¾“å…¥çš„ data_dict å½¢å¼ä¸Šæ˜¯ç»Ÿä¸€çš„ï¼Œæœ‰å¾ˆå¥½çš„è§„èŒƒä½œç”¨ï¼ŒåŒæ—¶ä¹Ÿå¢åŠ äº†çµæ´»æ€§

## SemiSECOND & AnchorHeadSemi

å’ŒåŸå§‹ SECOND æ¯”è¾ƒï¼ŒSemiSECOND å°†æ¨¡å‹åˆ†ä¸ºä¸‰ç§ç±»å‹ï¼šorigin, student, teacherã€‚æ ¹æ®ä¸åŒçš„ç±»å‹ï¼Œå‰å‘æ–¹ç¨‹ `forward` å°†ç¨æœ‰å·®åˆ«ã€‚Detector åœ¨é€»è¾‘ä¸Šåˆ†ä¸ºä¸Šé¢ä¸‰ç±»ï¼Œå®é™…æ‰§è¡Œæ¨¡å—æ˜¯è½å®åˆ° dense head ä¸Šï¼Œå³ `AnchorHeadSemi`

```python
    def set_model_type(self, model_type):
        assert model_type in ['origin', 'teacher', 'student']
        self.model_type = model_type
        self.dense_head.model_type = model_type
```

å¦ä¸€ä¸ªç‚¹ï¼šconsistency loss æ˜¯åœ¨æ¨¡å‹ä¹‹å¤–è®¡ç®—çš„ï¼Œtraining loss æ˜¯åœ¨æ¨¡å‹å†…è®¡ç®—çš„

### Origin

ä¸åšè¿‡å¤šä»‹ç»ï¼Œå°±æ˜¯åŸæ±åŸå‘³çš„ SECONDã€‚training å’Œ testing çš„è¡¨ç°éƒ½ä¸æ”¹å˜

### Student

å…¶å® student æ¨¡å‹å’Œ origin æ˜¯æ¯”è¾ƒå¾ˆç›¸ä¼¼çš„ï¼Œåªæ˜¯ä¸ºäº†å…¼å®¹å¤„ç† unlabeled dataï¼Œå¤šäº†ä¸€ä¸ªåˆ¤æ–­

- training, return (loss & pred_boxes) or just pred_boxes 
- testing, return pred_boxes with post processing

```python
        elif self.model_type == 'student':
            for cur_module in self.module_list:
                batch_dict = cur_module(batch_dict)
            if self.training:
                if 'gt_boxes' in batch_dict: # for (pseudo-)labeled data, this is the only difference between origin mode
                    loss, tb_dict, disp_dict = self.get_training_loss()
                    ret_dict = {
                        'loss': loss
                    }
                    return batch_dict, ret_dict, tb_dict, disp_dict
                else:
                    return batch_dict
            else:
                pred_dicts, recall_dicts = self.post_processing(batch_dict)
                return pred_dicts, recall_dicts
```

### Teacher

æŠŠæ‰€æœ‰è¾“å…¥éƒ½ä½œä¸º unlabeldï¼Œç›´æ¥ return pred_boxes

```python
        elif self.model_type == 'teacher':
            # assert not self.training
            for cur_module in self.module_list: # MIGHT CONSIDERING GET SOME LOSS
                batch_dict = cur_module(batch_dict)
            return batch_dict
```

### Model Wrapper

åŠç›‘ç£å­¦ä¹ æ—¢æœ‰ labeled æ•°æ®ï¼Œåˆæœ‰ unlabeled æ•°æ®ï¼Œæ‰€ä»¥ä½¿ç”¨ä¸€ä¸ª Wrapper æ¥åŒæ—¶å¤„ç†ä¸¤ç§æ•°æ®

```python
class DistStudent(nn.Module):
    def __init__(self, student):
        super().__init__()
        self.onepass = student

    def forward(self, ld_batch, ud_batch):
        return self.onepass(ld_batch), self.onepass(ud_batch)
```

## SE-SSD & Mean-Teacher

### sess / se_ssd

sess å’Œ se_ssd æ˜¯éå¸¸è¿‘ä¼¼çš„ä¸¤ä¸ªå‡½æ•°ã€‚ä¹Ÿæ˜¯åŠç›‘ç£å­¦ä¹ çš„æ ¸å¿ƒä»£ç ï¼šè¾“å…¥ student & teacher æ¨¡å‹ï¼Œè¾“å…¥ labeled_data & unlabeled_dataï¼Œé€šè¿‡å‰å‘æ–¹ç¨‹å¾—åˆ°é¢„æµ‹ç»“æœï¼Œæœ€åè®¡ç®—ç›‘ç£å­¦ä¹ çš„ loss & åŠç›‘ç£çš„ consistency loss 

1. input params

   ```python
   def se_ssd(teacher_model, student_model,
            ld_teacher_batch_dict, ld_student_batch_dict,
            ud_teacher_batch_dict, ud_student_batch_dict,
            cfgs, epoch_id, dist):
   ```

2. output: return loss, tb_dict, disp_dictï¼Œå…¶ä¸­ loss ç”±2ä¸ªéƒ¨åˆ†ç»„æˆ

   ```python
       loss = sup_loss + consistency_weight * consistency_loss
   ```

3. used functions 

   1. `load_data_to_gpu(data_dict)` åå­—å°±æ˜¯åŠŸèƒ½ã€‚æä¸€å¥ï¼šè¿™ä¸ªå‡½æ•°åœ¨ç›‘ç£å­¦ä¹ é‡Œæ˜¯è¢«åŒ…è¿›äº† `model_fn_decorator`

   2. `filter_boxes(data_dict, cfg)` è¿™ä¸€æ­¥å…¶å®åšçš„æ˜¯ post_processing çš„å·¥ä½œï¼Œä»…æœ‰ä¸€ä¸ªåŒºåˆ«ï¼š`pred_cls` æ²¡æœ‰å–æœ€å¤§å€¼ï¼Œæ‰€æœ‰ class çš„å¾—åˆ†éƒ½ä¿ç•™äº†ã€‚æœ€ç»ˆè¿”å› list of dict

      ```python
              record_dict = [{
                  'pred_boxes': final_boxes,
                  'pred_cls_preds': final_cls_preds,
                  'pred_labels': final_labels
              } for _ in batch_size]
      ```

   3. `reverse_transform` å°† teacher çš„ augmentation é€†è½¬ï¼Œå¹¶å®æ–½ student_augmentation

      ```python
      @torch.no_grad()
      def reverse_transform(teacher_boxes, teacher_dict, student_dict):
          return teacher_boxes	# dict like output of filter_boxes
      ```

   4. **`get_iou_consistency_loss`** å°±æ˜¯è®¡ç®—ä¸€è‡´æŸå¤±çš„æ ¸å¿ƒ

      1. input params: teacher_boxes, student_boxesï¼Œç»è¿‡äº† filter & transform

      2. output: box_loss, cls_loss

      3. **è®¡ç®—è¿‡ç¨‹å¦‚ä¸‹**ï¼š

         1. è®¡ç®— teacher_class & student_class çš„åŒ¹é…çŸ©é˜µ (Nt, Ns)ï¼Œç±»åˆ«ç›¸åŒä¸º1ï¼Œä¸åŒä¸º0
         2. è®¡ç®— teacher_boxes & student_boxes çš„ IoU çŸ©é˜µ (Nt, Ns)ï¼Œå¹¶ä¸”å‡å»åŒ¹é…çŸ©é˜µï¼Œè¿™æ ·å°±èƒ½è¿‡æ»¤ç±»åˆ«ä¸åŒçš„ boxes
         3. è®¡ç®— student_boxes åŒ¹é…çš„ matched_teacher_boxes (Ns,)ã€‚å¹¶è®¡ç®—ä¸€ä¸ª maskï¼šIoU >= thresh = 0.7ï¼Œåœ¨è®¡ç®— smooth L1 loss æ—¶è¿›è¡Œè¿‡æ»¤
         4. è®¡ç®— smooth L1 lossï¼Œå¹¶ä½¿ç”¨ batch_normalizer & num_matched_boxes è¿›è¡Œå½’ä¸€åŒ–

         sess ä¸º `get_consistency_loss`ï¼Œå®ç°ç¨æœ‰ä¸åŒï¼Œè¿™é‡Œä¸åšæ•´ç†ã€‚å€¼å¾—ä¸€æçš„æ˜¯ï¼ŒONCE è®ºæ–‡è¯´ box size ç›¸å…³çš„ä¸€è‡´æŸå¤±ä¼¼ä¹å¹¶ä¸é‡è¦ï¼Ÿ

         > SESS [57] performs worse than Mean Teacher with 58.78% mAP, which indicates that size and center consistency may not be useful in driving scenarios.

   5. `sigmoid_rampup` æ§åˆ¶ consistency loss çš„æƒé‡é€æ¸å¢åŠ ç›´åˆ°å¢åŠ åˆ°1

### Mean Teacher Update

åœ¨æ¯ä¸€æ¬¡ iteration è¿‡åå¯¹ teacher model è¿›è¡Œ updateã€‚å¯ä»¥å¤§æ¦‚åˆ†ä¸º2ä¸ªé˜¶æ®µï¼š

1. rampup é˜¶æ®µï¼Œä½¿ç”¨çœŸå®å¹³å‡å€¼
2. ema é˜¶æ®µï¼Œä½¿ç”¨ ema

å­¦ä¹ ç‚¹ï¼š

1. ä½¿ç”¨ `model.parameters()` æ–¹æ³•å®Œæˆå¯¹æ‰€æœ‰å‚æ•°çš„è¿­ä»£ï¼Œå¹¶ä½¿ç”¨ `tensor.data` å¯¹å¼ é‡å€¼è¿›è¡Œä¿®æ”¹ï¼Œ`tensor.data` ä¸åŸ tensor å…±äº«å­˜å‚¨ï¼Œä½¿ç”¨ inplace æ“ä½œå°±å¯ä»¥å®Œæˆã€‚`tensor.detach()` ä¹Ÿæ˜¯å¯ä»¥å®Œæˆç±»ä¼¼çš„åŠŸèƒ½çš„

   ```python
   def update_ema_variables_with_fixed_momentum(model, ema_model, alpha):
       for ema_param, param in zip(ema_model.parameters(), model.parameters()):
           # ema_param.data.mul_(alpha).add_(1 - alpha, param.data)
           ema_param.detach().mul_(alpha).add_(1 - alpha, param.data)	
           # if use .data, loss.backward would extremely slow sometimes
   ```

## Mermaid

ä¸Šé¢çš„æµç¨‹å›¾å°±æ˜¯ç”¨ mermaid å†™çš„ï¼Œè¿™é‡Œç®€å•æ€»ç»“ä¸€ä¸‹ç”»æµç¨‹å›¾çš„è¯­æ³•

1. ä½¿ç”¨ `graph` or `flowchart`åˆ›å»ºæµç¨‹å›¾ï¼Œå¹¶åˆå§‹åŒ–å…¶æ–¹å‘ `LR, RL, TB, BT` ä»å·¦åˆ°å³ï¼Œä»ä¸Šåˆ°ä¸‹éƒ½å¯æŒ‡å®š

2. ç›´æ¥ä½¿ç”¨å˜é‡æ–°å»ºèŠ‚ç‚¹ï¼Œé€šè¿‡ä¸€äº›ç‰¹æ®Šç¬¦æŒ‡å®šå½¢çŠ¶ï¼Œåœ¨å­—ç¬¦ä¹‹å†…å¡«å†™æ–‡å­—

   ```mermaid
   flowchart LR
       a("(A node with round edges)") -.->
       b{"{rhombus}"} <-->
       c(("((circle))")) --x
   	d["[square] defualt"]
       style a fill:#ffffd2
       style b fill:#fcbad3
       style c fill:#aa96da
       style d fill:#a8d8ea
   ```

3. ä½¿ç”¨ç®­å¤´ `-->` è¿æ¥å„ä¸ªèŠ‚ç‚¹ï¼Œä¹Ÿå¯åœ¨ç®­å¤´ä¸­æ·»åŠ æ–‡å­— `--text->`ã€‚ç®­å¤´çš„æ ·å¼ä¹Ÿå¯ä»¥æŒ‡å®šï¼š`---, -.-, --x, <-->, ==>`

4. ä½¿ç”¨ style è¯­æ³•æ›´æ”¹é¢œè‰²ï¼š`style id fill:#ffffff, stroke: #ffffff, stroke_witdh: 4px`

5. ä½¿ç”¨ `subgraph id... end` è¯­æ³•åˆ›å»ºå­å›¾

```scripts
flowchart LR
    a("(A node with round edges)") -.->
    b{"{rhombus}"} <-->
    c(("((circle))")) --x
	d["[square] defualt"]
    style a fill:#ffffd2
    style b fill:#fcbad3
    style c fill:#aa96da
    style d fill:#a8d8ea
```

mermaid è¿˜èƒ½ç”»å¾ˆå¤šç±»å‹çš„å›¾è¡¨ï¼Œæœ‰éœ€è¦å†å»æ¢ç´¢å§ğŸ˜