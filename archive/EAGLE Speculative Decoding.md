## EAGLE Speculative Decoding

EAGLE æŠ•æœºé‡‡æ ·ä½œä¸ºç›®å‰æœ€å¼ºçš„æŠ•æœºé‡‡æ ·æ–¹æ³•ï¼Œå€¼å¾—æ•´ç†ä¸€ç•ªã€‚æˆ‘å°†ä»æŠ•æœºé‡‡æ ·åŸºç¡€å¼€å§‹ï¼Œé€æ­¥åœ°è®²è§£ EAGLE æŠ•æœºé‡‡æ ·çš„æ”¹è¿›è¿‡ç¨‹ï¼Œå¹¶é…åˆä»¥å®é™…ä»£ç å¸®åŠ©ç†è§£ã€‚åœ¨æœ¬æ–‡ä¸­å°†ä»¥ SD ä»£è¡¨ Speculative Decoding çš„ç¼©å†™

Reference [github](https://github.com/SafeAILab/EAGLE)

## æŠ•æœºé‡‡æ ·åŸºç¡€

- **LLM decode process & the challenge**

  LLM åœ¨ decode é˜¶æ®µé‡‡ç”¨çš„æ˜¯è‡ªå›å½’å¼ decodeï¼Œè¿™æ ·çš„æ–¹å¼æ¯æ¬¡ input tokens æ•°ç›®åªèƒ½ä¸º1ï¼Œç„¶åè·å¾— next tokenï¼Œä»¥æ­¤å¾ªç¯å¾€å¤ç›´è‡³é‡åˆ° end of text tokenã€‚ç”¨ç®€æ´çš„ä¼ªä»£ç å¯ä»¥è¡¨ç¤ºä¸ºå¦‚ä¸‹

  ```python
  # decode_token is a single integer (1,)
  while True:
      # llm forward
      hidden_states = transformer(decode_token_id)
      logits = lm_head(hidden_states)
      
      # sample next token
      next_token_id = sampler(logits)
      
      # check end
      if next_token == end_of_text_token:
          break
      
      # continue
      decode_token_id = next_token_id
  ```

  è¿™æ ·çš„æ–¹å¼æœ‰ä¸€ä¸ªæ˜æ˜¾çš„é—®é¢˜ï¼šæ•´ä¸ªè¿‡ç¨‹è®¡ç®—å¼ºåº¦ä½ï¼Œæˆä¸º memory bound åœºæ™¯ã€‚ä¸€ä¸ªæ›´å½¢è±¡çš„ä¾‹å­æ¥è¯´æ˜ï¼šinput tokens = 8 å’Œ input tokens = 1 çš„ decode æ—¶é—´æ˜¯éå¸¸æ¥è¿‘çš„ï¼Œå› ä¸ºæ­¤æ—¶è®¡ç®—åŸºæœ¬ä¸Šä¸è€—æ—¶ï¼Œè€—æ—¶çš„æ˜¯è¯»å–/å†™å…¥æƒé‡å’Œæ¿€æ´»å€¼

- **Intuitive of Speculative Decoding**

  æŠ•æœºé‡‡æ ·çš„æ ¸å¿ƒæ€æƒ³ï¼Œå°±æ˜¯ç”¨ä¸€ä¸ª draft model å»çŒœæµ‹ï¼ˆspeculateï¼‰åé¢çš„ tokens æ˜¯ä»€ä¹ˆï¼ŒçŒœå®Œè¿‡åç”¨åŸæ¨¡å‹ï¼ˆæœ¬æ–‡æœ‰æ—¶å€™ä¹Ÿä¼šç§°åŸæ¨¡å‹ä¸º base modelï¼‰å»è¿›è¡ŒéªŒè¯ï¼Œå¦‚æœçŒœå¯¹äº†ï¼Œé‚£å°±æ­£å¥½æ¥å—ï¼›å¦‚æœçŒœé”™äº†ï¼Œå°±æ‰”æ‰çŒœé”™çš„ tokenã€‚åŠ é€Ÿæ•ˆæœæ¥è‡ªäºå¹¶è¡Œè®¡ç®—äº†å¤šä¸ª input tokensï¼ŒçŒœå¯¹å¾—è¶Šå¤šï¼ŒåŠ é€Ÿè¶Šæ˜æ˜¾ã€‚å…·ä½“æ¥è¯´ï¼š**æŠ•æœºé‡‡æ ·å°‘é‡çš„ draft model çŒœæµ‹æ—¶é—´ + ç”¨ä¸€æ¬¡ decode çš„æ—¶é—´ç”¨äºéªŒè¯ï¼Œè¾“å‡ºäº†å¤šä¸ªæ­£ç¡®çš„ next tokensï¼Œæ‰€ä»¥èŠ‚çœäº†å¤šæ¬¡ decode çš„æ—¶é—´ï¼Œè·å¾—äº†åŠ é€Ÿæ•ˆæœ**

  ä¸‹é¢æˆ‘å°†ç”¨ä¸€ä¸ªå…·ä½“çš„ä¾‹å­ï¼Œæ¥å±•ç¤ºæ•´ä¸ªæŠ•æœºé‡‡æ ·çš„è¿‡ç¨‹ã€‚å‡è®¾ prompt ä¸ºä¸‰ä¸ªå•è¯ï¼š`How can I`ï¼Œå¹¶ä¸”å‡è®¾ LLM æœ€ç»ˆçš„ decode è¾“å‡ºä¸º `learn eagle speculative decoding well?`ï¼Œæˆ‘ç”¨ä»¥ä¸‹å›¾ç¤ºæ¥è¡¨ç¤ºä¸€èˆ¬çš„ LLM decoding è¿‡ç¨‹

  <img src="EAGLE Speculative Decoding/image-20250328225651677.png" alt="image-20250328225651677" style="zoom:80%;" />
  
  **æˆ‘ä»¬å¯ä»¥ç®€å•åœ°æŠŠ LLM (i.e. Base Model) çœ‹ä½œæ˜¯ä¸€ä¸ª next token prediction machine**ï¼Œä¹Ÿå°±æ˜¯è¯´ä½ ç»™è¿›å»ä»»ä½• tokenï¼Œå®ƒéƒ½ä¼šåŸºäºå†å²çŠ¶æ€æ¥é¢„æµ‹ä¸‹ä¸€ä¸ª token æ˜¯ä»€ä¹ˆã€‚è¿™ä¸ªæƒ³æ³•å°†ä¼šç®€åŒ– LLM æ¨¡å‹ï¼Œå¸®åŠ©æˆ‘ä»¬ç†è§£æ•´ä¸ª speculative decoding è¿‡ç¨‹ã€‚ç®€è¦æè¿°ä¸‹ä¸Šå›¾çš„è¿‡ç¨‹ï¼šåœ¨ prefill ä¸­è¾“å…¥ `How can I` é¢„æµ‹å‡ºäº† 3 ä¸ª next tokensï¼Œä½†æ˜¯æˆ‘ä»¬åªå…³æ³¨æœ€åä¸€ä¸ªï¼Œå³ç”± `I` é¢„æµ‹å¾—åˆ°çš„ next token `learn`ã€‚ç„¶åè¿›å…¥ decode é˜¶æ®µï¼Œæˆ‘ä»¬ä½¿ç”¨ `learn` å»é¢„æµ‹å¾—åˆ°ä¸‹ä¸€ä¸ª token `eagle`ï¼Œç”¨ `eagle` å»é¢„æµ‹å¾—åˆ° `speculative`ï¼Œ...ï¼Œå¦‚æ­¤å¾ªç¯ä¸‹å»è·å¾—æœ€ç»ˆå®Œæ•´çš„å¥å­ `How can I learn eagle speculative decoding well?`
  
  OKï¼Œç°åœ¨æ¥çœ‹çœ‹ç”¨æŠ•æœºé‡‡æ ·æ•´ä¸ªè¿‡ç¨‹å¯èƒ½æ˜¯ä»€ä¹ˆæ ·çš„ï¼Ÿè¿™é‡Œå°±å¼€å§‹å¼•å…¥ draft model äº†ï¼Œè¯¥ draft model ä¹Ÿæ˜¯ä¸€ä¸ª LLMï¼Œåªä¸è¿‡æ¯”åŸæ¥çš„ baes model è¦å°å¾ˆå¤šï¼Œ**ä½†æ˜¯ä¸å¦¨ç¢å…¶æœ¬è´¨æ˜¯ä¸€ä¸ª next token prediction machine**
  
  <img src="EAGLE Speculative Decoding/image-20250328231636101.png" alt="image-20250328231636101" style="zoom:80%;" />
  
  Draft model æ‹¿åˆ°ä¸€ä¸ªåˆå§‹çš„ token `learn`ï¼Œå¼€å§‹äº†è‡ªå·±çš„è‡ªå›å½’è¿‡ç¨‹ï¼Œè·å¾—äº†è®¸å¤š draft tokens `eagle speculative decoding better? ...`ã€‚è¿™äº› draft tokens å°±æ˜¯ draft model å»çŒœæµ‹ base model æ¥ä¸‹æ¥ä¼šç”Ÿæˆçš„è¯ã€‚é—®é¢˜æ¥äº†ï¼Œæ€ä¹ˆçŸ¥é“ draft model çŒœå¾—å¯¹ä¸å¯¹å‘¢ï¼Ÿè¿™å°±éœ€è¦ä¸€ä¸ªéªŒè¯è¿‡ç¨‹ã€‚éªŒè¯è¿‡ç¨‹çš„ç¬¬ä¸€æ­¥å°±æ˜¯å°†è¿™äº› draft tokens è¿åŒ initial token **ä¸€èµ·**è¾“å…¥åˆ° base model ä¸­ï¼Œå¦‚ä¸‹å›¾æ‰€ç¤º
  
  <img src="EAGLE Speculative Decoding/image-20250329002507107.png" alt="image-20250329002507107" style="zoom:80%;" />
  
  å½“è¿™äº› tokens è¾“å…¥åˆ° base model è¿‡åï¼Œæ¯ä¸€ä¸ª token éƒ½ä¼šäº§ç”Ÿè‡ªå·±å¯¹åº”çš„ next tokenï¼ˆå†æ¬¡å¼ºè°ƒï¼Œbase model çš„æœ¬è´¨æ˜¯ä¸€ä¸ª next token prediction machineï¼‰ã€‚æ­¤å¤–ä½ å¯ä»¥æ³¨æ„åˆ°è¿™ä¸ªå›¾ä¸­æ²¡æœ‰è™šçº¿è¿›è¡Œè¿æ¥ï¼Œ**è¿™è¡¨ç¤ºè¯¥è¿‡ç¨‹å¹¶éè‡ªå›å½’çš„ï¼Œè€Œæ˜¯å¹¶è¡Œçš„**ã€‚ç°åœ¨æˆ‘ä»¬æœ‰äº† base model é¢„æµ‹çš„ next tokenï¼Œæˆ‘ä»¬å°±å¯ä»¥å’Œç”± draft model æ‰€äº§ç”Ÿçš„ draft tokens è¿›è¡Œå¯¹æ¯”ï¼Œçœ‹ä¸‹æ˜¯å¦çŒœå¯¹äº†
  
  <img src="EAGLE Speculative Decoding/image-20250329002637632.png" alt="image-20250329002637632" style="zoom:80%;" />
  
  å¯ä»¥çœ‹åˆ°ï¼Œ**ç»¿è‰²çš„çº¿æ¡ä»£è¡¨æˆ‘ä»¬çš„ draft tokens å’ŒçœŸå®çš„ base model æ‰€é¢„æµ‹çš„ next tokens æ˜¯ä¸€æ ·çš„ï¼Œçº¢è‰²çº¿æ¡å°±ä»£è¡¨äºŒè€…å¹¶ä¸åŒ¹é…**ã€‚æ‰€ä»¥è¯´åœ¨è¿™ä¸ª case å½“ä¸­ draft model çŒœå¯¹äº†ä¸‰ä¸ªè¯ `eagle speculative decoding`ã€‚ä½†æ˜¯æœ€åä¸€ä¸ªè¯ `well?`æ²¡æœ‰çŒœå¯¹ï¼ŒçŒœçš„æ˜¯ `better?`ï¼Œå¹¶ä¸”ä¸€æ—¦ä¸€ä¸ªè¯çŒœé”™è¿‡åï¼Œåé¢çš„æ‰€æœ‰ draft tokens æˆ‘ä»¬éƒ½è®¤ä¸ºæ˜¯é”™è¯¯çš„ï¼Œæ‰€ä»¥ç›´æ¥å¿½ç•¥æ‰
  
  è™½ç„¶æœ€åä¸€ä¸ªè¯æ²¡æœ‰çŒœå¯¹ï¼Œä½†æ˜¯ç”±äº `decoding` è¿™ä¸ªè¯æ˜¯çŒœå¯¹çš„ï¼Œé‚£ä¹ˆç”± base model é¢„æµ‹å¾—åˆ°çš„ `well?` å°±æ˜¯æ­£ç¡®çš„ next tokenã€‚æ­£æ˜¯è¿™ä¸ªæ€§è´¨ï¼Œä¿è¯äº†æŠ•æœºé‡‡æ ·çš„ä¸‹é™å°±æ˜¯ï¼š**ä¸€å®šè·å¾—ä¸€ä¸ªæ­£ç¡®çš„ next token**ã€‚è¿™ç§æƒ…å†µæˆ‘ç”¨ä¸‹å›¾è¡¨ç¤º
  
  <img src="EAGLE Speculative Decoding/image-20250329002706795.png" alt="image-20250329002706795" style="zoom:67%;" />
  
  å¯ä»¥çœ‹åˆ°ï¼Œå³ä½¿ draft tokens ç”Ÿæˆçš„æ˜¯ garbage å¯¼è‡´ä¸€ä¸ªéƒ½å¯¹ä¸ä¸Šã€‚ä½†ç”±äº `learn` è¿™ä¸ªè¯æ˜¯ initial tokenï¼Œç”± base model æ­£å¸¸ç”Ÿæˆï¼Œæ‰€ä»¥ `eagle` è¿™ä¸ªè¯ä¸€å®šæ˜¯æ­£ç¡®çš„ next token
  
  æ³¨æ„ï¼šåœ¨å®Œæˆäº† verify è¿‡åï¼Œæˆ‘ä»¬éœ€è¦å°†æ­£ç¡®çš„ tokens è¿›è¡Œæ¥æ”¶ï¼Œé”™è¯¯çš„ tokens è¿›è¡Œåˆ é™¤ã€‚è¿™é‡Œä¸»è¦æ˜¯å¯¹ KV Cache è¿›è¡Œæ“ä½œï¼Œå°†é”™è¯¯çš„ KV Cache è¿›è¡Œåˆ é™¤ï¼Œä¿ç•™æ­£ç¡® tokens çš„ KV Cache
  
  æœ€åï¼Œç”Ÿæˆè¿˜æ²¡æœ‰ç»“æŸï¼Œå› ä¸ºæˆ‘ä»¬ç°åœ¨è·å¾—çš„æœ€æ–°çš„ next token æ˜¯ `well?`ï¼Œè¿˜æ²¡æœ‰é‡åˆ° `<endoftext>`ï¼Œæ‰€ä»¥ç»§ç»­è¿›è¡Œä¸‹ä¸€è½®çš„æŠ•æœºé‡‡æ ·ï¼š
  
  1. å°† initial token (`well?` in this case) è¾“å…¥åˆ° draft model å½“ä¸­ï¼Œç”Ÿæˆ draft tokens
  2. å°† initial token & draft tokens è¾“å…¥åˆ° base model ä¸­ï¼Œç”Ÿæˆ base model é¢„æµ‹çš„ next token
  3. å°† base model é¢„æµ‹çš„ next token å’Œ draft tokens è¿›è¡Œå¯¹æ¯”éªŒè¯
  4. å¦‚æœæ²¡æœ‰å‡ºç° `<endoftext>` å›åˆ° Step1
  
  <img src="EAGLE Speculative Decoding/image-20250328235339912.png" alt="image-20250328235339912" style="zoom:80%;" />

- Extend to sampling situations

  åœ¨ä¸Šé¢çš„è®¨è®ºä¸­ï¼Œæˆ‘ä»¬åˆ©ç”¨äº† base model çš„å‰å‘è¾“å‡ºå»éªŒè¯ draft tokens çš„æ­£ç¡®æ€§ï¼Œå®Œæˆè¿™ä¸€æ“ä½œæœ‰ä¸€ä¸ªéšè—æ¡ä»¶ï¼šbase model & draft model åœ¨é¢„æµ‹ next token çš„æ—¶å€™æ˜¯ç¡®å®šæ€§çš„ï¼Œç”¨ä¸“ä¸šæœ¯è¯­æ¥è¯´å°±æ˜¯ï¼štemperature ä¸º 0ã€‚å¦‚æœè¿™ä¸ªæ¡ä»¶æ— æ³•æ»¡è¶³ï¼Œé‚£ä¹ˆä¸Šè¿°çš„é”™ä½å¯¹æ¯”æ˜¯æ²¡æœ‰æ„ä¹‰çš„ï¼ˆæ— æ³•å¯¹æ¯”ä¸ç¡®å®šçš„ä¸œè¥¿ï¼‰ã€‚`temperature = 0` åœ¨å…·ä½“å®ç°ä¸­å°±æ˜¯ç›´æ¥ä½¿ç”¨ `argmax(probability)` æ¥å®Œæˆå¯¹ token çš„é€‰å–

  åœ¨ `temperature != 0` çš„æƒ…å†µä¸‹ï¼Œæˆ‘ä»¬å°±éœ€è¦é€šè¿‡é‡‡æ ·æ¥è·å¾— next tokenã€‚æ­¤æ—¶ draft token & base model è¾“å‡ºå˜ä¸ºä¸ç¡®å®šæ€§çš„ï¼Œä½†æˆ‘ä»¬ä»ç„¶å¯ä»¥éªŒè¯æ‰€ç”Ÿæˆçš„ draft token åˆ†å¸ƒæ˜¯å¦ç¬¦åˆ base model åº”è¯¥ç”Ÿæˆçš„ token åˆ†å¸ƒã€‚æ¥ä¸‹æ¥å°±éœ€è¦åšä¸‹æ¦‚ç‡è®ºäº†ğŸ¤”

  å®šä¹‰ï¼šdraft token é¢„æµ‹ next token `x` çš„åˆ†å¸ƒä¸º `q(x)`ï¼Œè€Œ base model é¢„æµ‹ next token `x` çš„åˆ†å¸ƒä¸º `p(x)`

  ç›®æ ‡ï¼šä»åˆ†å¸ƒ `q(x)` å‡ºå‘ï¼Œæœ€ç»ˆè·å¾—åˆ†å¸ƒ `p(x)`

  ç®—æ³•ï¼šä¸‹å›¾æ¥è‡ªäº EAGLE-3 paperï¼Œæè¿°äº†å¤š token çš„æŠ•æœºé‡‡æ ·ç®—æ³•ã€‚å…¶æ ¸å¿ƒæ€æƒ³æ˜¯ï¼šå…ˆä» `q(x)` åˆ†å¸ƒä¸­é‡‡æ ·ï¼Œä»¥ä¸€å®šæ¦‚ç‡å»æ¥æ”¶é‡‡æ ·åˆ°çš„ `x`ï¼Œå¦‚æœ `x` è¢«æ‹’ç»ï¼Œåˆ™åœ¨ä¸€ä¸ªæ–°åˆ†å¸ƒé‡æ–°é‡‡æ ·ä¸€ä¸ª `x`ã€‚è¯¥è¿‡ç¨‹é‡‡æ ·è·å¾—çš„ `x` åœ¨æ•°å­¦ä¸Šç­‰ä»·äºç›´æ¥ä» `p(x)` ä¸­ç›´æ¥é‡‡æ ·

  <img src="EAGLE Speculative Decoding/image-20250330223102475.png" alt="image-20250330223102475"  />

  æˆ‘å°†ä¸Šå›¾çš„ç®—æ³•æŠ½è±¡ä¸º python ä¼ªä»£ç ï¼Œå¹¶åªè€ƒè™‘ single round

  ```python
  def speculative_sampling(p, q):
      x = sample_from_distribution(q)
      ratio = p(x) / q(x)
  
      r = uniform(0, 1)
      if r < ratio: # accept the x according to ratio
          return x
      if r >= ratio: # reject x, resample from a new distribution
          new_p = lambda x: (p(x) - min(p(x), q(x))) / sum([p(x) - min(p(x), q(x)) for x in sample_space])
          new_x = sample_from_distribution(new_p)
          return new_x
  ```

  è¯¥é‡‡æ ·è¿‡ç¨‹çš„æ­£ç¡®æ€§åœ¨ä¸‹é¢çš„ section ç»™å‡ºã€‚ç°åœ¨æˆ‘ä»¬é‡æ–°æ¥å®¡è§†æŠ•æœºé‡‡æ ·å’Œä¹‹å‰çš„ verify è¿‡ç¨‹ï¼šå·¦ä¾§å³ä¸ºå½“å‰è®¨è®ºçš„æŠ•æœºé‡‡æ ·ï¼Œè€Œå³ä¾§å³ä¸ºç®€å•çš„ verify è¿‡ç¨‹

  <img src="EAGLE Speculative Decoding/image-20250330232028249.png" alt="image-20250330232028249" style="zoom:80%;" />

  å¯ä»¥çœ‹åˆ°å·¦ä¾§ï¼Œ base model æ²¡æœ‰ç”Ÿæˆ tokenï¼Œè€Œæ˜¯ç”Ÿæˆçš„å¯¹åº”çš„æ¦‚ç‡åˆ†å¸ƒï¼Œæˆ‘ä»¬å°†åˆ©ç”¨è¿™ä¸ªæ¦‚ç‡åˆ†å¸ƒ `p(x)`ï¼Œæ¥å’Œå¯¹åº”çš„ draft token åˆ†å¸ƒ `q(x)` è¿›è¡ŒæŠ•æœºé‡‡æ ·ã€‚ä¹‹å‰çš„ verify è¿‡ç¨‹ï¼Œå˜ä¸ºäº†ç°åœ¨çš„æ˜¯å¦æ¥æ”¶é‡‡æ ·ç»“æœï¼š

  1. è‹¥æ¥æ”¶å½“å‰ draft tokenï¼Œåˆ™ç»§ç»­éªŒè¯ä¸‹ä¸€ä¸ª draft token
  2. è‹¥æ‹’ç»å½“å‰ draft tokenï¼Œåˆ™ç”¨æ–°åˆ†å¸ƒé‡æ–°é‡‡æ ·ï¼Œç”Ÿæˆä¸€ä¸ªæ–°çš„ tokenï¼Œåœ¨æ­¤ä¹‹åæ‰€æœ‰çš„ draft token å…¨éƒ¨èˆå¼ƒ

- Proof the correctness of speculative sampling

  æŒ‰ç…§ä¸Šè¿°æ–¹æ³•é‡‡æ ·äº§ç”Ÿçš„ `x` åœ¨æ•°å­¦ä¸Šæ˜¯ç­‰ä»·äº `p(x)` çš„ã€‚è¯æ˜æ¥è‡ªæŠ•æœºé‡‡æ ·è®ºæ–‡ [Fast Inference from Transformers via Speculative Decoding](https://openreview.net/pdf?id=C9NEblP8vS)

<img src="EAGLE Speculative Decoding/image-20250330224150492.png" alt="image-20250330224150492" style="zoom:80%;" />

ä¸Šè¿°è¯æ˜ä¸­ï¼Œæ²¡æœ‰æåˆ° $\beta$ çš„å®šä¹‰ï¼Œåœ¨è®ºæ–‡ä¸­å®šä¹‰ä¸ºï¼šé‡‡æ ·ç»“æœè¢«æ¥æ”¶çš„æ¦‚ç‡ã€‚é‡‡æ ·ç»“æœè¢«æ¥æ”¶çš„æ¦‚ç‡æ˜¯ä¸€ä¸ªæœŸæœ›å€¼ï¼Œå¦‚ä¸‹

<img src="EAGLE Speculative Decoding/image-20250330224536397.png" alt="image-20250330224536397" style="zoom: 80%;" />

æˆ‘å†ç¿»è¯‘ä¸€ä¸‹è¿™ä¸ªæœŸæœ›ï¼š

1. å½“ `q(x) <= p(x)` æ—¶ï¼Œé‡‡æ ·ç»“æœä¸€å®šä¼šè¢«æ¥æ”¶ï¼Œæ¦‚ç‡ä¸º 1
2. å½“ `q(x) > p(x)` æ—¶ï¼Œé‡‡æ ·ç»“æœä»¥æ¦‚ç‡ `p(x) / q(x)` æ¥æ”¶

## EAGLE-1

ç¬¬ä¸€ç« èŠ‚çš„æŠ•æœºé‡‡æ ·åŸç†æ˜¯â€œç¥â€ï¼Œè€Œå…¶ä»–çš„æ–¹æ³•éƒ½æ˜¯â€œå½¢â€ã€‚å¯¹äº EAGLE æ¥è¯´ï¼Œå…¶ç‰¹è‰²å°±æ˜¯åœ¨ draft tokens ç”Ÿæˆè¿‡ç¨‹ä¸­ï¼ŒåŠ å…¥äº† `hidden_states` ä½œä¸ºé¢å¤–çš„ä¿¡æ¯ï¼Œæ¥å¸®åŠ© draft model æ›´å¥½çŒœæµ‹ã€‚

<img src="EAGLE Speculative Decoding/image-20250330235637826.png" alt="image-20250330235637826" style="zoom:80%;" />

NOTE: ä¸Šå›¾ä¸­çœç•¥äº† draft model çš„ prefill è¿‡ç¨‹ï¼Œå®é™…ä¸Šä¼šä½¿ç”¨ base model ä¸­çš„ input tokens & hidden states å®Œæˆ prefill

EAGLE åˆ©ç”¨ initial token embedding + å¯¹åº”çš„ `hidden_states` ä½œä¸ºè¾“å…¥ï¼Œä½¿ç”¨ä¸€ä¸ª linear å±‚æ¥èåˆè¿™ä¸¤ä¸ª featureï¼Œå¹¶ç”¨å…¶è¿›è¡Œè‡ªå›å½’æ¨ç†

```python
def eagle_decode(init_token,
                 input_hidden_states,
                 embed,
                 fc,
                 draft_model_transformer, 
                 lm_head, 
                 draft_len):
    """
    Args:
    	- init_token: initial token, (1,)
    	- input_hidden_states: the hidden_states which produce the initial token (1, C)
    	- embed: token embedding map
    	- fc: linear to fuse embedding & hidden_states (2C, C)
    	- draft_model_transformer: transformer blocks
    Return:
    	- draft_tokens, (draft_len + 1,)
    """
    next_token = init_token
    draft_tokens = [init_token]
    
    for i in range(draft_len):
        # get input feat
        input_embed = embed(next_token)	# (1, C)
        input_feat = fc(torch.concat([input_embed, input_hidden_states], dim=-1)) # (1, C)
        
        # get hidden states
        last_hidden_states = draft_model_transformer(input_feat)
        
        # get logits
        logits = lm_head(last_hidden_states) # (1, vocab_size)
        
        # sample
        next_token = sample(logits)
        
        draft_tokens.append(next_token)
        
	return draft_tokens
```

ä¹‹åå°±æ˜¯ verify draft tokensï¼Œå¹¶åˆ é™¤ base model ä¸­å½•å…¥çš„é”™è¯¯ kv cache

NOTE: å¯¹äº draft model kv cache éœ€è¦æ¸…é™¤æ‰ç”± draft model hidden states äº§ç”Ÿçš„ kv cacheï¼Œé‡æ–°ç”¨ base model hidden states ç”Ÿæˆæ–°çš„ kv cacheã€‚è¿™ä¸ªæŠ€å·§åœ¨ EAGLE ä»£ç é‡Œå«åš stable kvï¼Œç¡®ä¿åœ¨ decode ä¹‹å‰ï¼Œdraft model ä¸­çš„ kv cache å…¨éƒ¨ç”± base model hidden states ç”Ÿæˆï¼Œè¿™ä¸º EAGLE-3 åŸ‹ä¸‹äº†ä¼ç¬”

## EAGLE-1 Tree

## EAGLE-2 Tree

## EAGLE-3 Train

## Question

- å¦‚ä½•è¿›è¡Œ batched speculative samplingï¼Ÿ

  æŒ‘æˆ˜åœ¨äºæ¯ä¸€ä¸ª sequence éƒ½æœ‰è‡ªå·±çš„ accept lengthï¼Œä»è€Œå¯¼è‡´æ— æ³•è¿›è¡Œæœ‰æ•ˆåœ° batch decode

  æ–¹æ¡ˆä¸€ï¼šæ•´ä¸ª batch åŒæ­¥ä¸ºæœ€å°çš„ accept-lengthã€‚è¿™æ ·å°±èƒ½å¤Ÿä»ç„¶åŒæ­¥æ•´ä¸ª batch ä»ç„¶å¢åŠ ç›¸åŒçš„ tokenï¼ŒæŒç»­è¿›è¡Œ batch decode

  æ–¹æ¡ˆäºŒï¼šä¹Ÿè®¸å€Ÿé‰´ continous batching æ‰æ˜¯æœ€ç»ˆçš„è§£å†³æ–¹æ¡ˆï¼Ÿæ—¢ç„¶ continous batching èƒ½å¤Ÿè§£å†³ä¸åŒ sequence length çš„ batch decodeï¼Œé‚£ä¹ˆè¿™ç§æƒ…å†µæ”¾åˆ°æŠ•æœºé‡‡æ ·ä¸Šåº”è¯¥æ˜¯æœ€ä¼˜è§£ï¼šæ¯ä¸€ä¸ª sequence éƒ½å„è‡ªæ¥æ”¶è‡ªå·±æ­£ç¡®çš„æŠ•æœº tokensï¼Œç„¶åå†å¼€å§‹ä¸‹ä¸€æ¬¡ decodeã€‚ä¸‹å›¾å‚è€ƒè‡ª [blog](https://friendli.ai/blog/llm-iteration-batching) & [zhihu](https://zhuanlan.zhihu.com/p/680123256)

  <img src="EAGLE Speculative Decoding/v2-8092ac7d9ffc1eea2d2782d9a946b79e_b.webp" alt="åŠ¨å›¾" style="zoom: 80%;" />

## Concept

- EAGLE Model

  EAGLE model å®é™…ä¸Šå°±æ˜¯ä¸€ä¸ªå•å±‚çš„ LLMï¼Œsingle layer transformerï¼Œè¿™æ„å‘³ç€ EAGLE æœ‰æ‰€æœ‰ LLAMA æ¨¡å‹çš„åŠŸèƒ½ï¼ŒåŒ…æ‹¬ kv cache, rope ç­‰ç­‰ï¼Œå”¯ä¸€ä¸€ç‚¹ä¸åŒçš„æ˜¯ï¼šä¸ºäº†æ”¯æŒ tree attentionï¼Œåœ¨è®¡ç®— attention çš„æ—¶å€™åŠ å…¥äº† tree mask

  é™¤æ­¤ä¹‹å¤– EAGLE è¿˜æœ‰ä¸€ä¸ª linear layer ç”¨äºå°† `2 * hidden_size` é™ç»´åˆ° `hidden_size`

- Forward path of EAGLE

  EAGLE ä½¿ç”¨äº†ä¸¤ä¸ªç‰¹å¾ï¼š`hidden_states & input_ids` æ¥é¢„æµ‹ next hidden statesã€‚å…¶ä¸­ `input_ids` å’Œ `hidden_states` æœ‰ç€ä¸€ä¸ª token çš„åç§»

  <img src="EAGLE Speculative Decoding/image-20240813111345556.png" alt="image-20240813111345556" style="zoom:50%;" />

  ```python
  def forward(self, 
              hidden_states, 
              input_ids,
              tree_mask,
              position_ids = None, 
              past_key_values = None)ï¼š
  	"""
  	Args:
  		- hidden_states: (B, N, C) N input tokens's hidden states
  		- input_ids: (B, N), N next token ids
  		- tree_mask: (1, 1, N, M), N is input tokens, M is past input tree tokens
  		- position_ids: (B, N)
  		- past_key_values: Tuple of k and v states, (B, N', C)
  	"""
      inputs_embeds = self.embed_tokens(input_ids)	# (B, N, C)
      inputs_feat = torch.cat((inputs_embeds, hidden_states), dim=-1)
      hidden_states = self.fc(inputs_feat)	# (B, N, C)
      
      attn_mask = self.prepare_attn_mask(inputs_embeds, past_key_values, tree_mask)
      layer_outputs, past_kv_values = self.layer(hidden_states, attn_mask, position_ids, past_key_value)
      
      return layer_outputs, past_kv_values
  ```

- Draft tokens to generate tree prediction

  æ•´ä¸ªè¿‡ç¨‹éƒ½å†™åœ¨äº† `Model.topK_generate`

- Build tree mask

- Logit processor

## Layout

- Reranking is less important

- EAGLE1 vs EAGLE2

- EAGLE2 does not support batch inference right now, because the tree attention mask between different batch is not the same

  But EAGLE1 uses fix tree structure, so it supports batch inference, and it can increase 2x throughput at low batch size, because EAGLE is helpful at memory bound, when it becomse compute bound, it would not be so helpful 

- EAGLE1

## Question

- mask index is the same as the draft_parents?

  No

- åœ¨ä½¿ç”¨ logits_processor çš„æ—¶å€™å¦‚ä½•å¤„ç†å¤šä¸ª token input ä½¿å¾—å¾—åˆ°çš„ç»“æœå’Œ auto regressive ä¸€è‡´ï¼Ÿ

  éªŒè¯è¿‡ç¨‹å¾—ç”¨ä¸€ä¸ª for å¾ªç¯æ¥éªŒè¯ï¼Œé€ä¸ªéªŒè¯å³å¯ä¿è¯ç»“æœå’Œ auto regressive ä¸€è‡´