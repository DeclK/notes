# Speculative Decoding

[Fast Inference from Transformers via Speculative Decoding](https://arxiv.org/abs/2211.17192)

[Medusa](https://github.com/FasterDecoding/Medusa)

## Concept

### Speculative decoding

- Observations

  > At the heart of our approach lie the observations that **(1) hard language-modeling tasks often include easier subtasks that can be approximated well by more efficient models, and (2) using speculative execution and a novel sampling method, we can make exact decoding from the large models faster**

- Speculative execution

  > Speculative execution (Burton, 1985; Hennessy & Patterson, 2012) is an optimization technique, common in processors, where a task is performed in parallel to verifying if itâ€™s actually needed

- speculative sampling

  > maximize the probability of these speculative tasks to be accepted, while guaranteeing that the outputs from our system have the same distribution as those from the target model alone. 

  é‡‡æ ·ç®—æ³•ï¼š

  1. å…ˆæ ¹æ®å°æ¨¡å‹åˆ†å¸ƒé‡‡æ · $x\sim p(x)$â€‹
  2. å¦‚æœé‡‡æ ·ç»“æœ $q(x)\le p(x)$ åˆ™æ¥å—é‡‡æ ·ç»“æœï¼Œåä¹‹åˆ™ä»¥ $1-\frac{p(x)}{q(x)}$ çš„æ¦‚ç‡æ‹’ç»é‡‡æ ·ç»“æœ
  3. æ‹’ç»é‡‡æ ·ç»“æœåä»¥æ–°æ¦‚ç‡ $p'(x)=norm(max(0,p(x)-q(x)))$ é‡æ–°è¿›è¡Œé‡‡æ ·

  ä»¥è¿™æ ·çš„é‡‡æ ·ç®—æ³•ï¼Œèƒ½å¤Ÿä¿è¯ç»“æœç­‰ä»·äºä½¿ç”¨ $p(x)$ åˆ†å¸ƒè¿›è¡Œé‡‡æ ·

- Problem Statement

  åŸå§‹æ¨¡å‹ $M_p$ï¼Œå°æ¨¡å‹ $M_q$

  next token distribution $p(x_t|x_{<t})$ï¼Œå…¶ä¸­ $x_{<t}$ ä»£è¡¨å‰ç¼€ï¼Œå³å‰ t-1 ä¸ª tokens

  æ ¸å¿ƒæ€æƒ³å°±æ˜¯è¦ä½¿ç”¨å°æ¨¡å‹ç”Ÿæˆ $\gamma$ ä¸ª completions (tokens)ï¼Œç„¶åä½¿ç”¨å¤§æ¨¡å‹å»è¯„ä¼°è¿™ $\gamma$ ä¸ª tokens æ˜¯å¦ä¸ºå¯æ¥å—çš„ï¼Œè¿™ä¸ªè¯„ä¼°è¿‡ç¨‹æ˜¯å¹¶è¡ŒåŒ–çš„ï¼Œæ‰€ä»¥åœ¨ä¸€å®šç¨‹åº¦ä¸Šè§£å†³äº† memory bound é—®é¢˜ï¼ˆåŸæ¥æ˜¯å•ä¸ª token å¤„ç†ï¼‰ã€‚æœ€åå¯»æ‰¾è¢«åŸå§‹æ¨¡å‹æ¥å—çš„æœ€å¤§å‰ç¼€è¯ï¼Œåœ¨ä¸æ¥å—å¤„çš„ token ä½ç½®ï¼Œé‡æ–°ç”¨åŸå§‹æ¨¡å‹ç”Ÿæˆä¸€ä¸ªæ–°çš„ token ä»è€Œä¿®æ­£å°æ¨¡å‹çš„é¢„æµ‹ï¼Œå¦‚æ­¤å¾ªç¯ï¼Œä»¥è¾¾åˆ°åŠ é€Ÿç›®çš„

- è®ºæ–‡è®¡ç®—äº†ç†è®ºæ¥å—ç‡
  $$
  \alpha = E(min(p, q))
  $$
  è¿™é‡Œ E ä¸ºæœŸæœ›

- åœ¨ç»™å®šäº†å¤§å°æ¨¡å‹çš„è®¡ç®—é‡æ¯” $c$ï¼Œä»¥åŠæ¥å—ç‡ $\alpha$ï¼Œå¯ä»¥è·å¾—æœ€ä¼˜çš„ç”Ÿæˆ $\gamma$ æ•°é‡ï¼Œä½†å®é™…åº”ç”¨ä¸­è¿˜æ˜¯é å®éªŒå¤šä¸€äº›ï¼Œå› ä¸ºæ¥å—ç‡ä¸å¥½è¡¡é‡

  <img src="Speculative Decoding/image-20240401203528761.png" alt="image-20240401203528761" style="zoom: 67%;" />

### Medusa

- Medusa ä½¿ç”¨çš„æ˜¯ auxiliary head æ¥æ›¿ä»£ä¸Šè¿°æ–¹æ¡ˆä¸­çš„å°æ¨¡å‹ã€‚

- ä½¿ç”¨ Tree-Attention æ¥åŒæ—¶å¤„ç†å¤šä¸ª continuationsï¼Œä½†è¿™æ ·æ‰€å¸¦æ¥çš„é—®é¢˜æ˜¯ï¼šéšç€ head çš„å¢é•¿ï¼ŒTree çš„æ•°é‡ä¼šæŒ‡æ•°å¢åŠ ï¼Œattention mask ä¼šå˜å¾—éå¸¸ç¨€ç–ï¼Œè¿™ä¸ä¼šå¼•èµ·é—®é¢˜å—ï¼Ÿ
  $$
  \text{number of continuations}=\sum_{k=1}^{K}\prod_{i=1}^{k}s_i
  $$
  å…¶ä¸­ $s_i$ ä»£è¡¨çš„æ˜¯ç¬¬ i ä¸ªå¤´å°†é€‰æ‹© top-$s_i$ ä¸ªé¢„æµ‹ç»“æœ

- éœ€è¦ä½¿ç”¨ calibration dataset æ¥å¯¹æ ‘ç»“æ„è¿›è¡Œç­›é€‰ï¼Œè¿™ä¸ªæ ‘ç»“æ„åœ¨æ¨ç†è¿‡ç¨‹ä¸­æ˜¯ç¡®å®šçš„

- Run the notebook of `medusa_introduction`

  - Initial inferecne with Medusa Head

    å½“ç»™å®š prompt

    ```python
    prompt = "A chat between a curious user and an artificial intelligence assistant. The assistant gives helpful, detailed, and polite answers to the user's questions. USER: Hi, could you share a tale about a charming llama that grows Medusa-like hair and starts its own coffee shop? ASSISTANT:"
    ```

    æˆ‘ä»¬ä¼šè·å¾—å¦‚ä¸‹ç»“æœ
    
    <table border="1">
    <thead>
        <tr>
            <th> </th>
            <th>Model's head</th>
            <th>Medusa head 1</th>
            <th>Medusa head 2</th>
            <th>Medusa head 3</th>
            <th>Medusa head 4</th>
        </tr>
    </thead>
    <tbody>
        <tr>
            <th> Prediction </th>
            <td>'Once'<br>&#9989</td>
            <td>'upon'<br>&#10067</td>
            <td>'ly'<br>&#10067</td>
            <td>'time'<br>&#10067</td>
            <td>','<br>&#10067</td>
        </tr>
    </tbody>
    </table>
    å…¶ä¸­ `Once` æ˜¯ç”±æ¨¡å‹æœ¬èº«æ¨ç†å‡ºçš„ next tokenï¼Œè€Œå‰©ä½™çš„å…¶ä»–è¯ä¸º Medusa head æ¨ç†å‡ºçš„ç»“æœã€‚è¿™é‡Œä¸ºäº†ç†è§£åšäº†ä¸€äº›ç®€åŒ–ï¼šæ¯ä¸€ä¸ª Medusa head åªè¾“å‡ºäº†ä¸€ä¸ªè¯ï¼Œä½†å®é™…ä¸Šæ¯ä¸€ä¸ª head å¯ä»¥è¾“å‡ºå¤šä¸ªè¯
    
    å°†è¿™äº›é¢„æµ‹ç»“æœ `Once upon ly time ,` è¾“å…¥åˆ°å¤§æ¨¡å‹ä¸­è¿›è¡ŒéªŒè¯
    
    <table border="1">
        <thead>
            <tr>
                <th>Input</th>
                <td>'Once'</td>
                <td>'upon'</td>
                <td>'ly'</td>
                <td>'time'</td>
                <td>','</td>
            </tr>
        </thead>
        <tbody>
            <tr>
                <th>Model output</th>
                <td>'upon'<br>&#9989</td>
                <td>'a'<br>&#9989</td>
                <td>'a'<br>&#x274C</td>
                <td>','<br>&#x274C</td>
                <td>'in'<br>&#x274C</td>
            </tr>
        </tbody>
    </table>
    
    æ­£å¸¸çš„ LLM è¾“å‡ºç»“æœæ˜¯ä¸€ä¸ª shifted resultsï¼Œmodel output ä¸ºä¸‹ä¸€ä¸ª inputã€‚æŒ‰ç…§è¿™æ ·çš„éªŒè¯æ–¹å¼ï¼Œæˆ‘ä»¬å¯ä»¥çŸ¥é“ï¼šï¼ˆåœ¨ greedy sample ä¸‹ï¼Œæ¸©åº¦ä¸º0ï¼‰å¦‚æœ model input ä¸ä¸ºä¸Šä¸€ä¸ª outputï¼Œé‚£å°±è¯´æ˜è¿™ä¸ªç”Ÿæˆçš„ input ä¸ç¬¦åˆæ¨¡å‹çš„æ¨ç†ç»“æœï¼Œæˆ‘ä»¬å°±ä½¿ç”¨ âŒ æ¥è¡¨ç¤º
    
    å¯ä»¥çœ‹åˆ°æˆ‘ä»¬çš„ upon æ˜¯æ¨ç†æ­£ç¡®çš„ç»“æœï¼æ­å–œğŸ‰ï¼è¯´æ˜æˆ‘ä»¬èµ·ç æœ‰ä¸€ä¸ªè¯çŒœå¯¹äº†ï¼Œå¹¶ä¸”æˆ‘ä»¬è¿˜è·å¾—äº† upon çš„ä¸‹ä¸€ä¸ªè¯ aï¼Œå› ä¸ºè¿™ä¹Ÿæ˜¯ç”±å¤§æ¨¡å‹æœ¬èº«æ¨ç†å¾—åˆ°çš„
    
    æˆ‘ä»¬é€šè¿‡ä¸€æ¬¡éªŒè¯ï¼Œè·å¾—äº†ä¸¤ä¸ªæ–°è¯ï¼Œè¿™å°±æ˜¯åŠ é€Ÿçš„åŸç†ã€‚å¤šçš„ä¸€ä¸ªè¯å°±æ˜¯ç”± Medusa head çŒœæµ‹å¾—åˆ°ã€‚åŠæ—¶æˆ‘ä»¬ä¸€ä¸ªè¯éƒ½æ²¡æœ‰çŒœå¯¹ï¼Œæˆ‘ä»¬ä¹Ÿèƒ½é€šè¿‡éªŒè¯è·å¾—ä¸€ä¸ªæ–°è¯ï¼Œè¿™ä¹Ÿä¿è¯äº†æ¨ç†èƒ½å¤ŸæŒç»­å‘å‰æ¨è¿› 
    
    ä»æ•´ä¸ªæ¨ç†è¿‡ç¨‹æ¥çœ‹ï¼Œæˆ‘ä»¬è¿è¡Œäº†ä¸¤æ¬¡å¤§æ¨¡å‹ï¼š
    
    1. è·å¾—ç¬¬ä¸€ä¸ªè¯ `Once`
    2. éªŒè¯ Medusa head ç»“æœ
    
    è€Œæˆ‘ä»¬æœ€ç»ˆç”Ÿæˆäº†3ä¸ªè¯ï¼š`Once upon a`ï¼Œæ­¤æ—¶åŠ é€Ÿæ¯”å°±ä¸º 1.5 å€
    
    ä¸ºäº†è¿›ä¸€æ­¥ç†Ÿæ‚‰è¿™ä¸ªè¿‡ç¨‹ï¼Œæˆ‘ä»¬ç»§ç»­ä½¿ç”¨ 4 ä¸ª Medusa head ç»§ç»­æ¨ç† next 4 tokensï¼Œå¹¶è¿›è¡ŒéªŒè¯
    
    <table border="1">
        <thead>
            <tr>
                <th>Input</th>
                <td>'a'</td>
                <td>'time'</td>
                <td>','</td>
                <td>'there'</td>
                <td>'a'</td>
            </tr>
        </thead>
        <tbody>
            <tr>
                <th>Model output</th>
                <td>'time'<br>&#9989</td>
                <td>','<br>&#9989</td>
                <td>'in'<br>&#9989</td>
                <td>'was'<br>&#x274C</td>
                <td>'ll'<br>&#x274C</td>
            </tr>
        </tbody>
    </table>
    
    å¯ä»¥çœ‹åˆ°è¿™æ¬¡çŒœå¯¹äº†ä¸¤ä¸ªè¯ `time` å’Œ `,`ï¼Œç®—ä¸ŠéªŒè¯è·å¾—çš„æ–°è¯ï¼Œæ€»å…±è·å¾—äº† 3 ä¸ªè¯
    
    æ­¤æ—¶æˆ‘ä»¬ä¸€å…±æ¨ç†äº†3æ¬¡å¤§æ¨¡å‹ï¼Œè·å¾—äº† 6 ä¸ªè¯ï¼ŒåŠ é€Ÿæ¯”ä¸º 2 å€
  
- Tree Attention

  Tree attention çš„ç›®çš„æ˜¯ä¸ºäº†ä¸€æ¬¡å¤„ç†å¤šä¸ªçŒœæµ‹ç»“æœï¼Œä¸æ­£å¸¸ attention çš„åŒºåˆ«ä»…ä»…æ˜¯ attention mask ä¸ä¸€æ ·ã€‚Tree attention mask ä½¿å¾—æ¨¡å‹å‰å‘åªæ³¨æ„è‡ªå·±å¥å­ä¸­çš„ tokenï¼Œå³è‡ªå·±è·¯å¾„ä¸Šçš„ token
  
  <img src="Speculative Decoding/image-20240412100032683.png" alt="image-20240412100032683" style="zoom:50%;" />
  
- Code Implementation

  Medusa çš„ä»£ç å®ç°å’ŒåŸç†æ˜¯ç­‰ä»·çš„ï¼Œä½†æ˜¯ç¨å¾®å˜æ¢äº†ä¸€ä¸‹ Medusa head å‰å‘çš„ä½ç½®ï¼šMedusa head å‰å‘æ˜¯ç´§è·Ÿåœ¨å¤§æ¨¡å‹å‰å‘ä¹‹åçš„ï¼Œæ¯ä¸€æ¬¡ `model.forward` éƒ½ä¼šå¾—åˆ° medusa logits & normal logits ä¸¤ä¸ªéƒ¨åˆ† 
  
  - introduction of medusa choices
  
    å‡è®¾ medusa æœ‰ 4 ä¸ª headï¼Œæ¯ä¸€ä¸ª head éƒ½å°†å¯¹ next $i^{th}$ token (i~[1, 4]) è¿›è¡Œé¢„æµ‹ã€‚æˆ‘ä»¬éœ€è¦æ¯ä¸ª head ä¸­æŒ‘é€‰ä¸€äº› tokenï¼Œå¹¶ç”¨è¿™äº› token æ¥ç»„æˆå¤šä¸ªå¥å­ï¼Œä»è€Œæé«˜å‘½ä¸­æ¦‚ç‡ï¼ˆç›¸æ¯”å•ä¸ªå¥å­æ¥è¯´ï¼‰
  
    medusa æ„é€ äº†ä¸€ä¸ª medusa choices æ¥ä»è¿™äº›é¢„æµ‹ä¸­ç»„åˆå‡ºæ›´æœ‰å¯èƒ½é¢„æµ‹æˆåŠŸçš„å¥å­ã€‚è¿™ä¸ª medusa choices æœ¬è´¨ä¸Šå°±æ˜¯ä¸€ä¸ªæ ‘ï¼Œæ ‘ä¸­çš„æ¯ä¸€ä¸ªèŠ‚ç‚¹ä»£è¡¨ä¸€ä¸ª tokenï¼Œç›¸åŒå±‚çš„ token ç”±ç›¸åŒ head é¢„æµ‹ã€‚æ¯ä¸€ä¸ªå¶èŠ‚ç‚¹ä»£è¡¨äº†ä¸€æ¡è·¯å¾„ï¼Œè¯¥è·¯å¾„å°±æ˜¯æˆ‘ä»¬ç»„åˆå‡ºæ¥çš„å¥å­
  
    ```python
    medusa_choices = [[0], [0, 0], [1], [0, 1], [2], [0, 0, 0], [1, 0], [0, 2], [3], [0, 3], [4], [0, 4], [2, 0], [0, 5], [0, 0, 1], [5], [0, 6], [6], [0, 7], [0, 1, 0], [1, 1], [7], [0, 8], [0, 0, 2], [3, 0], [0, 9], [8], [9], [1, 0, 0], [0, 2, 0], [1, 2], [0, 0, 3], [4, 0], [2, 1], [0, 0, 4], [0, 0, 5], [0, 0, 0, 0], [0, 1, 1], [0, 0, 6], [0, 3, 0], [5, 0], [1, 3], [0, 0, 7], [0, 0, 8], [0, 0, 9], [6, 0], [0, 4, 0], [1, 4], [7, 0], [0, 1, 2], [2, 0, 0], [3, 1], [2, 2], [8, 0], [0, 5, 0], [1, 5], [1, 0, 1], [0, 2, 1], [9, 0], [0, 6, 0], [0, 0, 0, 1], [1, 6], [0, 7, 0]]
    ```
  
    
  
    ![image-20240412101529902](Speculative Decoding/image-20240412101529902.png)
  
    æ”¾å¤§æ¥çœ‹ä¸‹è¿™ä¸ªæ ‘é‡Œé¢çš„æ ‡è¯†
  
    <img src="Speculative Decoding/image-20240412101654581.png" alt="image-20240412101654581" style="zoom: 67%;" />
  
    æ¯ä¸€ä¸ªæ ‘èŠ‚ç‚¹ç”±ä¸€ä¸ª tuple è¡¨ç¤ºï¼Œtuple ä¸­çš„å†…å®¹ä»£è¡¨ç€è¯¥èŠ‚ç‚¹çš„è·¯å¾„ï¼Œä»¥ä¸‰ä¸ªèŠ‚ç‚¹ä¸ºä¾‹ç®€å•è¯´æ˜ï¼š
  
    1. `(x,)` è¯¥èŠ‚ç‚¹çš„ token ä¸ºç¬¬ 1 ä¸ª head æ¦‚ç‡ç¬¬ x çš„ tokenï¼Œå…¶çˆ¶èŠ‚ç‚¹ä¸º rootï¼Œroot ä¸ºæ¨¡å‹ä¹‹å‰æ‰€å¾—çš„æœ€åä¸€ä¸ª token
    2. `(x, y)` è¯¥èŠ‚ç‚¹çš„ token ä¸ºç¬¬ 2 ä¸ª head æ¦‚ç‡ç¬¬ y çš„ tokenï¼Œå…¶çˆ¶èŠ‚ç‚¹ä¸º `(x,)`
    3. `(x, y, z)` è¯¥èŠ‚ç‚¹çš„ token ä¸ºç¬¬ 3 ä¸ª head æ¦‚ç‡ç¬¬ z çš„ tokenï¼Œå…¶çˆ¶èŠ‚ç‚¹ä¸º `(x, y)`
  
  - medusa buffer
  
    medusa buffer æ˜¯ç”± medusa choices ç”Ÿæˆçš„ä¸€ä¸ªå­—å…¸ï¼š
  
    - `medusa_attn_mask`ï¼Œshape `(1, 1, N, N)`ï¼Œå…¶ä¸­ `N = num_tree_nodes + 1`ï¼ŒåŠ  1 ä¸ºæ ¹èŠ‚ç‚¹ï¼Œ`num_tree_nodes = len(medusa_choices)`
  
    - `tree_indices`ï¼Œshape `(N,)`ï¼Œç”¨äºåœ¨ candidates ä¸­è·å¾— tree node
  
      ```python
      # candidates (1 + num_heads *topk,)
      tree_candidates = candidates[tree_indices]	#(N,)
      
      # tree_indices look like this
      tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
              18, 19, 20, 11, 12, 13, 14, 15, 16, 17, 11, 12, 13, 11, 12, 11, 11, 11,
              11, 11, 11, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 21, 22, 23, 21, 22,
              21, 21, 21, 21, 21, 21, 22, 21, 31, 32])
      ```
  
    - `medusa_position_ids`ï¼Œshape `(N,)`ï¼Œç”¨äºæ ‡è®°å„ä¸ª token çš„ä½ç½®ï¼Œåœ¨ä¹‹åçš„ä½ç½®ç¼–ç å°†æ ¹æ®è¿™ä¸ª id è®¡ç®—
  
      ```python
      tensor([0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,
              2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3,
              3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 4, 4])
      ```
  
    - `retrieve_indices`, shape `(leave_nodes_num, num_medusa_heads)`ï¼Œç”¨äºåœ¨ `tree_candidates` ä¸­è·å¾—å¤šä¸ªå¥å­
  
      ```python
      cart_candidates = tree_candidates_ext[retrieve_indices]
      
      # retrieve_indices look like this
      tensor([[ 0,  1, 11, 39, 63],
              [ 0,  1, 11, 39, 62],
              [ 0,  3, 28, 61, -1],
              [ 0,  2, 21, 60, -1],
              [ 0,  2, 21, 59, -1],
              ...
      ```
  
      `tree_candidates_ext` åœ¨ `tree_candidates` æœ«å°¾ append äº†ä¸€ä¸ª0ï¼Œä½œä¸º padding index æ‰€å–çš„ tree candidates
  
      ç¬¬ä¸€ä¸ª index æ°¸è¿œéƒ½æ˜¯0ï¼Œå› ä¸ºæ˜¯æ ¹èŠ‚ç‚¹ï¼Œä¹Ÿå°±æ˜¯ model logits æ‰€é¢„æµ‹çš„ next token

- Medusa forward pseudo code

  å‡è®¾æˆ‘ä»¬æœ‰ 4 ä¸ª medusa head

  ```python
  model				# medusa model
  input_ids 			# (1, N), N tokens
  medusa_choices 		# a list of tuple, length is 63
  temperature = 0. 	# we only discuss greedy decoding
  
  medusa_buffers = generate_medusa_buffers(medusa_choises)
  
  medusa_buffers.attention_mask		# (1, 1, 64, 64)
  medusa_buffers.tree_indices			# (64,)
  medusa_buffers.medusa_position_ids	# (64,)
  medusa_buffers.retrieve_indices		# (42, 5)
  
  # move buffers to model
  model.medusa_buffers = medusa_buffers
  model.medusa_choices = medusa_choices
  
  # initialze past key values (kv-cache)
  past_key_values,
  past_key_values_data,
  current_length_data = initialzie_past_key_values(model)
  
  # set medusa mask to None
  model.base_model.model.medusa_mask = None
  
  # pre-fill, also the first inference
  # medusa_logits (5, 1, N, 32000)
  # logits (1, N, 32000)
  medusa_logits, logits = model(input_ids, past_key_values)
  
  # set back medusa mask
  model.base_model.model.medusa_mask = medusa_buffers.attention_mask
  
  # ------------- LOOP -----------------#
  # generate candidates
  # candidates (42, 5)
  # tree_candidates (1, 64)
  candidates, tree_candidates = generate_candidates(medusa_logits, logits, medusa_buffers)
  
  #### how to create candidates ###
  candidate_ori = torch.argmax(logits[:, -1]).unsqueeze(0)	# (1,)
  candidates_medusa = torch.topk(medusa_logits[:, 0, -1], TOPK, dim = -1).indices	# (4, topK=10)
  
  candidates = torch.cat([candidate_ori, candidate_medusa.view(-1)], dim=-1)		# (1 + 4 *topK)
  
  tree_candidates = candidates[tree_inidces]	# (64,)
  tree_candidates_with_zero = torch.cat([tree_candidates, torch.zeros((1), dtype=torch.long,)], dim=0)
  
  candidates = tree_candidates_with_zero[retrieve_indices] # (42, 5)
  ##################################
  
  # use tree decoding, just forward
  medusa_logits, logits = model(tree_candidates, past_key_values, position_ids)
  # restore to tree
  medusa_logits = medusa_logits[:, 0, retrieve_indices]
  logits = logits[0, retrieve_indices]
  # medusa_logits (5, 42, 5, 32000)
  # (42, 5, 32000)
  
  # evaluate, get the longest match (best candidates)
  posterior_mask = (candidates[:, 1:] == torch.argmax(logits[:, :-1], dim=-1)).int()
  candidates_accept_length = (torch.cumprod(posterior_mask dim=1)).sum(dim=1)
  accept_length = candidates_accept_length.max()
  # best candidates
  best_candidate = torch.argmax(candidates_accept_length).to(torch.long)
  
  # update the input to restart the loop
  candi = candidates[None, best_candidatt, : accecpt_length + 1]
  input_ids = torch.cat([input_ids, candi], dim=-1)
  logits = logits[None, best_candidate, accept_length : accept_length + 1]
  medusa_logits = medusa_logits[:, None, best_candidate, accept_length : accept_length + 1]
  # logits (1, 1, 32000)
  # medusa_logits (5, 1, 1, 32000)
  ```

  

  

  model forward pseudo code

  ```python
  def forward(input_ids, past_key_values, position_ids):
      # attn mask is used in attention, not passed here
      hidden_states = self.base_model.model(input_ids, past_key_values)
      
      medusa_logits = []
      for i in range(self.medusa):
      	medusa_logits.append(self.medusa_head[i](hidden_states))
  	medusa_logits = torch.stack(medusa_logits, dim=0)
      
      logits = orig = self.base_model.lm_head(hidden_states)
      
      return medusa_logits, logits
  ```

  

  

### EAGLE

- LookAHead
- EAGLE å¯¹ä¹‹å‰çš„ Speculative decoding æœ‰ä¸€ä¸ªç²¾å¦™çš„å›¾æ€»ç»“

## Question

- ä½¿ç”¨å¤§æ¨¡å‹è¿›è¡ŒéªŒè¯ä»¥åŠç”Ÿæˆæ–° token åº”è¯¥åªä½¿ç”¨äº†å•è¯å‰å‘