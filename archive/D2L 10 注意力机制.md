---
title: D2L 10 æ³¨æ„åŠ›æœºåˆ¶
tag:
  - Dive into deep learning
categories:
  - è¯¾ç¨‹
  - Dive into deep learning
mathjax: true
abbrlink: b7d04b34
date: 2021-12-15 00:00:00
---

# D2L 10 æ³¨æ„åŠ›æœºåˆ¶

555ç»ˆäºå¯ä»¥å¼€å§‹çœ‹æ³¨æ„åŠ›æœºåˆ¶äº†ğŸ˜†Transformer æˆ‘æ¥å•¦ï¼

## æ³¨æ„åŠ›æç¤º

### ç”Ÿç‰©å­¦ä¸­çš„æ³¨æ„åŠ›æç¤º

ä¸»è¦æœ‰ä¸¤ä¸ªæ¦‚å¿µï¼š

1. **éè‡ªä¸»æ€§æç¤º/ééšæ„çº¿ç´¢**ï¼ˆnon-volitional cueï¼‰ï¼ŒåŸºäºç¯å¢ƒä¸­ç‰©ä½“çš„çªå‡ºæ€§å’Œæ˜“è§æ€§
2. **è‡ªä¸»æ€§æç¤º/éšæ„çº¿ç´¢**ï¼ˆvolitional cueï¼‰ï¼Œå—ä¸»è§‚æ„æ„¿æ¨åŠ¨

### æŸ¥è¯¢ã€é”®å’Œå€¼

æ•™æå¯¹äºè¿™ä¸‰ä¸ªæ¦‚å¿µçš„è§£é‡Šå¹¶ä¸æ¸…æ™°ï¼Œè¿˜æ˜¯çœ‹æ²ç¥çš„è®²è§£å§ [bilibili](https://www.bilibili.com/video/BV1264y1i7R1?p=1&t=447)

å·ç§¯ã€å…¨è¿æ¥ã€æ± åŒ–å±‚éƒ½åªè€ƒè™‘ä¸éšæ„çº¿ç´¢ï¼Œæ³¨æ„åŠ›æœºåˆ¶åˆ™æ˜¾å¼åœ°è€ƒè™‘éšæ„çº¿ç´¢ï¼š

1. éšæ„çº¿ç´¢è¢«ç§°ä¹‹ä¸ºæŸ¥è¯¢ï¼ˆqueryï¼‰
2. æ¯ä¸ª**è¾“å…¥**æ˜¯ä¸€ä¸ªé”®å€¼å¯¹ (key, value)ï¼Œå…¶ä¸­ key å¯è§†ä¸ºééšæ„çº¿ç´¢ï¼Œï¼ˆä¸‹é¢è¿™å¥æ˜¯æˆ‘è‡ªå·±ä¹±æƒ³çš„ï¼‰value å¯ä»¥è§†ä¸ºè¯¥çº¿ç´¢çš„ç›¸å…³å±æ€§
3. é€šè¿‡æ³¨æ„åŠ›æ± åŒ–å±‚æ¥æœ‰åå‘æ€§çš„é€‰æ‹©æŸäº›è¾“å…¥

### éå‚æ•°æ³¨æ„åŠ›æ±‡èšï¼šNadaraya-Watson æ ¸å›å½’

å®é™…ä¸Šä¸€ä¸ªæ•°å­¦è¡¨è¾¾çš„ä¾‹å­èƒ½å¤Ÿæ›´æ¸…æ¥šå±•ç¤ºè¿™ä¸‰ä¸ªæ¦‚å¿µã€‚ç»™å®šæ•°æ® $(x_i, y_i), i=1,...,n$

ç»™å®šæŸ¥è¯¢ $x$ï¼Œå¹³å‡æ± åŒ–å°†è·å¾—è¾“å‡º
$$
f(x) = \frac{1}{n}\sum_{i}{y_i}
$$
è¿™å°±æ˜¯æ²¡æœ‰æ³¨æ„åŠ›æœºåˆ¶çš„æƒ…å†µï¼Œä¸æŸ¥è¯¢å€¼æ— å…³ï¼Œå…¨å‡­ééšæ„çº¿ç´¢è·å¾—è¾“å‡ºã€‚è€Œæ›´å¥½çš„æ–¹æ¡ˆæ˜¯60å¹´ä»£æå‡ºæ¥çš„ Nadaraya-Waston æ ¸å›å½’
$$
f(x)=\sum_{i=1}^{n} \frac{K\left(x-x_{i}\right)}{\sum_{j=1}^{n} K\left(x-x_{j}\right)} y_{i}
$$
å…¶ä¸­ K å¯ä»¥çœ‹ä½œä¸€ä¸ªæ ¸å‡½æ•°ï¼Œä¾‹å¦‚ä¸€ä¸ªé«˜æ–¯æ ¸ï¼Œç”¨äºè¡¡é‡ä¸¤ç‚¹ä¹‹é—´çš„è·ç¦»
$$
K(u)=\frac{1}{\sqrt{2 \pi}} \exp \left(-\frac{u^{2}}{2}\right)
$$
è¿™å°±å°†æ³¨æ„åŠ›æœºåˆ¶æ˜¾å¼åœ°ç”¨äºè¾“å‡ºï¼Œä¹Ÿå°±æ˜¯ç»™å„ä¸ª value åŠ å…¥ç›¸å…³æƒé‡ã€‚ç°åœ¨å†æ¥çœ‹è¿™ä¸ªå›¾ç¤ºå¯èƒ½ä¼šæ›´å¥½

<img src="D2L 10 æ³¨æ„åŠ›æœºåˆ¶/image-20211210215054690.png" style="zoom:80%;" />

### å¸¦å‚æ•°æ³¨æ„åŠ›æ±‡èš

éå‚æ•°çš„Nadaraya-Watsonæ ¸å›å½’å…·æœ‰ä¸€è‡´æ€§ï¼ˆconsistencyï¼‰çš„ä¼˜ç‚¹ï¼šå¦‚æœæœ‰è¶³å¤Ÿçš„æ•°æ®ï¼Œæ­¤æ¨¡å‹ä¼šæ”¶æ•›åˆ°æœ€ä¼˜ç»“æœã€‚å°½ç®¡å¦‚æ­¤ï¼Œæˆ‘ä»¬è¿˜æ˜¯å¯ä»¥è½»æ¾åœ°å°†å¯å­¦ä¹ çš„å‚æ•°é›†æˆåˆ°æ³¨æ„åŠ›æ±‡èšä¸­
$$
\begin{aligned}
f(x) &=\sum_{i=1}^{n} \alpha\left(x, x_{i}\right) y_{i} \\
&=\sum_{i=1}^{n} \frac{\exp \left(-\frac{1}{2}\left(\left(x-x_{i}\right) w\right)^{2}\right)}{\sum_{j=1}^{n} \exp \left(-\frac{1}{2}\left(\left(x-x_{j}\right) w\right)^{2}\right)} y_{i} \\
&=\sum_{i=1}^{n} \operatorname{softmax}\left(-\frac{1}{2}\left(\left(x-x_{i}\right) w\right)^{2}\right) y_{i} .
\end{aligned}
$$
æ³¨æ„è¿™é‡Œ $w$ åªæ˜¯ä¸€ä¸ªæ ‡é‡ï¼Œå¦‚æœ $w$ è¶Šå¤§è¯´æ˜è¶Šæ³¨æ„è¿‘è·ç¦»çš„é”®å€¼ã€‚è¿™é‡Œæä¸€ä¸‹ï¼Œä¸€ä¸ªè®­ç»ƒæ ·æœ¬çš„è¾“å…¥éƒ½ä¼šå’Œ**é™¤è‡ªå·±ä»¥å¤–**çš„æ‰€æœ‰è®­ç»ƒæ ·æœ¬çš„â€œé”®ï¼å€¼â€å¯¹è¿›è¡Œè®¡ç®—ï¼Œå¦‚æœåŠ å…¥è‡ªå·±çš„ key é‚£ä¹ˆè®­ç»ƒç»“æœå¯æƒ³è€ŒçŸ¥ï¼Œå°±æ˜¯ç»™è‡ªå·±çš„ key åŠ å…¥å¾ˆå¤§çš„æƒé‡

### æ³¨æ„åŠ›å¯è§†åŒ–

å¹³å‡æ± åŒ–å¯ä»¥è¢«è§†ä¸ºè¾“å…¥çš„åŠ æƒå¹³å‡å€¼ï¼Œåªæ˜¯æƒé‡ç›¸ç­‰ã€‚è€Œæ³¨æ„åŠ›æ± åŒ–åˆ™æ˜¯çœŸæ­£çš„åŠ æƒå¹³å‡ï¼Œå…¶ä¸­æƒé‡æ˜¯åœ¨ç»™å®šçš„æŸ¥è¯¢ query å’Œä¸åŒçš„é”® key ä¹‹é—´è®¡ç®—å¾—å‡ºçš„ã€‚æ•™æè¿™é‡Œå†™äº†ä¸€äº›ä»£ç ï¼Œåœ¨ä¹‹åç”¨äºæ³¨æ„åŠ›å¯è§†åŒ–ï¼Œä»¥æç»˜å›¾åƒ $weight = f(query, key)$ ï¼Œè¿™é‡Œç›´æ¥çœ‹çœ‹ä¸Šä¸€å°èŠ‚ä¸­çš„éå‚ N-W æ ¸å›å½’ï¼ˆå·¦ä¾§ï¼‰ & å¸¦å‚ N-W æ ¸å›å½’ï¼ˆå³ä¾§ï¼‰çš„å›¾åƒ

<img src="D2L 10 æ³¨æ„åŠ›æœºåˆ¶/image-20211212175647738.png" style="zoom:80%;" />

å¯ä»¥æ˜æ˜¾çœ‹åˆ°æ³¨æ„åŠ›æƒé‡åœ¨ $query = key$ çš„æ—¶å€™åŠ é‡äº†

## æ³¨æ„åŠ›è¯„åˆ†å‡½æ•°

æˆ‘ä»¬å¯ä»¥å°†ä¸Šä¸€èŠ‚ä¸­çš„é«˜æ–¯æ ¸æŒ‡æ•°éƒ¨åˆ†è§†ä¸ºæ³¨æ„åŠ›è¯„åˆ†å‡½æ•°ï¼ˆattention scoring functionï¼‰ï¼Œç®€ç§°è¯„åˆ†å‡½æ•°ï¼ˆscoring functionï¼‰ï¼Œç„¶åæŠŠè¿™ä¸ªå‡½æ•°çš„è¾“å‡ºç»“æœè¾“å…¥åˆ° softmax å‡½æ•°ä¸­è¿›è¡Œè¿ç®—ï¼ˆè¿™æ ·å°±èƒ½ä½¿è¯„åˆ†ä»¥æ¦‚ç‡åˆ†å¸ƒå½¢å¼å±•ç°ï¼Œæ¢å¥è¯è¯´å°±æ˜¯ä½¿æƒé‡çš„å’Œä¸ºä¸€ï¼‰

è®© score function è¡¨ç¤ºæ›´åŠ æ•°å­¦åŒ–
$$
\alpha\left(\mathbf{q}, \mathbf{k}_{i}\right)=\operatorname{softmax}\left(a\left(\mathbf{q}, \mathbf{k}_{i}\right)\right)=\frac{\exp \left(a\left(\mathbf{q}, \mathbf{k}_{i}\right)\right)}{\sum_{j=1}^{m} \exp \left(a\left(\mathbf{q}, \mathbf{k}_{j}\right)\right)} \in \mathbb{R}
$$
æ­¤æ—¶æ³¨æ„åŠ›æ±‡èšå‡½æ•° $f$ å°±è¢«è¡¨ç¤ºä¸º
$$
f\left(\mathbf{q},\left(\mathbf{k}_{1}, \mathbf{v}_{1}\right), \ldots,\left(\mathbf{k}_{m}, \mathbf{v}_{m}\right)\right)=\sum_{i=1}^{m} \alpha\left(\mathbf{q}, \mathbf{k}_{i}\right) \mathbf{v}_{i} \in \mathbb{R}^{v}
$$
åœ¨æœ¬èŠ‚ä¸­ï¼Œæˆ‘ä»¬å°†ä»‹ç»ä¸¤ä¸ªæµè¡Œçš„è¯„åˆ†å‡½æ•°ï¼Œç¨åå°†ç”¨ä»–ä»¬æ¥å®ç°æ›´å¤æ‚çš„æ³¨æ„åŠ›æœºåˆ¶

### æ©è”½ softmax æ“ä½œ

åœ¨æŸäº›æƒ…å†µä¸‹ï¼Œå¹¶éæ‰€æœ‰çš„ **key** éƒ½åº”è¯¥è¢«çº³å…¥åˆ°æ³¨æ„åŠ›æ±‡èšä¸­ã€‚ä¾‹å¦‚ï¼Œä¸ºäº†é«˜æ•ˆå¤„ç†å°æ‰¹é‡æ•°æ®é›†ï¼ŒæŸäº›æ–‡æœ¬åºåˆ—è¢«å¡«å……äº†æ²¡æœ‰æ„ä¹‰çš„ç‰¹æ®Šè¯å…ƒã€‚ä¸ºäº†ä»…å°†æœ‰æ„ä¹‰çš„è¯å…ƒä½œä¸ºå€¼æ¥è·å–æ³¨æ„åŠ›æ±‡èšï¼Œæˆ‘ä»¬å¯ä»¥æŒ‡å®šä¸€ä¸ªæœ‰æ•ˆåºåˆ—é•¿åº¦ï¼Œä»¥ä¾¿åœ¨è®¡ç®— softmax æ—¶è¿‡æ»¤æ‰è¶…å‡ºæŒ‡å®šèŒƒå›´çš„ä½ç½®

```python
def masked_softmax(X, valid_lens):
    """Perform softmax operation by masking elements on the last axis.
    Params:
        - X: 3D (B, N, M) tensor
        - valid_lens: 1D (B,) or 2D (B, N) tensor
        B for batch size, N for query nums, M for key & val nums
    """
    if valid_lens is None:
        return nn.functional.softmax(X, dim=-1)
    else:
        shape = X.shape
        if valid_lens.dim() == 1:
            valid_lens = torch.repeat_interleave(valid_lens, shape[1])  # (BxN)
        else:
            valid_lens = valid_lens.reshape(-1) # (BxN)
        # On the last axis, replace masked elements with a very large negative
        # value, whose exponentiation outputs 0
        X = d2l.sequence_mask(X.reshape(-1, shape[-1]), valid_lens,     # (BxN, M)
                              value=-1e6)
        return nn.functional.softmax(X.reshape(shape), dim=-1)
    
# å½“è¾“å…¥ mask ä¸ºä¸€ç»´æ—¶ï¼ŒåŒä¸€ä¸ª batch çš„ query ä½¿ç”¨ç›¸åŒçš„ mask
masked_softmax(torch.rand(2, 2, 4), torch.tensor([2, 3]))

# tensor([[[0.4527, 0.5473, 0.0000, 0.0000],
#          [0.3458, 0.6542, 0.0000, 0.0000]],

#         [[0.4151, 0.3528, 0.2321, 0.0000],
#          [0.2604, 0.2631, 0.4765, 0.0000]]])

# å½“è¾“å…¥ mask ä¸ºäºŒç»´æ—¶ï¼Œbatch å†…éƒ¨çš„ query ä¹Ÿå¯ä»¥æœ‰ä¸åŒçš„ mask
masked_softmax(torch.rand(2, 2, 4), torch.tensor([[2, 3], [1, 2]]))

# tensor([[[0.5879, 0.4121, 0.0000, 0.0000],
#          [0.2180, 0.3672, 0.4149, 0.0000]],

#         [[1.0000, 0.0000, 0.0000, 0.0000],
#          [0.5511, 0.4489, 0.0000, 0.0000]]])
```

### åŠ æ€§æ³¨æ„åŠ›

å½“æŸ¥è¯¢å’Œé”®æ˜¯ä¸åŒé•¿åº¦çš„çŸ¢é‡æ—¶ï¼Œ æˆ‘ä»¬å¯ä»¥ä½¿ç”¨åŠ æ€§æ³¨æ„åŠ›ï¼ˆadditive attentionï¼‰ä½œä¸ºè¯„åˆ†å‡½æ•°
$$
a(\mathbf{q}, \mathbf{k})=\mathbf{w}_{v}^{\top} \tanh \left(\mathbf{W}_{q} \mathbf{q}+\mathbf{W}_{k} \mathbf{k}\right) \in \mathbb{R}
$$
å…¶æ€æƒ³å°±æ˜¯å°†å…¶æŠ•å½±åˆ°ç›¸åŒçš„ç»´åº¦ä¸Šï¼Œè¿™æ ·å°±èƒ½è¿›è¡Œç›¸åŠ ï¼Œç„¶åå†è®¡ç®—å…¶æƒé‡ aã€‚ç”±äºå¹³æ—¶é‡åˆ°çš„ä¸å¤šï¼Œè¿™é‡Œå°±ä¸è¯¦ç»†è¯´äº†

###  ç¼©æ”¾ç‚¹ç§¯æ³¨æ„åŠ›

ä½¿ç”¨ç‚¹ç§¯å¯ä»¥å¾—åˆ°è®¡ç®—æ•ˆç‡æ›´é«˜çš„è¯„åˆ†å‡½æ•°ï¼Œä½†æ˜¯ç‚¹ç§¯æ“ä½œè¦æ±‚æŸ¥è¯¢å’Œé”®å…·æœ‰ç›¸åŒçš„é•¿åº¦ d

å‡è®¾æŸ¥è¯¢å’Œé”®çš„æ‰€æœ‰å…ƒç´ éƒ½æ˜¯ç‹¬ç«‹çš„éšæœºå˜é‡ï¼Œ å¹¶ä¸”éƒ½æ»¡è¶³é›¶å‡å€¼å’Œå•ä½æ–¹å·®ï¼Œ é‚£ä¹ˆä¸¤ä¸ªå‘é‡çš„ç‚¹ç§¯çš„å‡å€¼ä¸º0ï¼Œæ–¹å·®ä¸º dã€‚ä¸ºç¡®ä¿æ— è®ºå‘é‡é•¿åº¦å¦‚ä½•ï¼Œç‚¹ç§¯çš„æ–¹å·®åœ¨ä¸è€ƒè™‘å‘é‡é•¿åº¦çš„æƒ…å†µä¸‹ä»ç„¶æ˜¯1ï¼Œæˆ‘ä»¬å°†ç‚¹ç§¯é™¤ä»¥ $\sqrt d$
$$
a(\mathbf{q}, \mathbf{k})=\mathbf{q}^{\top} \mathbf{k} / \sqrt{d}
$$
æŸ¥è¯¢ $Q\in R^{n\times d}$ï¼Œé”® $K \in R^{m \times d}$ ï¼Œå€¼ $V \in R^{m \times v}$ çš„ç¼©æ”¾ç‚¹ç§¯æ³¨æ„åŠ›ï¼ˆscaled dot-product attentionï¼‰æ˜¯ï¼š
$$
\operatorname{softmax}\left(\frac{\mathbf{Q K}^{\top}}{\sqrt{d}}\right) \mathbf{V} \in \mathbb{R}^{n \times v}
$$
å®ƒçš„ä»£ç å°±ç›¸å¯¹ç®€å•ä¸€äº›

```python
#@save
class DotProductAttention(nn.Module):
    """ç¼©æ”¾ç‚¹ç§¯æ³¨æ„åŠ›"""
    def __init__(self, dropout, **kwargs):
        super(DotProductAttention, self).__init__(**kwargs)
        self.dropout = nn.Dropout(dropout)

    def forward(self, queries, keys, values, valid_lens=None):
        """
        queries:	(B, N, C)
        key:		(B, M, C)
        values:     (B, M, C)
        valid_lens: (B,) or (B, N)
        """
        d = queries.shape[-1]
        scores = torch.bmm(queries, keys.transpose(1,2)) / math.sqrt(d)
        self.attention_weights = masked_softmax(scores, valid_lens)
        return torch.bmm(self.dropout(self.attention_weights), values)
```

## Bahdanau æ³¨æ„åŠ›

ä¹‹å‰æ•™æè®¨è®ºäº†æœºå™¨ç¿»è¯‘é—®é¢˜ï¼šé€šè¿‡ç¼–ç å™¨-è§£ç å™¨æ¶æ„ï¼Œç”¨äºåºåˆ—åˆ°åºåˆ—å­¦ä¹ ã€‚å…·ä½“æ¥è¯´ï¼Œç¼–ç å™¨å°†é•¿åº¦å¯å˜çš„åºåˆ—è½¬æ¢ä¸ºå›ºå®šå½¢çŠ¶çš„ä¸Šä¸‹æ–‡å˜é‡ï¼Œç„¶åè§£ç å™¨æ ¹æ®ç”Ÿæˆçš„è¯å…ƒå’Œä¸Šä¸‹æ–‡å˜é‡æŒ‰è¯å…ƒç”Ÿæˆè¾“å‡ºï¼ˆç›®æ ‡ï¼‰åºåˆ—è¯å…ƒã€‚ç„¶è€Œï¼Œå³ä½¿å¹¶éæ‰€æœ‰è¾“å…¥ï¼ˆæºï¼‰è¯å…ƒéƒ½å¯¹è§£ç æŸä¸ªè¯å…ƒéƒ½æœ‰ç”¨ï¼Œä½†æˆ‘ä»¬åœ¨æ¯ä¸ªè§£ç æ­¥éª¤ä¸­ä»ä½¿ç”¨ç¼–ç ç›¸åŒçš„ä¸Šä¸‹æ–‡å˜é‡

æœ‰ä»€ä¹ˆæ–¹æ³•èƒ½åœ¨ä¸åŒè§£ç æ­¥éª¤ä¸­ï¼Œ**ä½¿ç”¨ä¸åŒçš„ä¸Šä¸‹æ–‡å˜é‡**å‘¢ï¼Ÿè¿™ä¸ªæ—¶å€™å¯ä»¥ç”¨ Bahdanau æ³¨æ„åŠ›æœºåˆ¶ï¼Œå…¶ä¸Šä¸‹æ–‡å˜é‡ä»»æ„è§£ç æ—¶é—´æ­¥ $t'$ ä¼šè¢«æ›¿æ¢ä¸º $c_{t'}$

$$
\mathbf{c}_{t^{\prime}}=\sum_{t=1}^{T} \alpha\left(\mathbf{s}_{t^{\prime}-1}, \mathbf{h}_{t}\right) \mathbf{h}_{t}
$$
å…¶ä¸­ï¼Œ$h_t$ ä¸º**ç¼–ç å™¨** t æ—¶é—´æ­¥çš„éšçŠ¶æ€ï¼Œå®ƒå³ä½¿ key åˆæ˜¯ valueï¼›$s_{t'-1}$ ä¸º**è§£ç å™¨** $t'-1$ æ—¶åˆ»æ­¥çš„éšçŠ¶æ€ï¼›æ³¨æ„åŠ›æƒé‡ $\alpha$ å¯ä»¥ç”¨ä»»æ„çš„æ³¨æ„åŠ›è¯„åˆ†å‡½æ•°è®¡ç®—

## å¤šå¤´æ³¨æ„åŠ›

å¤šå¤´æ³¨æ„åŠ›è¿™ä¸€éƒ¨åˆ†çš„è§†é¢‘è®²è§£æ˜¯åœ¨ Transformer ä¸­è¿›è¡Œçš„ [bilibili](https://www.bilibili.com/video/BV1Kq4y1H7FL?p=1&t=1256)

åœ¨å®è·µä¸­ï¼Œå½“ç»™å®šç›¸åŒçš„æŸ¥è¯¢ã€é”®å’Œå€¼çš„é›†åˆæ—¶ï¼Œ æˆ‘ä»¬å¸Œæœ›æ¨¡å‹å¯ä»¥**åŸºäºç›¸åŒçš„æ³¨æ„åŠ›æœºåˆ¶å­¦ä¹ åˆ°ä¸åŒçš„è¡Œä¸º**ï¼Œç„¶åå°†ä¸åŒçš„è¡Œä¸ºä½œä¸ºçŸ¥è¯†ç»„åˆèµ·æ¥ï¼Œæ•è·åºåˆ—å†…å„ç§èŒƒå›´çš„ä¾èµ–å…³ç³»ï¼ˆä¾‹å¦‚ï¼ŒçŸ­è·ç¦»ä¾èµ–å’Œé•¿è·ç¦»ä¾èµ–å…³ç³»ï¼‰

å¯¹äºå…¶ä¸­ä¸€ä¸ªå¤´ $i$ çš„æ“ä½œç®€è¿°å¦‚ä¸‹ï¼šæ˜¯å¯¹ query, key, value å…ˆä½¿ç”¨å…¨è¿æ¥å±‚è¿›è¡Œç»´åº¦è½¬æ¢ï¼Œè½¬æ¢åˆ°ä¸€ä¸ªç›¸åŒçš„ç»´åº¦ $p_v$ï¼Œç„¶åå†ä½¿ç”¨ç¼©æ”¾ç‚¹ç§¯æ³¨æ„åŠ›ã€‚æ¯ä¸€ä¸ªå¤´éƒ½å°†è¿›è¡Œè¿™æ ·çš„æ“ä½œï¼Œå‡è®¾æœ‰ $m$ ä¸ªå¤´ï¼Œé‚£ä¹ˆå°±ä¼šå¾—åˆ° $m$ ä¸ªæ³¨æ„åŠ›æ±‡èšè¾“å‡º $h_i, i=1,...,m$ï¼Œæœ€åå°†æ‰€æœ‰çš„ $h_i$ è¿æ¥èµ·æ¥ï¼Œä½¿ç”¨ä¸€ä¸ªå…¨è¿æ¥å±‚è¿›è¡Œç‰¹å¾ç»„åˆå¾—åˆ°æœ€ç»ˆçš„è¾“å‡ºï¼Œæ•°å­¦å½¢å¼å¦‚ä¸‹ï¼š
$$
\mathbf{h}_{i}=f\left(\mathbf{W}_{i}^{(q)} \mathbf{q}, \mathbf{W}_{i}^{(k)} \mathbf{k}, \mathbf{W}_{i}^{(v)} \mathbf{v}\right) \in \mathbb{R}^{p_{v}}
\\
\mathbf{W}_{o}\left[\begin{array}{c}
\mathbf{h}_{1} \\
\vdots \\
\mathbf{h}_{h}
\end{array}\right] \in \mathbb{R}^{p_{o}}
$$
è¿™é‡Œ $W_0$ æ˜¯ä¸€ä¸ª $p_0 \times p_0$ çš„çŸ©é˜µï¼Œ$p_0 = \text{number of heads} \times p_v$ï¼Œå›¾ç¤ºå¦‚ä¸‹

<img src="D2L 10 æ³¨æ„åŠ›æœºåˆ¶/image-20211213235228429.png" style="zoom:80%;" />

åœ¨ä½¿ç”¨ä»£ç å®ç°çš„æ—¶å€™å‘ç°ï¼Œå¯ä»¥æŠŠ `num_heads` ä¸ª $W_{i}q$ ä½¿ç”¨ä¸€ä¸ªå¤§çš„ $W_q$ ä»£æ›¿ï¼Œç„¶åå°†ç‰¹å¾é€šè¿‡ reshape åˆ†æˆ `num_heads` ä¸ªå³å¯ã€‚è¿™æ ·å¯ä»¥å°†å¤šå¤´å¹¶è¡Œå¤„ç†ï¼Œå¯ä»¥ç†è§£ä¸º batch å˜ä¸º `num_heads` å€åçš„æ³¨æ„åŠ› $(B\times \text{num heads}, N, C)$ ã€‚åšå®Œå¤šå¤´æ³¨æ„åŠ›è¿‡ååˆ reshape å›å»å°±è¡Œå•¦

```python
#@save
class MultiHeadAttention(nn.Module):
    """å¤šå¤´æ³¨æ„åŠ›"""
    def __init__(self, key_size, query_size, value_size, num_hiddens,
                 num_heads, dropout, bias=False, **kwargs):
        super(MultiHeadAttention, self).__init__(**kwargs)
        self.num_heads = num_heads
        self.attention = d2l.DotProductAttention(dropout)
        self.W_q = nn.Linear(query_size, num_hiddens, bias=bias)
        self.W_k = nn.Linear(key_size, num_hiddens, bias=bias)
        self.W_v = nn.Linear(value_size, num_hiddens, bias=bias)
        self.W_o = nn.Linear(num_hiddens, num_hiddens, bias=bias)

    def forward(self, queries, keys, values, valid_lens):
        queries = transpose_qkv(self.W_q(queries), self.num_heads)
        keys = transpose_qkv(self.W_k(keys), self.num_heads)
        values = transpose_qkv(self.W_v(values), self.num_heads)

        if valid_lens is not None:
            # åœ¨è½´0ï¼Œå°†ç¬¬ä¸€é¡¹ï¼ˆæ ‡é‡æˆ–è€…çŸ¢é‡ï¼‰å¤åˆ¶num_headsæ¬¡
            valid_lens = torch.repeat_interleave(
                valid_lens, repeats=self.num_heads, dim=0)

        # outputçš„å½¢çŠ¶:(batch_size*num_headsï¼Œnum_query,
        # num_hiddens/num_heads)
        output = self.attention(queries, keys, values, valid_lens)

        output_concat = transpose_output(output, self.num_heads)
        return self.W_o(output_concat)

#@save
def transpose_qkv(X, num_heads):
    """ä¸ºäº†å¤šæ³¨æ„åŠ›å¤´çš„å¹¶è¡Œè®¡ç®—è€Œå˜æ¢å½¢çŠ¶"""
    X = X.reshape(X.shape[0], X.shape[1], num_heads, -1)

    X = X.permute(0, 2, 1, 3)

    # æœ€ç»ˆè¾“å‡ºçš„å½¢çŠ¶:(batch_size*num_heads, num_query or num_keys,
    # num_hiddens/num_heads)
    return X.reshape(-1, X.shape[2], X.shape[3])


#@save
def transpose_output(X, num_heads):
    """é€†è½¬transpose_qkvå‡½æ•°çš„æ“ä½œ"""
    X = X.reshape(-1, num_heads, X.shape[1], X.shape[2])
    X = X.permute(0, 2, 1, 3)
    return X.reshape(X.shape[0], X.shape[1], -1)
```

## è‡ªæ³¨æ„åŠ›å’Œä½ç½®ç¼–ç 

åœ¨æ·±åº¦å­¦ä¹ ä¸­ï¼Œæˆ‘ä»¬ç»å¸¸ä½¿ç”¨å·ç§¯ç¥ç»ç½‘ç»œï¼ˆCNNï¼‰æˆ–å¾ªç¯ç¥ç»ç½‘ç»œï¼ˆRNNï¼‰å¯¹åºåˆ—è¿›è¡Œç¼–ç ã€‚æƒ³è±¡ä¸€ä¸‹ï¼Œæœ‰äº†æ³¨æ„åŠ›æœºåˆ¶ä¹‹åï¼Œæˆ‘ä»¬å°†è¯å…ƒåºåˆ—è¾“å…¥æ³¨æ„åŠ›æ± åŒ–å±‚ä¸­ï¼ŒåŒä¸€ç»„è¯å…ƒåŒæ—¶å……å½“æŸ¥è¯¢ã€é”®å’Œå€¼ã€‚æ¯ä¸ªæŸ¥è¯¢éƒ½ä¼šå…³æ³¨æ‰€æœ‰çš„é”®ï¼å€¼å¯¹å¹¶ç”Ÿæˆä¸€ä¸ªæ³¨æ„åŠ›è¾“å‡ºã€‚ç”±äºæŸ¥è¯¢ã€é”®å’Œå€¼æ¥è‡ªåŒä¸€ç»„è¾“å…¥ï¼Œå› æ­¤è¢«ç§°ä¸º è‡ªæ³¨æ„åŠ›ï¼ˆself-attentionï¼‰åœ¨æœ¬èŠ‚ä¸­ï¼Œæˆ‘ä»¬å°†ä½¿ç”¨è‡ªæ³¨æ„åŠ›è¿›è¡Œåºåˆ—ç¼–ç ï¼Œä»¥åŠå¦‚ä½•ä½¿ç”¨åºåˆ—çš„é¡ºåºä½œä¸ºè¡¥å……ä¿¡æ¯

### è‡ªæ³¨æ„åŠ›

ç»™å®šä¸€ä¸ªç”±è¯å…ƒç»„æˆçš„è¾“å…¥åºåˆ—ï¼Œå…¶ä¸­ä»»æ„ $x_i \in R^ d$ã€‚è¯¥åºåˆ—çš„è‡ªæ³¨æ„åŠ›è¾“å‡ºä¸ºä¸€ä¸ªé•¿åº¦ç›¸åŒçš„åºåˆ—ï¼š
$$
\mathbf{y}_{i}=f\left(\mathbf{x}_{i},\left(\mathbf{x}_{1}, \mathbf{x}_{1}\right), \ldots,\left(\mathbf{x}_{n}, \mathbf{x}_{n}\right)\right) \in \mathbb{R}^{d}
$$

### æ¯”è¾ƒå·ç§¯ç¥ç»ç½‘ç»œã€å¾ªç¯ç¥ç»ç½‘ç»œå’Œè‡ªæ³¨æ„åŠ›

ä¸‹å›¾ä¸ºä¸‰è€…è®¡ç®—çš„å›¾ç¤º

<img src="D2L 10 æ³¨æ„åŠ›æœºåˆ¶/image-20211213171227551.png" style="zoom:80%;" />

ç°åœ¨è®©æˆ‘ä»¬æ¯”è¾ƒè¿™ä¸‰ä¸ªæ¶æ„ï¼Œç›®æ ‡éƒ½æ˜¯å°†ç”± n ä¸ªè¯å…ƒç»„æˆçš„åºåˆ—æ˜ å°„åˆ°å¦ä¸€ä¸ªé•¿åº¦ç›¸ç­‰çš„åºåˆ—ï¼Œå…¶ä¸­çš„æ¯ä¸ªè¾“å…¥è¯å…ƒæˆ–è¾“å‡ºè¯å…ƒéƒ½ç”± d ç»´å‘é‡è¡¨ç¤ºã€‚å…·ä½“æ¥è¯´ï¼Œæˆ‘ä»¬å°†æ¯”è¾ƒçš„æ˜¯å·ç§¯ç¥ç»ç½‘ç»œã€å¾ªç¯ç¥ç»ç½‘ç»œå’Œè‡ªæ³¨æ„åŠ›è¿™å‡ ä¸ªæ¶æ„çš„è®¡ç®—å¤æ‚æ€§ã€é¡ºåºæ“ä½œå’Œæœ€å¤§è·¯å¾„é•¿åº¦ã€‚è¯·æ³¨æ„ï¼Œ**é¡ºåºæ“ä½œä¼šå¦¨ç¢å¹¶è¡Œè®¡ç®—ï¼Œè€Œä»»æ„çš„åºåˆ—ä½ç½®ç»„åˆä¹‹é—´çš„è·¯å¾„è¶ŠçŸ­ï¼Œåˆ™èƒ½æ›´è½»æ¾åœ°å­¦ä¹ åºåˆ—ä¸­çš„è¿œè·ç¦»ä¾èµ–å…³ç³»**

ä¸‹é¢è¿™ä¸ªè¡¨ä¾ç„¶æ¥è‡ªäºæ²ç¥è§†é¢‘ [bilibili](https://www.bilibili.com/video/BV19o4y1m7mo)ï¼Œéå¸¸æ¸…æ™°åœ°å¯¹æ¯”äº†ä¸‰è€…çš„å…³ç³»ï¼Œå…¶ä¸­ k æ˜¯ä¸€ç»´å·ç§¯æ ¸çš„ kernel size

<img src="D2L 10 æ³¨æ„åŠ›æœºåˆ¶/image-20211213172102475.png" style="zoom: 50%;" />

ç¨å¾®è§£é‡Šä¸€ä¸‹ï¼š

1. æœ€é•¿è·¯å¾„ä¸­çš„è·¯å¾„ä¸ºï¼šä¸¤ä¸ªè¯å…ƒè¿›è¡Œä¿¡æ¯ä¼ é€’çš„è®¡ç®—æ¬¡æ•°
2. å¾ªç¯ç¥ç»ç½‘ç»œçš„éšçŠ¶æ€æ—¶ï¼Œ dÃ—d æƒé‡çŸ©é˜µå’Œ d ç»´éšçŠ¶æ€çš„ä¹˜æ³•è®¡ç®—å¤æ‚åº¦ä¸º $O(d^2)$
3. åœ¨è‡ªæ³¨æ„åŠ›ä¸­ï¼ŒæŸ¥è¯¢ã€é”®å’Œå€¼éƒ½æ˜¯ nÃ—d çŸ©é˜µã€‚ å¹¶ä¸”ä½¿ç”¨ç¼©æ”¾ç‚¹ç§¯æ³¨æ„åŠ›ï¼Œæ•…è‡ªæ³¨æ„åŠ›è®¡ç®—å¤æ‚åº¦ä¸º $O(n^2d)$ï¼Œå¹¶ä¸”ç”±äºä½¿ç”¨çš„æ˜¯çŸ©é˜µä¹˜æ³•ï¼Œè€ŒçŸ©é˜µä¹˜æ³•çš„å¹¶è¡Œåº¦ä¸º $O(n)$

æ€»è€Œè¨€ä¹‹ï¼Œå·ç§¯ç¥ç»ç½‘ç»œå’Œè‡ªæ³¨æ„åŠ›éƒ½æ‹¥æœ‰å¹¶è¡Œè®¡ç®—çš„ä¼˜åŠ¿ï¼Œè€Œä¸”è‡ªæ³¨æ„åŠ›çš„æœ€å¤§è·¯å¾„é•¿åº¦æœ€çŸ­ã€‚ä½†æ˜¯å› ä¸ºå…¶è®¡ç®—å¤æ‚åº¦æ˜¯å…³äºåºåˆ—é•¿åº¦çš„äºŒæ¬¡æ–¹ï¼Œæ‰€ä»¥åœ¨å¾ˆé•¿çš„åºåˆ—ä¸­è®¡ç®—ä¼šéå¸¸æ…¢

### ä½ç½®ç¼–ç 

ä¸åŒäº CNN å’Œ RNNï¼Œä»¥ä¸Šå¾—åˆ°çš„è‡ªæ³¨æ„åŠ›è®¡ç®—ç»“æœæ˜¯ä¸åŒ…å«ä½ç½®ï¼ˆé¡ºåºï¼‰ä¿¡æ¯çš„ã€‚ä¹Ÿå°±æ˜¯è¯´æ¢ä¸ªè¾“å…¥é¡ºåºï¼Œå¾—åˆ°çš„ç»“æœè¿˜æ˜¯é‚£äº›ç»“æœï¼Œè¿™æ˜¾ç„¶ä¸æ˜¯æˆ‘ä»¬æƒ³è¦çš„ï¼Œæ¥ä¸‹æ¥ï¼Œæˆ‘ä»¬æè¿°çš„æ˜¯åŸºäºæ­£å¼¦å‡½æ•°å’Œä½™å¼¦å‡½æ•°çš„å›ºå®šä½ç½®ç¼–ç ï¼ˆä¸å¾—ä¸åæ§½ä¸€ä¸‹è¿™ä¸ªç¼–ç çœŸçš„ç•¥å¾®æŠ½è±¡

ä»¥ä¸‹æ˜¯æˆ‘çš„ä¸ªäººç†è§£ï¼šå¯¹äºä¸€ä¸ªåºåˆ— `range(n)`ï¼Œæˆ‘éœ€è¦ä½¿ç”¨ d ä¸ªç»´åº¦å¯¹å…¶ä½ç½®è¿›è¡Œç¼–ç ï¼Œé‡‡å–å¦‚ä¸‹ç¼–ç å½¢å¼ï¼Œ $p_{i,j}$ å³æ˜¯ç¬¬ i ä¸ªä½ç½®çš„ç¬¬ j ä¸ªç»´åº¦çš„ç¼–ç æ•°
$$
\begin{aligned}
p_{i, 2 j} &=\sin \left(\frac{i}{10000^{2 j / d}}\right) \\
p_{i, 2 j+1} &=\cos \left(\frac{i}{10000^{2 j / d}}\right)
\end{aligned}
$$
ç¬¬ä¸€æ¬¡çœ‹è¿™ä¸ªç¼–ç çœŸçš„å¤ªè’™åœˆäº†ï¼Œä¸è¿‡æ•™æä¸¾äº†ä¸€ä¸ªä¾‹å­ï¼šç»å¯¹ä½ç½®ä¿¡æ¯ã€‚ä¹Ÿå°±æ˜¯æˆ‘ä»¬ä½¿ç”¨ d ä½äºŒè¿›åˆ¶å¯¹åºåˆ— `range(n)` çš„ä½ç½®è¿›è¡Œç¼–ç ï¼Œè¿™æ ·æ¥çœ‹æ˜¯ä¸æ˜¯å°±ç®€å•ä¸å°‘äº†

```python
# d = 5
0çš„äºŒè¿›åˆ¶æ˜¯ï¼š00000
1çš„äºŒè¿›åˆ¶æ˜¯ï¼š00001
2çš„äºŒè¿›åˆ¶æ˜¯ï¼š00010
3çš„äºŒè¿›åˆ¶æ˜¯ï¼š00011
4çš„äºŒè¿›åˆ¶æ˜¯ï¼š00100
5çš„äºŒè¿›åˆ¶æ˜¯ï¼š00101
6çš„äºŒè¿›åˆ¶æ˜¯ï¼š00110
7çš„äºŒè¿›åˆ¶æ˜¯ï¼š00111
```

è¶Šé«˜ä½çš„æ•°å­—å˜åŒ–å¾—è¶Šæ…¢ï¼Œä¸€å…±èƒ½å¤Ÿç¼–ç  $2^n$ ä¸ªæ•°ã€‚é‚£å¦‚æœæˆ‘ä»¬ç”¨ d ç»´ (0, 1) ä¹‹é—´çš„æ•°å»å¯¹ä½ç½®è¿›è¡Œç¼–ç æ˜¯ä¸æ˜¯ä¹Ÿå¯ä»¥å‘¢ï¼Ÿæ•™æä¸­çš„ä½ç½®ç¼–ç å°±å±äºå…¶ä¸­ä¸€ç§ã€‚è¿˜å¯ä»¥ä»å¹³é¢ç©ºé—´çš„è§’åº¦æ¥è¿›è¡Œç†è§£ï¼Œå‡è®¾æœ‰ d ä¸ªç»´åº¦ï¼Œæ­¤æ—¶æˆ‘ä»¬ç”»å‡º d/2 ä¸ªå¹³é¢

![image-20211213201150635](D2L 10 æ³¨æ„åŠ›æœºåˆ¶/image-20211213201150635.png)

æ—‹è½¬è§’åº¦å°±æ˜¯å¯¹åº”ç€ (cos, sin)ï¼Œéšç€ä½æ•°è¶Šé«˜æ¯æ¬¡ i è¿›ä¸€æ—¶ï¼Œæ—‹è½¬çš„å¹…åº¦è¶Šå°ã€‚ä¸‹é¢æ˜¯ position å’Œ endoding dimension çš„çƒ­åŠ›å›¾

<img src="D2L 10 æ³¨æ„åŠ›æœºåˆ¶/image-20211213201335149.png" style="zoom:80%;" />

æˆ‘å·²ç»å°½åŠ›å»ç†è§£äº†...ä½†æ˜¯è¿˜æ˜¯æœ‰ç‚¹äº‘é‡Œé›¾é‡Œï¼Œä¸è¿‡è¿˜æ˜¯å…ˆç»§ç»­å‰è¡Œå§

## Transformer

ä¸ CNN å’Œ RNN æ¯”è¾ƒï¼Œè‡ªæ³¨æ„åŠ›åŒæ—¶å…·æœ‰å¹¶è¡Œè®¡ç®—å’Œæœ€çŸ­çš„æœ€å¤§è·¯å¾„é•¿åº¦è¿™ä¸¤ä¸ªä¼˜åŠ¿ï¼Œå› æ­¤ï¼Œä½¿ç”¨è‡ªæ³¨æ„åŠ›æ¥è®¾è®¡æ·±åº¦æ¶æ„æ˜¯å¾ˆæœ‰å¸å¼•åŠ›çš„ã€‚å°½ç®¡ transformer æœ€åˆæ˜¯åº”ç”¨äºåœ¨æ–‡æœ¬æ•°æ®ä¸Šçš„åºåˆ—åˆ°åºåˆ—å­¦ä¹ ï¼Œä½†ç°åœ¨å·²ç»æ¨å¹¿åˆ°å„ç§ç°ä»£çš„æ·±åº¦å­¦ä¹ ä¸­ï¼Œä¾‹å¦‚è¯­è¨€ã€è§†è§‰ã€è¯­éŸ³å’Œå¼ºåŒ–å­¦ä¹ é¢†åŸŸ

æˆ‘è®¤ä¸ºè¿™é‡Œè´´è‹±æ–‡çš„å›¾ç¤ºæ¯”è¾ƒå¥½ï¼Œç¬¬ä¸€æ¬¡çœ‹è¿™ä¸ªå›¾è‚¯å®šæ˜¯ä¸€å¤´é›¾æ°´ï¼Œå¯ä»¥å…ˆçœ‹ä»£ç ï¼Œäº†è§£æ¯ä¸ªæ¨¡å—çš„ç»“æ„ï¼Œç„¶åå†æ‹¼èµ·æ¥

<img src="D2L 10 æ³¨æ„åŠ›æœºåˆ¶/image-20211213212144723.png" style="zoom:80%;" />

### åŸºäºä½ç½®çš„å‰é¦ˆç½‘ç»œ ï¼ˆPositionwise FFNï¼‰

åå­—å¾ˆé…·ï¼Œå®é™…ä¸Šæ˜¯ä¸¤ä¸ªå…¨è¿æ¥å±‚

```python
#@save
class PositionWiseFFN(nn.Module):
    """åŸºäºä½ç½®çš„å‰é¦ˆç½‘ç»œ"""
    def __init__(self, ffn_num_input, ffn_num_hiddens, ffn_num_outputs,
                 **kwargs):
        super(PositionWiseFFN, self).__init__(**kwargs)
        self.dense1 = nn.Linear(ffn_num_input, ffn_num_hiddens)
        self.relu = nn.ReLU()
        self.dense2 = nn.Linear(ffn_num_hiddens, ffn_num_outputs)

    def forward(self, X):
        return self.dense2(self.relu(self.dense1(X)))
```

### æ®‹å·®è¿æ¥å’Œå±‚è§„èŒƒåŒ–ï¼ˆadd & normï¼‰

æ®‹å·®è¿æ¥æ˜¯å¾ˆå¸¸è§çš„ç½‘ç»œç»“æ„ï¼Œè¿™é‡Œä¸»è¦è®²è®² [LayerNorm](https://pytorch.org/docs/stable/generated/torch.nn.LayerNorm.html)ã€‚ç”±äº batch ä¸­æ¯ä¸ªæ ·æœ¬çš„æ—¶é—´æ­¥å¯èƒ½ä¸ä¸€æ ·ï¼Œä½¿ç”¨ BatchNorm æ˜¯ä¸å¤ªåˆç†çš„ï¼Œè€Œ LayerNorm å°±ä¸ä¼šå—åˆ°è¿™æ ·çš„é™åˆ¶ï¼Œå…¶ç»Ÿè®¡é‡æ˜¯åœ¨ sample å†…è®¡ç®—çš„
$$
y=\frac{x-\mathrm{E}[x]}{\sqrt{\operatorname{Var}[x]+\epsilon}} * \gamma+\beta
$$

> The mean and standard-deviation are calculated over the last D dimensions

ä¸¾ä¸ªä¾‹å­ï¼Œå‡å¦‚è¾“å…¥çš„å½¢çŠ¶ä¸º $(B, N, C)$ é‚£ä¹ˆç»Ÿè®¡é‡çš„è®¡ç®—å°†åœ¨åä¸¤ä¸ªç»´åº¦è¿›è¡Œï¼Œæœ€åå¾—åˆ°å½¢çŠ¶ä¸º $(B,)$ çš„ç»Ÿè®¡é‡ã€‚æ‰€ä»¥ LayerNorm çš„åˆå§‹åŒ–å‚æ•°ä¸ºä¸€ä¸ª `normalized_shape, in this case (N, C)`

ä¸‹é¢æ¥çœ‹çœ‹ `AddNorm` ä»£ç 

```python
#@save
class AddNorm(nn.Module):
    """æ®‹å·®è¿æ¥åè¿›è¡Œå±‚è§„èŒƒåŒ–"""
    def __init__(self, normalized_shape, dropout, **kwargs):
        super(AddNorm, self).__init__(**kwargs)
        self.dropout = nn.Dropout(dropout)
        self.ln = nn.LayerNorm(normalized_shape)

    def forward(self, X, Y):
        return self.ln(self.dropout(Y) + X)
```

### ç¼–ç å™¨ï¼ˆEncoderï¼‰

#### EncoderBlock

æœ‰äº†ä»¥ä¸Šä¸¤ä¸ªæ¨¡å—ï¼šFFN & AddNormï¼Œå†åŠ ä¸Šä¹‹å‰ä»‹ç»çš„å¤šå¤´æ³¨æ„åŠ›æ¨¡å—ï¼Œå°±èƒ½å¤Ÿæ„å»ºä¸€ä¸ªå®Œæ•´çš„ transformer ç¼–ç å™¨æ¨¡å—

```python
#@save
class EncoderBlock(nn.Module):
    """transformerç¼–ç å™¨å—"""
    def __init__(self, key_size, query_size, value_size, num_hiddens,
                 norm_shape, ffn_num_input, ffn_num_hiddens, num_heads,
                 dropout, use_bias=False, **kwargs):
        super(EncoderBlock, self).__init__(**kwargs)
        self.attention = d2l.MultiHeadAttention(
            key_size, query_size, value_size, num_hiddens, num_heads, dropout,
            use_bias)
        self.addnorm1 = AddNorm(norm_shape, dropout)
        self.ffn = PositionWiseFFN(
            ffn_num_input, ffn_num_hiddens, num_hiddens)
        self.addnorm2 = AddNorm(norm_shape, dropout)

    def forward(self, X, valid_lens):
        Y = self.addnorm1(X, self.attention(X, X, X, valid_lens))
        return self.addnorm2(Y, self.ffn(Y))
```

transformer ä¸€ä¸ªå¾ˆå¥½çš„æ€§è´¨æ˜¯ï¼š**ç¼–ç å™¨ä¸­çš„ä»»ä½•å±‚éƒ½ä¸ä¼šæ”¹å˜å…¶è¾“å…¥çš„å½¢çŠ¶ï¼**

```python
X = torch.ones((2, 100, 24))
valid_lens = torch.tensor([3, 2])
encoder_blk = EncoderBlock(24, 24, 24, 24, [100, 24], 24, 48, 8, 0.5)
encoder_blk.eval()
encoder_blk(X, valid_lens).shape
# torch.Size([2, 100, 24])
```

#### TransformerEncoder

æœ‰äº†å•ä¸ªæ¨¡å—ä¹‹åï¼Œå°±å¯ä»¥å°†å®ƒä»¬å †å èµ·æ¥è·å¾—æ›´å¼ºå¤§ç¼–ç å™¨ï¼Œå½“ç„¶è¿™é‡Œè¿˜æœ‰ä¸¤ä¸ªéœ€è¦æ³¨æ„çš„ç‚¹ï¼š

1. Positional encodingï¼Œç»™æ¯ä¸€ä¸ªåºåˆ—ä½¿ç”¨ä¹‹å‰æ‰€å°†çš„ä¸‰è§’å‡½æ•°ä½ç½®ç¼–ç 
2. ç”±äº embedding çš„æ•°å€¼æ˜¯ç»è¿‡å½’ä¸€åŒ–çš„ï¼Œä¹Ÿå°±æ˜¯è¯´é™¤ä»¥äº† $\sqrt{d}$ï¼Œè€Œ Positional encoding çš„å€¼æ˜¯ (-1, 1) ä¹‹é—´çš„ä¸‰è§’å‡½æ•°ï¼Œä¸ºäº†è®©ä¸¤ä¸ªæ•°ç›¸åŠ ï¼ˆåŠ å…¥ä½ç½®ä¿¡æ¯ï¼‰ï¼Œå¹¶ä¸”è®©äºŒè€…çš„æ•°å€¼å¤§å°ç›¸å·®æ›´å°ï¼Œåˆ™éœ€è¦å°† embedding å†ä¹˜ä»¥é•¿åº¦ $\sqrt{d}$ ä»¥è¿˜åŸ

ä»£ç å¦‚ä¸‹

```python
#@save
class TransformerEncoder(d2l.Encoder):
    """transformerç¼–ç å™¨"""
    def __init__(self, vocab_size, key_size, query_size, value_size,
                 num_hiddens, norm_shape, ffn_num_input, ffn_num_hiddens,
                 num_heads, num_layers, dropout, use_bias=False, **kwargs):
        super(TransformerEncoder, self).__init__(**kwargs)
        self.num_hiddens = num_hiddens
        self.embedding = nn.Embedding(vocab_size, num_hiddens)
        self.pos_encoding = d2l.PositionalEncoding(num_hiddens, dropout)
        self.blks = nn.Sequential()
        for i in range(num_layers):
            self.blks.add_module("block"+str(i),
                EncoderBlock(key_size, query_size, value_size, num_hiddens,
                             norm_shape, ffn_num_input, ffn_num_hiddens,
                             num_heads, dropout, use_bias))

    def forward(self, X, valid_lens, *args):
        X = self.pos_encoding(self.embedding(X) * math.sqrt(self.num_hiddens))
        self.attention_weights = [None] * len(self.blks)
        for i, blk in enumerate(self.blks):
            X = blk(X, valid_lens)
            self.attention_weights[
                i] = blk.attention.attention.attention_weights
        return X
```

ä¸‹é¢æˆ‘ä»¬æŒ‡å®šäº†è¶…å‚æ•°æ¥åˆ›å»ºä¸€ä¸ªä¸¤å±‚çš„ transformer ç¼–ç å™¨ã€‚Transformer ç¼–ç å™¨è¾“å‡ºçš„å½¢çŠ¶æ˜¯ï¼ˆæ‰¹é‡å¤§å°ï¼Œæ—¶é—´æ­¥æ•°ç›®ï¼Œ`num_hiddens`ï¼‰

```python
encoder = TransformerEncoder(
    200, 24, 24, 24, 24, [100, 24], 24, 48, 8, 2, 0.5)
encoder.eval()
encoder(torch.ones((2, 100), dtype=torch.long), valid_lens).shape
# torch.Size([2, 100, 24])
```

### è§£ç å™¨ï¼ˆDecoderï¼‰

#### DecoderBlock

åŒæ ·çš„ï¼Œå…ˆå®ç°å•ä¸ªè§£ç å™¨æ¨¡å—ã€‚å…¶å®åŸºæœ¬çš„æ¨¡å—ä¹‹å‰å·²ç»å…¨éƒ¨å®ç°äº†ï¼Œç»†èŠ‚ä¸Šçš„ä¸åŒæ˜¯ï¼š

**ä¸ encoder ç›¸æ¯”ï¼Œdecoder å…ˆä½¿ç”¨ masked multi-head self-attention å¯¹è¾“å…¥è¿›è¡Œç¼–ç å¾—åˆ° queryã€‚ç„¶åå°†è¯¥ queryã€ä¸ encoder è¾“å‡ºçš„ key & value è¿›è¡Œ cross attention è®¡ç®—**

å…¶ä¸­ mask ä¿ç•™çš„æ˜¯ä¸€ä¸ªä¸‹ä¸‰è§’çŸ©é˜µæƒé‡ï¼Œè¿™æ ·åœ¨è¿›è¡Œè‡ªæ³¨æ„åŠ›è®¡ç®—çš„æ—¶å€™ï¼ŒæŸä¸ªæ—¶é—´æ­¥çš„ç‰¹å¾å‘é‡æ˜¯ä¸ä¼šä¸åœ¨å…¶ä¹‹æ—¶é—´ä¸çš„å‘é‡äº§ç”Ÿæ³¨æ„åŠ›æƒé‡çš„ã€‚è¿™å°±ä¿ç•™äº†å…¶è‡ªå›å½’å±æ€§

è¯„è®ºåŒºæŒ‡å‡ºæ•™æä¸­çš„ transformer ä»£ç æœ‰è¯¯ï¼ˆå®é™…ä¸Šæ²¡æœ‰ï¼‰ï¼Œä½†æ˜¯å…¶ä»£ç æ›´ç®€æ´ï¼Œæ‰€ä»¥è¿™é‡Œè´´çš„æ˜¯è¯„è®ºåŒºæä¾›çš„ä»£ç 

```python
class DecoderBlock(nn.Module):
    """è§£ç å™¨ä¸­ç¬¬iä¸ªå—"""
    def __init__(self, key_size, query_size, value_size, num_hiddens,
                 norm_shape, ffn_num_input, ffn_num_hiddens, num_heads,
                 dropout, i, **kwargs):
        super(DecoderBlock, self).__init__(**kwargs)
        self.i = i
        self.attention1 = d2l.MultiHeadAttention(
            key_size, query_size, value_size, num_hiddens, num_heads, dropout)
        self.addnorm1 = AddNorm(norm_shape, dropout)
        self.attention2 = d2l.MultiHeadAttention(
            key_size, query_size, value_size, num_hiddens, num_heads, dropout)
        self.addnorm2 = AddNorm(norm_shape, dropout)
        self.ffn = PositionWiseFFN(ffn_num_input, ffn_num_hiddens,
                                   num_hiddens)
        self.addnorm3 = AddNorm(norm_shape, dropout)

    def forward(self, X, state):
        enc_outputs, enc_valid_lens = state[0], state[1]
        
        batch_size, num_steps, _ = X.shape
        # dec_valid_lensçš„å¼€å¤´:(batch_size,num_steps),
        # å…¶ä¸­æ¯ä¸€è¡Œæ˜¯[1,2,...,num_steps]
        dec_valid_lens = torch.arange(
            1, num_steps + 1, device=X.device).repeat(batch_size, 1)

        # è‡ªæ³¨æ„åŠ› encode query
        X2 = self.attention1(X, X, X, dec_valid_lens)
        Y = self.addnorm1(X, X2)
        # ç¼–ç å™¨ï¼è§£ç å™¨æ³¨æ„åŠ› cross attention, query ask encode key and value
        Y2 = self.attention2(Y, enc_outputs, enc_outputs, enc_valid_lens)
        Z = self.addnorm2(Y, Y2)
        return self.addnorm3(Z, self.ffn(Z)), state
```

ç¼–ç å™¨å’Œè§£ç å™¨çš„ç‰¹å¾ç»´åº¦éƒ½æ˜¯ `num_hiddens`ï¼Œä¾æ—§æ˜¯ä¸æ”¹å˜æ•°æ®çš„å½¢çŠ¶

```python
decoder_blk = DecoderBlock(24, 24, 24, 24, [100, 24], 24, 48, 8, 0.5, 0)
decoder_blk.eval()
X = torch.ones((2, 100, 24))
state = [encoder_blk(X, valid_lens), valid_lens, [None]]
decoder_blk(X, state)[0].shape
# torch.Size([2, 100, 24])
```

#### TransformerDecoder

ä¸‹é¢å°†å¤šä¸ª decoder ç»„åˆèµ·æ¥ï¼Œå¹¶ä¿å­˜æ³¨æ„åŠ›æƒé‡ç”¨äºå¯è§†åŒ–

```python
class TransformerDecoder(d2l.AttentionDecoder):
    def __init__(self, vocab_size, key_size, query_size, value_size,
                 num_hiddens, norm_shape, ffn_num_input, ffn_num_hiddens,
                 num_heads, num_layers, dropout, **kwargs):
        super(TransformerDecoder, self).__init__(**kwargs)
        self.num_hiddens = num_hiddens
        self.num_layers = num_layers
        self.embedding = nn.Embedding(vocab_size, num_hiddens)
        self.pos_encoding = d2l.PositionalEncoding(num_hiddens, dropout)
        self.blks = nn.Sequential()
        for i in range(num_layers):
            self.blks.add_module("block"+str(i),
                DecoderBlock(key_size, query_size, value_size, num_hiddens,
                             norm_shape, ffn_num_input, ffn_num_hiddens,
                             num_heads, dropout, i))
        self.dense = nn.Linear(num_hiddens, vocab_size)

    def init_state(self, enc_outputs, enc_valid_lens, *args):
        self.seqX = None
        return [enc_outputs, enc_valid_lens]

    def forward(self, X, state):
        if not self.training:
            self.seqX = X if self.seqX is None else torch.cat((self.seqX, X), dim=1)
            print(self.seqX.shape)
            X = self.seqX

        X = self.pos_encoding(self.embedding(X) * math.sqrt(self.num_hiddens))
        self._attention_weights = [[None] * len(self.blks) for _ in range (2)]
        for i, blk in enumerate(self.blks):
            X, state = blk(X, state)
            # è§£ç å™¨è‡ªæ³¨æ„åŠ›æƒé‡
            self._attention_weights[0][
                i] = blk.attention1.attention.attention_weights
            # â€œç¼–ç å™¨ï¼è§£ç å™¨â€è‡ªæ³¨æ„åŠ›æƒé‡
            self._attention_weights[1][
                i] = blk.attention2.attention.attention_weights
        
        if not self.training:   # åªå–æœ€åä¸€ä¸ªè¾“å‡ºè¯
            return self.dense(X)[:, -1:, :], state
        
        return self.dense(X), state
```

æŠŠæ¡å‡ ä¸ªé‡ç‚¹ï¼š

1. **ä¸€å®šè¦è®°ä½ X æ˜¯ä½œä¸º Query è¾“å…¥ decoder**

2. **key (is also value) æ˜¯ encoder çš„è¾“å‡ºï¼Œä¿å­˜åœ¨ state ä¸­ã€‚é™¤æ­¤ä¹‹å¤– state è¿˜ä¿å­˜äº† encode valid length**

3. **å¯ä»¥çœ‹åˆ° state ä½œä¸º cross attention çš„ key & valueï¼Œåœ¨ decoder ä¸­æ˜¯ä¸ä¼šæ”¹å˜çš„**
4. **è®­ç»ƒå’Œæµ‹è¯•çš„æ—¶å€™ decoder çš„æµç¨‹æ˜¯ä¸ä¸€æ ·çš„ï¼š**
   1. è®­ç»ƒæ—¶ï¼Œè¾“å…¥æ˜¯æ•´ä¸ª label åºåˆ—ä¸€èµ·è¾“å…¥ decoderï¼Œè¾“å‡ºä¹Ÿæ˜¯ä¸€æ•´ä¸ªåºåˆ—
   2. æµ‹è¯•æ—¶ï¼Œæ²¡æœ‰ labelï¼Œåˆå§‹è¾“å…¥æ˜¯ç‰¹æ®Šè¯å…ƒ `<bos>`ï¼Œç„¶åå¾—åˆ°ä¸€ä¸ªè¾“å‡ºè¯ï¼Œå†å’Œä¹‹å‰çš„è¾“å…¥ `<bos>` concatï¼Œä½œä¸ºæ–°è¾“å…¥å†é€å…¥ decoder ä¸­ï¼Œå¦‚æ­¤å¾ªç¯...ç›´åˆ°è¾“å‡ºçš„æ˜¯ `<eos>` æˆ–è€…åˆ°è¾¾æœ€å¤§æ—¶é—´æ­¥ã€‚å¯ä»¥ç”¨ RNN + è‡ªå›å½’è¿™æ ·çš„æ¦‚å¿µæ¥ç†è§£è¿™ä¸ªè¿‡ç¨‹

### ç¼–ç å™¨-è§£ç å™¨ï¼ˆEncoder-Decoderï¼‰

æŠŠä¸Šé¢çš„ encoder å’Œ decoder å°è£…èµ·æ¥å°±æ˜¯å®Œæ•´çš„å˜å½¢é‡‘åˆšäº†ï¼

```python
class EncoderDecoder(nn.Module):
    """The base class for the encoder-decoder architecture.
    """
    def __init__(self, encoder, decoder, **kwargs):
        super(EncoderDecoder, self).__init__(**kwargs)
        self.encoder = encoder
        self.decoder = decoder

    def forward(self, enc_X, dec_X, enc_valid_lens, *args):
        enc_outputs = self.encoder(enc_X, enc_valid_lens)    # (B, N, C)
        dec_state = self.decoder.init_state(enc_outputs, enc_valid_lens)
        return self.decoder(dec_X, dec_state)
```

### Attention å¯è§†åŒ–

ä¸‹é¢æ¥çœ‹çœ‹ä¸‰ä¸ª Multi-attention çš„å¯è§†åŒ–ç»“æœï¼Œä¸»è¦æ˜¯ä½“ä¼š valid_len çš„æ•ˆæœ

1. Encoder self-attention weights

   <img src="D2L 10 æ³¨æ„åŠ›æœºåˆ¶/image-20211215153222782.png" style="zoom: 67%;" />

   å¯ä»¥çœ‹åˆ°åœ¨æŸä¸ª key positions è¿‡åæ˜¯æ²¡æœ‰æ³¨æ„åŠ›æƒé‡çš„ï¼Œæ˜¯å› ä¸ºä¹‹åçš„ key éƒ½æ˜¯ <pad> è¯å…ƒï¼Œä¸éœ€è¦è¿›è¡Œæ³¨æ„åŠ›è®¡ç®—

2. Decoder self-attention weights

   <img src="D2L 10 æ³¨æ„åŠ›æœºåˆ¶/image-20211215153713172.png" alt="image-20211215153713172" style="zoom: 67%;" />

   ç”±äº decoder çš„æ¯ä¸ª valid_len æ˜¯éšç€æ—¶é—´æ­¥é€æ¸å¢åŠ çš„ï¼Œæ‰€ä»¥å¯ä»¥çœ‹åˆ° self-attention weights ä¼¼ä¹æ•´ä½“æ˜¯å‘ˆä¸‹ä¸‰è§’å½¢çŠ¶

3. Decoder cross attention weights

   <img src="D2L 10 æ³¨æ„åŠ›æœºåˆ¶/image-20211215154614074.png" alt="image-20211215154614074" style="zoom:67%;" />

   ä¾ç„¶æ˜¯ encoder self-attention ä¸­çš„æƒ…å†µï¼Œè¶…è¿‡æŸä¸ª encoder valid length å°±æ²¡æœ‰æƒé‡äº†

## è¡¥å……

### nn.Embedding

å…³äº `nn.Embedding`ï¼Œæ•´ç†å‡ ä¸ªç‚¹ï¼š

1. Embedding å±‚å°†æ¯ä¸ªè¯å…ƒè½¬åŒ–ä¸º embed_size ç»´åº¦çš„å‘é‡ï¼ˆä¹Ÿç§°ä¸ºè¯å‘é‡ï¼‰
2. Embedding layer å­˜å‚¨äº†ä¸€ä¸ªå‚æ•°çŸ©é˜µ (vocab_size, embed_size) æ˜¯å¯ä»¥éšç€è®­ç»ƒæ›´æ–°çš„
3. ç»è¿‡è®­ç»ƒä¹‹åç›¸ä¼¼è¯å…ƒçš„è¯å‘é‡å¯èƒ½ä¼šå˜å¾—æ›´æ¥è¿‘

### è‡ªå›å½’æ¨¡å‹

åœ¨ decoder çš„å‰å‘æ–¹ç¨‹ä¸­ï¼Œä¼šä½¿ç”¨ label ä½œä¸ºè¾“å…¥ï¼Œä½¿ç”¨å†å² label ä¿¡æ¯æ¥é¢„æµ‹å½“å‰çš„è¾“å‡ºã€‚è¿™å°±æ˜¯ä¸€ç§è‡ªå›å½’æ¨¡å‹ï¼Œä½†ä¸ºä»€ä¹ˆè¦ä½¿ç”¨è‡ªå›å½’çš„æ–¹å¼è®­ç»ƒï¼Œæˆ‘çš„ç†è§£æ˜¯ä¸ºäº†è®­ç»ƒçš„ç¨³å®šï¼Œæˆ‘ä»¬ä¸ä½¿ç”¨æ¨¡å‹è‡ªå·±å›å½’çš„ queryï¼Œè€Œæ˜¯ç›´æ¥ç”¨çœŸå®çš„ queryï¼Œç›¸å½“äºåŠ å…¥å…ˆéªŒï¼Œè®©æ¨¡å‹æœç´¢ç©ºé—´å˜å°

### æ„Ÿè¨€

å¯ç®—æ˜¯å®Œæˆäº†æ€»ç»“ğŸ˜­ğŸ˜­è™½ç„¶çœ‹å¾—è¿˜æ˜¯æ¯”è¾ƒç²—ç³™ï¼Œä½†æ˜¯æ€»å½’æ˜¯æœ‰äº›æ¦‚å¿µäº†ã€‚åœ¨æ²ç¥è¯»è®ºæ–‡çš„è§†é¢‘ [bilibili](https://www.bilibili.com/video/BV1pu411o7BE) ä¸­è®²åˆ°ï¼šè™½ç„¶ transformer è®ºæ–‡å«åš `Attention Is All You Need`ï¼Œä½†äº‹å®ä¸Šå„ä¸ªç»“æ„éƒ½æ˜¯å¾ˆé‡è¦çš„ï¼Œä¾‹å¦‚ï¼šæ®‹å·®è¿æ¥å’Œå±‚è§„è§„èŒƒåŒ–åœ¨è®­ç»ƒæ·±åº¦ç½‘ç»œæ—¶æ˜¯éå¸¸é‡è¦çš„ã€‚Transformer (attention) æ•´ä½“æ¥çœ‹ä»æ˜¯ä¸€ä¸ªå‘å±•åˆæœŸçš„æ¶æ„ï¼Œåœ¨æœªæ¥æˆ–è®¸æœ‰æ›´å¤šçš„æ¶æ„å‡ºç°ï¼Œä¸€èµ·æœŸå¾…å§

é¢˜å¤–è¯ï¼Œçœ‹åˆ°æ²ç¥ä½¿ç”¨ jupyter notebook è®²è§£ä»£ç çš„æ–¹å¼éå¸¸æ–¹ä¾¿ï¼Œå¯ä»¥ä½¿ç”¨ [rise](https://blog.csdn.net/ruizhiwang2015/article/details/115445514) æ’ä»¶
