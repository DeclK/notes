---
title: BEVDet
tags:
  - BEVDet
categories:
  - papers
mathjax: true
abbrlink: b5568258
date: 2022-10-06 12:57:00
---

# BEVDet

## ç›¸æœºå†…å¤–å‚

å…³äºç›¸æœºå†…å¤–å‚ [zhihu](https://zhuanlan.zhihu.com/p/389653208)ï¼Œè¿™ç¯‡åšå®¢å†™å¾—å·²ç»éå¸¸æ¸…æ™°äº†ï¼Œåªéœ€è¦è®°ä½å°å­”æˆåƒçš„ä¸€ä¸ªæ¯”å€¼å…¬å¼å°±å¥½ã€‚ä¸åŒçš„é¡¹ç›®å¯èƒ½ä¼šæœ‰ä¸åŒçš„çŸ©é˜µè¡¨è¾¾å½¢å¼ï¼Œä½†å¤§ä½“é€ƒä¸å‡ºåšå®¢ä¸­çš„é€»è¾‘ã€‚å°å­”æˆåƒï¼ˆå·²è¡¥å¿ç¿»è½¬ï¼‰çš„å…¬å¼ä¸º
$$
\frac{Z}{f}=\frac{X}{X^{\prime}}=\frac{Y}{Y^{\prime}}
$$
è¿™æ ·å°±å¯ä»¥è¡¨ç¤ºåƒç´ åŒ–åæ ‡ $u, v$ ä¸ºï¼š
$$
\begin{array}{l}
u=\alpha X^{\prime}+c_{x} \\
v=\beta Y^{\prime}+c_{y}
\end{array}
$$
å…¶ä¸­ $\alpha,\beta, c_x, c_y$ ä»£è¡¨ç€å¯¹å°å­”æˆåƒçš„å›¾åƒçš„ç¼©æ”¾å’Œå¹³ç§»ã€‚æŠŠä¸Šé¢çš„å¼å­å¸¦å…¥å¾—
$$
\begin{array}{l}
u=\alpha f \frac{X}{Z}+c_{x}=f_{x} \frac{X}{Z}+c_{x} \\
v=\beta f \frac{Y}{Z}+c_{y}=f_{y} \frac{Y}{Z}+c_{y}
\end{array}
$$
ä½¿ç”¨æ›´ç®€æ´çš„çŸ©é˜µå…¬å¼è¡¨è¾¾ä¸º
$$
Z\left(\begin{array}{l}
u \\
v \\
1
\end{array}\right)=\left(\begin{array}{ccc}
f_{x} & 0 & c_{x} \\
0 & f_{y} & c_{y} \\
0 & 0 & 1
\end{array}\right)\left(\begin{array}{c}
X \\
Y \\
Z
\end{array}\right)=\mathbf{K P}
$$
åœ¨åƒç´ åæ ‡é‡ŒåŠ å…¥ä¸€ç»´ï¼Œå¯ä»¥æ–¹ä¾¿ä¹‹ååšçŸ©é˜µè¿ç®—

ç›¸æœºçš„ä½ç½®ç”±æ—‹è½¬çŸ©é˜µ R å’Œå¹³ç§»å‘é‡ t æ¥æè¿°
$$
\mathbf{P}=\mathbf{R} \mathbf{P}_{\mathbf{w}}+\mathbf{t}
$$
å…¶ä¸­ $P_w$ å°±æ˜¯ä¸–ç•Œåæ ‡ã€‚è¿™ä¸ªå…³ç³»æ˜¯æ¯”è¾ƒä¸€èˆ¬æ€§çš„ï¼Œè¡¨è¾¾çš„æ˜¯ä¸¤ä¸ªåæ ‡ç³»ä¹‹é—´çš„ç›¸äº’è½¬æ¢

## BEVDet View Transformer

å…³äº lift splat shoot çš„è®²è§£è§†é¢‘ [bilibili](https://www.bilibili.com/video/BV16T411g7Gc)ï¼ŒåŸºæœ¬ä¸Š BEVDet å°±æ˜¯ä½¿ç”¨è¿™ç¯‡è®ºæ–‡ä½œä¸ºç‰¹å¾æå–ï¼Œç„¶åæ¥å…¥ä¸€ä¸ªæ£€æµ‹å¤´è¿›è¡Œè®­ç»ƒå³å¯

ç›´æ¥è´´ä¸€ä¸ªå‰å‘æ–¹ç¨‹ï¼Œæ ¹æ®ä»£ç è¿›è¡Œæ³¨é‡Šç¬”è®°

```python
    def forward(self, input):
        x, rots, trans, intrins, post_rots, post_trans = input
        # post_rots & post_trans è®°å½•çš„æ˜¯æ•°æ®å¢å¼ºçš„æ“ä½œï¼Œä¹‹åä¼šé€†è½¬æ•°æ®å¢å¼ºçš„æ•ˆæœï¼Œ
        # è·å¾— frustum åœ¨ç‚¹äº‘åæ ‡ç³»ä¸‹çš„ä½ç½®
        # rots & trans åº”è¯¥æ˜¯è®°å½•äº† cam åˆ° lidar åæ ‡ä¹‹é—´çš„å˜æ¢
        # ä½¿ç”¨ intrins å°†åƒç´ åæ ‡è½¬æ¢åˆ° cam åæ ‡
        
        B, N, C, H, W = x.shape	# N ä»£è¡¨ cam ä¸ªæ•°
        x = x.view(B * N, C, H, W)
        
        x = self.depthnet(x)
        # depthnet è¾“å‡ºç»´åº¦ä¸º self.D + self.numC_trans
        # self.D ä»£è¡¨ç¦»æ•£åŒ–æ·±åº¦ï¼Œself.numC_trans ä»£è¡¨é¢„æµ‹çš„ç‰¹å¾ç»´åº¦
        
        depth = self.get_depth_dist(x[:, :self.D])	# ç­‰ä»·äº softmax
        
        geom = self.get_geometry(rots, trans, intrins, post_rots, post_trans)
        # è·å¾— frustum åœ¨ lidar åæ ‡ç³»ä¸‹çš„ä½ç½® (B, N, D, H, W, 3)
        img_feat = x[:, self.D:(self.D + self.numC_Trans)]

        # Lift
        # å‡ç»´ï¼Œåš outer productï¼Œå³ broadcast
        volume = depth.unsqueeze(1) * img_feat.unsqueeze(2)
        volume = volume.view(B, N, self.numC_Trans, self.D, H, W)
        volume = volume.permute(0, 1, 3, 4, 5, 2)

        # Splat
        # æŠŠæ‰€æœ‰ cam çš„ frustum éƒ½è½¬ç§»åˆ° lidar ä½“ç´ åæ ‡ç³»ä¸­ï¼Œ
        # å¹¶ä¸”è½åœ¨ç›¸åŒ voxel çš„ç‰¹å¾å°†åš sum æ“ä½œ
        bev_feat = self.voxel_pooling(geom, volume)
        if self.image_view_supervision:
            return bev_feat, [x[:, :self.D].view(B,N,self.D,H,W), x[:, self.D:].view(B,N,self.numC_Trans,H,W)]
        return bev_feat
```

è¿™é‡Œæˆ‘æŠŠ ego åæ ‡ç³»æ¢æˆäº† lidar åæ ‡ç³»ä¾¿äºç†è§£ï¼Œå…³äºä»€ä¹ˆæ˜¯ ego å¯ä»¥çœ‹è¿™ä¸ª [issue](https://github.com/nutonomy/nuscenes-devkit/issues/487)

## å¯æå‡çš„åœ°æ–¹

1. frustum è½¬ç§»åˆ° lidar åæ ‡ç³»è¿‡åæ˜¯è¿‘å¤„ç¨ å¯†è¿œå¤„ç¨€ç–çš„ï¼Œå¯ä»¥æ›´é’ˆå¯¹åœ°è¿›è¡Œé‡‡æ ·
2. å¯ä»¥åŠ å…¥ä¸€äº›ä¸­é—´ç›‘ç£æ¥å¯¹ view transformer è¿›è¡Œè®­ç»ƒ
3. å¯¹ç»è¿‡ view transformer è¿‡åçš„ç‚¹äº‘å†æ¬¡è¿›è¡Œ BEV å¢å¹¿ï¼ˆè¿™åœ¨ BEVDet ä¸­å·²ç»æå‡ºï¼‰
4. åš `voxel_pooling` çš„æ—¶å€™å¯ä»¥ä½¿ç”¨æ›´å¥½çš„ pooling ç­–ç•¥ï¼Œè€Œä¸æ˜¯ç®€å•çš„ sum
5. ä¸€å®šè¦ä½¿ç”¨æ›´å¤§çš„æ„Ÿå—é‡å»å¤„ç†ï¼ˆdeformable convolution, big kernel, transformerï¼‰
6. å¯ä»¥åŠ å…¥æ—¶åºä¿¡æ¯

## Multiple View Geometry

[Persformer issue](https://github.com/OpenDriveLab/PersFormer_3DLane/issues/4) è¿™æ˜¯ä¸ºäº†è§£å†³æˆ‘å¯¹ Persformer ä»£ç çš„ä¸€äº›ç–‘æƒ‘ï¼šä¸ºä»€ä¹ˆ Extrinsic è¦æ±‚é€†ã€‚è®ºæ–‡é‡Œä½¿ç”¨çš„æŠ•å½±å˜æ¢å…¬å¼ä¹Ÿæ¯”è¾ƒå¥‡æ€ªï¼Œä¸å»ºè®®æ·±ç©¶ï¼Œä½†æ˜¯åŸç†å°±æ˜¯é€è§†å˜æ¢ï¼Œæ¨èä¸‹é¢çš„è§†é¢‘å­¦ä¹ ï¼š

1. [æç®€å¤šè§†å›¾å‡ ä½•](https://www.bilibili.com/video/BV1AU4y1H7Nr)ï¼Œæ•™æ [4CV](https://www.robots.ox.ac.uk/~dwm/Courses/4CV_2015/index.html)

ä¸€ä¸ªæ¯”è¾ƒé‡è¦çš„æ€æƒ³æ˜¯ä½¿ç”¨ homogeneous çš„æ–¹å¼æ¥è¡¨ç¤ºåæ ‡ï¼ˆé½æ¬¡åæ ‡ï¼‰ï¼Œè¿™æ ·èƒ½å¾ˆæ–¹ä¾¿åœ°è¡¨ç¤ºæŠ•å½±å’Œå˜æ¢ã€‚é½æ¬¡åæ ‡å°±æ˜¯æ¯”ç¬›å¡å°”åæ ‡å¤šä¸€ä¸ªç»´åº¦ï¼Œè¿™ä¸ªç»´åº¦å¯ä»¥é€šè¿‡å½’ä¸€åŒ–è¾¾åˆ°ä¸ç¬›å¡å°”ç­‰ä»·çš„è¡¨ç¤ºï¼Œå³ï¼šå¯¹ä¸€ä¸ªé½æ¬¡åæ ‡è¿›è¡Œç¼©æ”¾æ˜¯ä¸æ”¹å˜è¿™ä¸ªç‚¹åœ¨ç©ºé—´ä¸­çš„ä½ç½®çš„

### é€è§†æŠ•å½±

ç›´æ¥ä¸Šè¯¾ [perspective projection](https://www.bilibili.com/video/BV1DM4y1c7gT/?p=5)ï¼Œè¯¾ä»¶ [github](https://github.com/Nerdyvedi/Multiple-View-Geometry)ã€‚é€è§†æŠ•å½±çš„ç›®çš„å°±æ˜¯å°†3Dçš„åæ ‡æŠ•å½±åˆ°imageåæ ‡ (H, W) ä¸Š

é¦–å…ˆä»å‡¸é€é•œæˆåƒå¼€å§‹è®²èµ·

<img src="BEVDet/image-20230414221015944.png" alt="image-20230414221015944" style="zoom:50%;" />

å¦‚æœæŠŠæ‰€æˆçš„åƒæ¢åˆ°å¦ä¸€ä¾§ï¼Œå°±å˜æˆäº†é€è§†æŠ•å½±

<img src="BEVDet/image-20230414221045158.png" alt="image-20230414221045158" style="zoom:50%;" />

è€Œè¯¥é€è§†æŠ•å½± perspective projection çš„æ•°å­¦è¡¨è¾¾å¼å¦‚ä¸‹

<img src="BEVDet/image-20230414221201475.png" alt="image-20230414221201475" style="zoom:50%;" />

è¯¥å˜æ¢æ˜¯ä¸€ä¸ªéçº¿æ€§å˜æ¢ï¼Œæˆ‘ä»¬é€šå¸¸å°† Z ç§»åˆ°å·¦ä¾§ï¼Œè®©è¿™ä¸ªå¼å­çœ‹èµ·æ¥æ˜¯ä¸€ä¸ªçº¿æ€§å˜æ¢ï¼Œå¹¶ä¸”ä½¿ç”¨é½æ¬¡åæ ‡è¡¨ç¤º

<img src="BEVDet/image-20230414222024077.png" alt="image-20230414222024077" style="zoom: 33%;" />

è¿™é‡Œ $K_f$ å°±æ˜¯æˆ‘ä»¬æ‰€è¯´çš„ç›¸æœºå†…å‚å•¦ï¼ä½†å®é™…ä¸Šè¿™æ˜¯ç†æƒ³çš„ç›¸æœºï¼ŒçœŸå®çš„ç›¸æœºå†…å‚è¿˜éœ€è¦è¿›è¡Œæ ¡æ­£ï¼Œä½†æœ¬è´¨ä¹Ÿæ˜¯ä¸€ä¸ª $3\times 3$ çŸ©é˜µã€‚$\Pi_0$ æ˜¯ä¸€ä¸ªç®€å•çš„é™ç»´çŸ©é˜µï¼Œæœ¬è´¨ä¸Šå°±æ˜¯æŠŠé½æ¬¡åæ ‡çš„æœ€åä¸€ç»´æ‰”æ‰

å†åŠ å…¥ä¸€ä¸ªä¸–ç•Œåæ ‡ç³»åˆ°ç›¸æœºåæ ‡ç³»çš„è½¬æ¢å°±æ˜¯æ•´ä¸ªé€è§†æŠ•å½±çš„å…¨éƒ¨å†…å®¹å•¦ğŸ¥³

<img src="BEVDet/image-20230414221954469.png" alt="image-20230414221954469" style="zoom: 33%;" />

### é€è§†å˜æ¢

é€è§†å˜æ¢ä¼šç¨å¾®å¤æ‚ä¸€äº›ï¼Œé€è§†å˜æ¢çš„æœ¬è´¨æ˜¯å°†å›¾ç‰‡æŠ•å½±åˆ°ä¸€ä¸ªæ–°çš„å¹³é¢ï¼ŒåŒºåˆ«äºåˆšä½“å˜æ¢ä¸æ”¾å°„å˜æ¢ï¼Œé€è§†å˜æ¢åçš„ç‰©ä½“å˜åŒ–æ›´çµæ´» [CSDN](https://blog.csdn.net/m0_43609475/article/details/112847314)

åªèƒ½å¯¹**å•ä¸€å¹³é¢**æœ‰å‡†ç¡®çš„ç‰©ç†æ„ä¹‰ï¼Œè€Œå…¶ä»–çš„å¹³é¢åˆ™ä¼šäº§ç”ŸéçœŸå®çš„å½¢å˜ï¼Œ[CSND](https://blog.csdn.net/bby1987/article/details/106317354)

<img src="BEVDet/image-20230415120726812.png" alt="image-20230415120726812" style="zoom: 33%;" />

é€è§†å˜åŒ–çš„ä¸€ä¸ªç†è§£æ–¹å¼å°±æ˜¯å°†ä¸Šè¿°æ­£æ–¹å½¢çš„å››ä¸ªè§’ç‚¹æ˜ å°„åˆ°ä»»æ„å››è¾¹å½¢çš„å››ä¸ªè§’ç‚¹ï¼Œè¿™æ ·çš„å˜æ¢æ–¹å¼å¯ä»¥ç”¨ä¸€ä¸ªçŸ©é˜µè¡¨ç¤ºï¼Œ[bilibili](https://www.bilibili.com/video/BV1C64y1d7ng)
$$
\begin{bmatrix}x'\\y'\\1\end{bmatrix}=\begin{bmatrix}m_{11}&m_{12}&m_{13}\\m_{21}&m_{22}&m_{23}\\m_{31}&m_{32}&m_{33}\end{bmatrix}\begin{bmatrix}x\\y\\1\end{bmatrix}
$$
çœ‹ä¼¼æœ‰9ä¸ªæœªçŸ¥æ•°ï¼Œå®é™…ä¸Šé€è§†å˜æ¢çš„è‡ªç”±åº¦ä»…ä¸º8ä¸ªï¼Œæ‰€ä»¥é€šå¸¸æŒ‡å®š $m_{33}=1$ï¼Œç„¶åå¸¦å…¥4ä¸ªç‚¹æ±‚è§£å˜æ¢çŸ©é˜µ  $M$ï¼Œä¼ªä»£ç å¦‚ä¸‹

 ```python
 def get_M(src, dst):
     # Compute the homography matrix H not using cv2.getPerspectiveTransform
     A = np.zeros((8, 8))
     for i in range(4):
         A[2*i] = np.array([src[i][0], src[i][1], 1, 0, 0, 0, -dst[i][0]*src[i][0], -dst[i][0]*src[i][1]])
         A[2*i+1] = np.array([0, 0, 0, src[i][0], src[i][1], 1, -dst[i][1]*src[i][0], -dst[i][1]*src[i][1]])
 
     # Define the b matrix
     b = dst.reshape((8,1))
 
     # solve linear equation
     H = np.linalg.solve(A, b)
     H = np.vstack((H, 1))
     M = H.reshape((3, 3))
     return M
 
 M = cv2.getPerspectiveTransform(src, dst)
 warped = cv2.warpPerspective(img, M, (H, W))
 
 # check the OpenCV version and my implementation
 print(M)
 print(get_M(src, dst))
 ```

#### IPM

ä¹‹å‰ä¸€ç›´åœ¨çº ç»“ IPMï¼Œinverse perspective transform åˆ°åº•æ˜¯ä»€ä¹ˆï¼Œå…¶æœ¬è´¨å°±æ˜¯é€è§†å˜æ¢ï¼Œç»å¸¸æ˜¯ç”¨åœ¨è‡ªåŠ¨é©¾é©¶ä¸­çš„è½¦é“çº¿æ£€æµ‹ï¼Œå…¶ç›®çš„æ˜¯å°†å‰è§†å›¾ä¸­çš„åœ°é¢ï¼Œæ˜ å°„ä¸ºé¸Ÿç°å›¾ã€‚ä¸ºäº†è·å¾— IPM éœ€è¦äººä¸ºè®¾å®šä¸€äº›åŒºåŸŸï¼š

1. å…³æ³¨çš„åœ°é¢èŒƒå›´ï¼Œç”± 4 ä¸ªåœ°é¢ç‚¹è¡¨ç¤º `points = np.array(shape_4x3)`ï¼Œè¿™å››ä¸ªå‚è€ƒç‚¹å°±æ„æˆäº†ä¸€ä¸ªå¹³é¢ï¼Œæ³¨æ„ä¸èƒ½æœ‰3ç‚¹å…±çº¿çš„æƒ…å†µï¼Œè¯¥å¹³é¢é€šå¸¸è®¾å®šä¸ºä¸€ä¸ªçŸ©å½¢ï¼Œæ–¹é¢å®šä¹‰åé¢çš„å›¾åƒæ˜ å°„ç‚¹
2. æ˜ å°„åˆ°å›¾åƒçš„èŒƒå›´ï¼Œä¹Ÿç”± 4 ä¸ªç‚¹è¡¨ç¤º `dst = np.array(shape_4x2)`ï¼Œè¿™å››ä¸ªç‚¹å°±æ˜¯ä¸Šè¿°åŒºåŸŸå˜æ¢è¿‡å**æˆ‘ä»¬å¸Œæœ›æ˜ å°„åˆ°æ–°çš„å›¾åƒä¸­çš„ä½ç½®**ï¼Œæ˜¾ç„¶å½“ `points` å®šä¹‰ä¸ºä¸€ä¸ªçŸ©å½¢æ—¶ï¼Œ`dst` å®šä¹‰ä¸ºä¸€ä¸ªç›¸ä¼¼çš„çŸ©å½¢æ˜¯æœ€å¥½çš„ï¼Œå…·ä½“çš„å€¼å¯ä»¥æŒ‰ä½ å–œå¥½

æœ€è¿‘åœ¨çœ‹ nuScenes æ•°æ®é›†ï¼Œä¸å¦‚å°±æ‹¿è¿™ä¸ªæ•°æ®é›†ç»ƒç»ƒæ‰‹å§~æ•°æ®é›†æ­£å¥½æœ‰æ‰€éœ€è¦çš„ç›¸æœºå†…å¤–å‚æ•°

```python
# a sample of ipm using nuscenes dataset
import cv2
import numpy as np
import matplotlib.pyplot as plt
from nuscenes.nuscenes import NuScenes
from pyquaternion import Quaternion

nusc = NuScenes(version='v1.0-mini', dataroot='/github/The-Eyes-Have-It/data/nuscenes', verbose=False)

# get a sample
my_sample = nusc.sample[0]

# get CAM_FRONT image, and its intrinsic matrix
cam_front_data = nusc.get('sample_data', my_sample['data']['CAM_FRONT'])
data_path, box_list, cam_intrinsic = nusc.get_sample_data(cam_front_data['token'])
img = cv2.imread(data_path)
K = np.array(cam_intrinsic).reshape(3, 3)

# get CAM_FRONT calibrated sensor
cam_front_sensor = nusc.get('calibrated_sensor', cam_front_data['calibrated_sensor_token'])
cam2ego_R = Quaternion(cam_front_sensor['rotation']).rotation_matrix
cam2ego_T = np.array(cam_front_sensor['translation'])

def RT(points, R, T, inverse=False):
    """ Rotation and translation, note that inverse is different """
    if inverse:
        return np.dot(R.T, (points - T).T).T
    return np.dot(R, points.T).T + T
    
    
# define 4 points in the ego car coords
points = np.array([[10, -5, 0], [10, 5, 0], [50, -5, 0], [50, 5, 0]], dtype=np.float32)
p = points
# transform points to camera coords
points = RT(points, cam2ego_R, cam2ego_T, inverse=True)

# transform points to image plane
points = np.dot(K, points.T).T
points = points / points[:, 2].reshape(-1, 1)
homo_points = points
points = points[:, :2].astype(np.float32)
print(points)

# define bev points
# get the transform matrix
dst = np.float32([[1200,img.shape[0]],
                  [400, img.shape[0]],
                  [1200,0],
                  [400, 0]])
M = cv2.getPerspectiveTransform(points, dst)
# warp
warped = cv2.warpPerspective(img, M, (img.shape[1], img.shape[0]))
print(img.shape)    # shape is (H, W, 3)


def homo2cood(homo_points):
    # homo_points: (N, C)
    last = homo_points[:, -1:]
    homo_points = homo_points / last
    return homo_points

print(homo_points)
transformed = np.dot(M, homo_points.T).T
coords = homo2cood(transformed)
# show image in matplotlib
fig, ax = plt.subplots(1, 2, figsize=(20, 10))
ax[0].imshow(img)
# add points
colors = ['r', 'g', 'b', 'y']
for i, point in enumerate(points):
    ax[0].scatter(point[0], point[1], s=50, c=colors[i])
    
ax[1].imshow(warped)
for i, point in enumerate(dst):
    ax[1].scatter(point[0], point[1], s=50, c=colors[i])

plt.show()
```

æœ€åæ˜ å°„å‡ºæ¥çš„æ•ˆæœå¦‚å›¾æ‰€ç¤ºï¼Œæ„Ÿè§‰è¿˜ä¸é”™ğŸ¥³ä½ å¯ä»¥çœ‹åˆ°åŸæœ¬åœ¨ front view ä¸­ç›¸äº¤çš„ç›´çº¿ç°åœ¨å˜æˆäº†å¹³è¡Œçº¿ï¼Œä½†æ˜¯åœ°å¹³é¢ä»¥å¤–çš„å›¾åƒå°±è¢«æ‹‰ä¼¸æˆå¥‡æ€ªçš„æ ·å­äº†ã€‚æ­£å¦‚å‰é¢æ‰€è¿°ï¼Œé€è§†å˜æ¢åªèƒ½å¯¹**å•ä¸€å¹³é¢**æœ‰å‡†ç¡®çš„ç‰©ç†æ„ä¹‰ï¼Œè€Œå…¶ä»–çš„å¹³é¢åˆ™ä¼šäº§ç”ŸéçœŸå®çš„å½¢å˜

![image-20230415125937805](BEVDet/image-20230415125937805.png)