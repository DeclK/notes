# 百面机器学习 chapter 1-2

## 第一章 特征工程

### 01 特征归一化

#### 为什么需要特征归一化？

为了消除数据特征之间的量纲影响，我们需要对特征进行归一化处理，使得不同指标之间具有可比性。以随机梯度下降为例，归一化能避免 zigzag 的震荡迭代，加速收敛

### 02 类别型特征

#### 怎样处理类别型特征？

对于逻辑回归、支持向量机等模型来说，类别型特征必须经过处理转换成数值型特征才能正确工作。通常使用以下方法进行编码：

1. 序号编码 ordinal encoding。序号编码通常用于处理类别间具有大小关系的数据
2. 独热编码 one-hot encoding。独热编码通常用于处理类别间不具有大小关系的特征。对于类别取值较多的情况下使用独热编码需要注意：
   1. 使用稀疏向量节省空间。稀疏向量和稀疏矩阵类似的概念，使用一个二元组表达（pos, value）
   2. 配合特征选择来降低维度。高维特征会带来以下问题：
      1. 高维特征难以衡量两个点之间的距离
      2. 在逻辑回归中，特征越多，模型的参数越多，会引起过拟合问题
      3. 通常只有部分维度对分类有帮助
3. 二进制编码 binary encoding。先用序号编码给每个类别赋予一个类别 ID 序号，然后将 ID 序号对应的二进制编码作为结果

### 03 高维组合特征的处理

#### 什么是组合特征？如何处理高维组合特征？

为了提高复杂关系的拟合能力，在特征工程中经常会把一阶离散特征进行组合，构成高阶组合特征。

组合特征的不同取值的个数， 为单个特征的不同取值的个数的乘积。假设数据的特征向量为 $X = (x_1, ..., x_k)$，则有
$$
Y=\operatorname{sigmoid}\left(\sum_{i} \sum_{j} w_{i j}<x_{i}, x_{j}>\right)
$$
其中 $<x_i, x_j>$ 代表组合特征，组合特征的维度为 $|x_i|\times|x_j|$，假设 $|x_i|=m,|x_j|=n$，并且假设模型采用线性回归（以逻辑回归为例），就能得到上面的公式，此时参数的规模为 $|x_i|\times|x_j|$。这个规模可以变得很大，所以一个可行的方法是做特征  embedding，即使用长度为 k 的低维向量表示特征，那么学习参数的规模变为 $m \times k + n \times k + k\times k$

这等价于矩阵分解，但我并不明白...

### 04 组合特征（to be reviewed）

#### 怎样有效地找到组合特征？

而且并不是所有的特征组合都是有意义的。因此，需要一种有效的方法来帮助我们找到应该对哪些特征进行组合

介绍一种基于决策树的组合特征寻找方法。但我不会决策树...

### 05 文本表示模型

#### 有哪些文本表示模型？它们各有什么优缺点？

1. 词袋模型和 N-gram 模型
2. 主题模型
3. 词嵌入与深度学习模型。词嵌入是一类将词向量化的模型的统称，核心思想是将每个词都映射成低维空间上的一个稠密向量

### 06 Word2Vec

谷歌2013 年提出的 Woid2Vec 是目前最常用的词嵌入模型之一

### 07 图像数据不足时的处理方法

#### 在图像分类任务中，数据不足会带来什么问题？如何缓解数据量不足带来的问题？

问题：1. 过拟合

解决方法：

1. 简化模型、正则化、Dropout、集成学习
2. 数据扩充 Data Augmentation，常见的方法有，平移、旋转、缩放、剪裁、填充、翻转、噪声、颜色变换、清晰度
3. 生成模型 GAN
4. 迁移学习，借用一个在大规模数据集上预训练好的通用模型，并在针对目标任务的小数据集上进行微调 fine-tune

## 第二章 模型评估

### 01 评估指标的局限性

如果不能合理地运用评估指标，不仅不能发现模型本身的问题，而且会得出错误的结论

#### 准确率的局限性

当样本不均衡时，准确率将不能很好评估模型。如当负样本占99%以上时，分类器把所有的样本都预测为负样本也可以获得超高的准确率

#### 精确率与召回率的权衡

精确率 Precision 召回率 Recall，它们的数学表达如下
$$
\begin{array}{c}
\text { Accuracy }=\frac{T P+T N}{T P+F P+T N+F N} \\
\text { Precision }=\frac{T P}{T P+F P} \\
\text { Recall }=\frac{T P}{T P+F N}
\end{array}
$$
用语言描述如下：

Precision，在所有预测为 Positive 的样本中，真正为 Positive 的比例

Recall，在所有为 Positive 的样本中，预测为 Positive 的比例

这两个指标是“准”和“全”的博弈，分类器可能很“准”，但是会因为过于保守，漏掉了很多没有把握的正样本；分类器也可能很“全”，但是会因为过于激进，错判了很多负样本

为了介绍 P-R 曲线，先介绍排序模型：通常，没有一个确定的阈值把得到的结果判定为正样本或负样本，所以我们采用 Top N 返回结果的 Precision 值和 Recall 值来衡量排序模型的性能

P-R 曲线的横轴是召回率，纵轴是精确率，**其 P-R 曲线上的一个点代表着，在某一个阈值下，模型将大于该阈值的结果判定为正样本，小于该阈值的结果判定为负样本，此时返回结果对应的召回率和精确率**

#### 平方根误差的“意外”

离群点 Outlier 会对模型的评估产生负面影响，一个模型可能在95%的时间内表现很好，但是由于5%的标签为离群点，会使得损失函数变得很大

### 02 ROC 曲线

#### 什么是 ROC 曲线？

ROC 曲线是 Receiver Operating Characteristic Curve 的简称，横坐标是假阳性率 FPR，纵坐标为真阳性率 TPR
$$
\begin{array}{l}
F P R=\frac{F P}{N} \\
T P R=\frac{T P}{P}
\end{array}
$$
TPR 也是 Recall 的定义

#### 如何绘制 ROC 曲线？

ROC 曲线是通过不断移动分类器的 “ 阈值” 来生成曲线上的一组关键点的。预测概率大于该阈值的样本会被判为正例，小于该阈值的样本则会被判为负例

实际上这个阈值就是每一个概率值，从高到底的排序

#### 如何计算 AUC？

顾名思义 area under curve 就是曲线下的面积大小，AUC 越大，说明分类器越可能把真正的正样本排在前面，分类性能越好

ROC 曲线一般处于 y = x 这条直线的上方，如果不是只需要把模型预测的概率翻转成 1 - p 就可以得到更好的分类器，所以 AUC 通常在 0.5~1 之间

#### ROC 相比 P-R 曲线有什么特点？

在正负样本不均衡的数据集中，ROC 曲线比 P-R 曲线更加稳定。原因在于 P-R 曲线完全聚焦于正例中，当样本中的负例增加时，FP 将会剧烈地变动，而 TP 和 FN 将会相对稳定

类别不平衡问题中，ROC曲线通常会给出一个乐观的效果估计，所以大部分时候还是PR曲线更好

### 03 余弦距离的应用

#### 为什么在一些场景中要使用余弦相似度而不是欧式距离？

余弦相似度为两个向量 A,B 之间的余弦 $cos(A,B)$，余弦距离为 $1 - cos(A, B)$

当关注的是向量之间的角度，而不关心它们的绝对大小时，选用余弦相似度，并且余弦在高维度下依然保持很好的性质，欧式距离则会受维度的影响，范围不固定，并且含义模糊

#### 余弦距离是否是一个严格定义的距离？

距离满足三性质：正定性，对称性，三角不等式。这里补充一下的范数的三性质：正定性，齐次性，三角不等式，是不是很像？

可以证明余弦距离是不满足三角不等式的：

简单来讲就是举一个反例，也就是0，45，90度分别取一个点即可，或者当三个点在接近一条直线上即可。严格来讲是余弦距离是欧式距离的平方，欧式距离满足三角不等式，那余弦距离不可能满足

### 04 A/B 测试的陷阱

在机器学习领域中，A/B 测试是验证模型最终效果的主要手段

其主要手段是进行用户分桶，即将用户分成实验组和对照组，对实验组的用户施以新模型，对对照组的用户施以旧模型

### 05 模型评估的方法

#### 在模型评估过程中，有哪些主要的验证方法，它们的优缺点是什么？

1. Holdout 检验。这是最简单的方法，它将原始的样本集随机划分为训练集和验证集，用于训练和测试。该方法缺点是：最后的评估结果和集合划分的情况有很大的关系，为了消除这一随机性引入了交叉验证
2. k-fold 交叉验证。将样本分成 k 个大小相等的样本子集，每次把当前子集作为验证集，其余子集作为训练集，最后把 k 次评估指标的平均值作为最终结果
3. 自助法 bootstrap。当数据集比较小不便于划分时，可采用自助法。对于总数为 n 的样本集合，进行 n 次有放回的随机抽样，有的样本会没有被抽出，这部分样本将作为验证集

#### 在自助法中，当 n 趋近无穷大时，最终有多少数据从未被选择过？

先把表达式拿出来，然后取极限
$$
\begin{aligned}
\lim _{n \rightarrow \infty}\left(1-\frac{1}{n}\right)^{n} &=\lim _{n \rightarrow \infty} \frac{1}{\left(1+\frac{1}{n-1}\right)^{n}} \\
&=\frac{1}{\lim _{n \rightarrow \infty}\left(1+\frac{1}{n-1}\right)^{n-1}} \cdot \frac{1}{\lim _{n \rightarrow \infty}\left(1+\frac{1}{n-1}\right)} \\
&=\frac{1}{\mathrm{e}} \approx 0.368
\end{aligned}
$$

### 06 超参数调优

#### 超参数有哪些调优方法？

1. 网格搜索
2. 随机搜索
3. 贝叶斯优化算法，前两个算法会忽略之前的信息，贝叶斯优化则充分利用之前的信息

为了理解[贝叶斯优化](https://zhuanlan.zhihu.com/p/76269142)，需要先解决[高斯过程](https://zhuanlan.zhihu.com/p/75589452) Gaussian Process，为了解决高斯过程还需要解决[多元高斯分布](https://zhuanlan.zhihu.com/p/58987388)...实在是感觉力不从心，还是先放着吧，之后一定要啃一遍白板机器学习

### 07 过拟合与欠拟合

过拟合：训练表现好，测试表现差

欠拟合：训练测试表现都差

#### 降低过拟合和欠拟合的方法？

1. 过拟合
   1. 数据增强
   2. 降低模型复杂度
   3. 正则化方法
   4. 集成学习
   5. Dropout
2. 欠拟合
   1. 添加新特征
   2. 增加模型复杂度
   3. 减小正则化系数
