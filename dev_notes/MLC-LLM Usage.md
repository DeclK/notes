# MLC-LLM Usage

å¦‚ä½•ä½¿ç”¨ MLC-LLM å·¥å…·é“¾ï¼Œéœ€è¦å›ç­”ä»¥ä¸‹é—®é¢˜ï¼š

1. MLC-LLM çš„å®‰è£…å¦‚ä½•è¿è¡Œ
2. å¦‚ä½•æ„å»ºæ¨¡å‹
3. å¦‚ä½•å°†æ¨¡å‹è¿›è¡Œç¼–è¯‘å¹¶è¿è¡Œ

## Concept

- å®‰è£… [tvm unity install](https://llm.mlc.ai/docs/install/tvm.html)

   æœ€ç®€å•çš„æ–¹å¼æ˜¯é€šè¿‡ pre-built package ä¸€é”®å®‰è£…ï¼Œä¸‹é¢æ˜¯å®‰è£…äº† cuda 12.2 ç‰ˆæœ¬çš„ tvm unity

   ```shell
   pip install --pre -U -f https://mlc.ai/wheels mlc-ai-nightly-cu122
   ```

   å¦‚æœéœ€è¦å®‰è£…å…¶ä»– cuda ç‰ˆæœ¬åŒ…ï¼Œå¯ä»¥å» https://mlc.ai/wheels å¯»æ‰¾å¯¹åº”çš„ wheel åŒ…ï¼Œä¸‹è½½åå®‰è£…

   > pip install -pre ä¼šå°† pre-release version packages æ”¾å…¥æœç´¢è·¯å¾„å½“ä¸­

   > tvm unity æ˜¯ tvm çš„ä¸€ä¸ªåˆ†æ”¯ç‰ˆæœ¬ï¼Œä½ å¯ä»¥åœ¨ tvm github çš„ branch ä¸­çœ‹åˆ°ä»–ã€‚å®é™…ä¸Š tvm unity å°±æ˜¯ tvm çš„æœ€æ–°ç‰ˆæœ¬ï¼ŒåŠŸèƒ½å’Œ tvm ä¸€æ ·ï¼Œæä¾›æ¨¡å‹ç¼–è¯‘åŠŸèƒ½

   é™¤æ­¤ä¹‹å¤–è¿˜å¯èƒ½è¦å®‰è£… xgboost

   ```python
   pip install xgboost --force
   ```

   > æˆ‘ä½¿ç”¨ --forece å¼ºåˆ¶å®‰è£…ï¼Œä¹Ÿå¯ä»¥ç”¨ -U æ›´æ–°å®‰è£…

   æ£€éªŒå®‰è£…æ˜¯å¦å®Œæˆ

   ```shell
   python -c "import tvm; print(tvm.__file__)"
   python -c "import tvm; print(tvm._ffi.base._LIB)"
   python -c "import tvm; print(tvm.cuda().exist)"
   ```

- å®‰è£… [mlc-llm install](https://llm.mlc.ai/docs/install/mlc_llm.html)

   æ¨¡å‹éƒ¨ç½²å¯ä»¥åˆ†ä¸ºä¸¤ä¸ªé˜¶æ®µï¼š compile & runtimeï¼Œtvm unity æä¾›äº† compile åŠŸèƒ½ï¼Œè€Œ mlc åˆ™æä¾›äº† runtime åŠŸèƒ½ï¼ˆä¸ªäººç†è§£ï¼‰

   åŒæ ·åœ°ï¼Œé€šè¿‡ä¸‹è½½ wheels è¿›è¡Œæœ¬åœ°å®‰è£…

   ```python
   pip install --pre -U -f https://mlc.ai/wheels mlc-llm-nightly-cu122 mlc-ai-nightly-cu122
   ```

- Overview Function of tvm & mlc-llm

   æˆ‘ä»¬è¦åšçš„äº‹æƒ…éå¸¸æ˜ç¡®ï¼šæ„å»ºæ¨¡å‹ -> ç¼–è¯‘æ¨¡å‹ -> è¿è¡Œæ¨¡å‹

   tvm å…¶å®ä¸ºè¿™ä»¶äº‹æƒ…æä¾›äº†å®Œæ•´çš„èƒ½åŠ›æ”¯æ’‘ï¼šæˆ‘ä»¬å¯ä»¥é€šè¿‡ tvm python api (relax) æ¥å®Œæˆæ¨¡å‹æ„å»ºï¼Œç„¶åå¯¹æ‰€æ„å»ºçš„æ¨¡å‹è¿›è¡Œç¼–è¯‘ï¼Œä½¿å…¶èƒ½å¤Ÿåœ¨å¯¹åº”çš„å¹³å°ä¸Šè¿è¡Œ

   è€Œ mlc-llm åˆ™æ˜¯ä¸€ä¸ªç”± tvm æ”¯æ’‘çš„ï¼Œé¢ç›¸ LLM çš„å¼€å‘ä»“åº“ã€‚mlc-llm åŒ…å«äº†è®¸å¤šç”± tvm python api æ„å»ºçš„è¯­è¨€æ¨¡å‹ã€‚å¹¶ä¸”å®šä¹‰äº†è®¸å¤š chat é…ç½®æ¨¡ç‰ˆï¼Œå¯ä»¥æ–¹ä¾¿åœ°è°ƒç”¨æ¨¡å‹æ¥æ„å»ºå®Œæ•´çš„èŠå¤©åº”ç”¨

- å¦‚ä½•é€šè¿‡ relax (tvm python api) æ¥æ„å»ºæ¨¡å‹ï¼Œå¹¶ç¼–è¯‘è¿è¡Œï¼Œä»¥ linear å±‚ä¸ºä¾‹

   å‚è€ƒ [notebook](https://github.com/mlc-ai/notebooks/blob/main/mlc-llm/tutorial_add_new_model_architecture_in_tvm_nn_module.ipynb) [define_new_models](https://llm.mlc.ai/docs/compilation/define_new_models.html)

   ç›´æ¥è·‘å®˜æ–¹çš„ notebook è‚¯å®šæ˜¯è·‘ä¸é€šçš„ï¼Œç»§æ‰¿äº† tvm æ–‡æ¡£çš„ä¸€è´¯é£æ ¼ğŸ˜‚åŸå› åœ¨äº tvm/relax api å˜åŒ–å¤ªå¿«ï¼Œä½†æ˜¯æ–‡æ¡£å®Œå…¨æ²¡æœ‰è·Ÿä¸Šï¼Œä¸‹é¢å°±æ˜¯å…¶ä¸­ä¸€ä¸ªä¾‹å­

   ```python
   # before
q = q.permute_dims([0, 2, 1, 3])  # [b, h, s, d]
   k = k.permute_dims([0, 2, 1, 3])  # [b, h, t, d]
   v = v.permute_dims([0, 2, 1, 3])  # [b, h, t, d]
   
   # after
q = q.permute_dims(0, 2, 1, 3)  # [b, h, s, d]
   k = k.permute_dims(0, 2, 1, 3)  # [b, h, t, d]
   v = v.permute_dims(0, 2, 1, 3)  # [b, h, t, d]
   ```
   
   æ— æ³•å®Œæˆå¯¹ `nn.KVCache` çš„ä¸€äº›æ“ä½œ

- Expression Node

   

- TIR & AST

   ä¸‹é¢çš„æ•´ç†åŸºæœ¬ä¸Šæ¥è‡ªäº [TVM è‡ªåº•å‘ä¸Šï¼ˆäºŒï¼‰ï¼šTIR çš„æ¦‚å¿µå’Œç¼–è¯‘åŸç†](https://zhuanlan.zhihu.com/p/533161438)

   TIR æ˜¯ TVM ä¸­æœ€æ¥è¿‘ç›®æ ‡ç¡¬ä»¶çš„æ•°æ®ç»“æ„ï¼Œæ˜¯å¯ä»¥è¢«ç¼–è¯‘ä¸ºç›®æ ‡ç¡¬ä»¶ç¼–ç¨‹è¯­è¨€ï¼ˆC++ã€CUDAã€LLVM IRç­‰ï¼‰çš„ä¸­é—´è¡¨ç¤ºã€‚å¯¹äºæ²¡æœ‰å­¦ä¹ è¿‡ç¼–è¯‘åŸç†çš„è¯»è€…è€Œè¨€ï¼Œä¼šæ¯”è¾ƒéš¾ä»¥ç†è§£ï¼š**å„ç§ç¼–ç¨‹è¯­è¨€çš„è¯­æ³•ï¼ŒåŒºåˆ«éƒ½éå¸¸å¤§ï¼Œé‚£ä¹ˆ TIR æ˜¯å¦‚ä½•åšåˆ°å¯ä»¥ç¼–è¯‘ä¸ºä»»ä½•ä¸€ç§è¯­è¨€çš„ï¼Ÿ**

   **è¿™é‡Œå°±è¦å¼•å…¥ä¸€ä¸ªæ–°çš„æ¦‚å¿µï¼Œå«æŠ½è±¡è¯­æ³•æ ‘ï¼ˆAbstract Syntax Treeï¼Œä»Šåéƒ½ç®€ç§°ä¸º ASTï¼‰ã€‚ä¸ç®¡ä»»ä½•ç¼–ç¨‹è¯­è¨€ï¼Œæœ‰ä»€ä¹ˆç‰¹æ€§å¦‚ä½•ï¼Œè¯­æ³•å¦‚ä½•ï¼Œä¸€æ®µç¨‹åºéƒ½æ˜¯å¦‚ä¸‹å…ƒç´ ç»„æˆçš„ï¼š**

   - **å˜é‡çš„å£°æ˜ã€å˜é‡åˆå§‹åŒ–ï¼ˆèµ‹å€¼æˆ–è€…å†…å­˜åˆ†é…ï¼‰**
   - **å˜é‡çš„è¿ç®—ï¼ˆå››åˆ™è¿ç®—ã€å¸ƒå°”è¿ç®—ç­‰ï¼‰ã€å‡½æ•°çš„è°ƒç”¨**
   - **æµç¨‹çš„æ§åˆ¶ï¼ˆif-else æ¡ä»¶åˆ¤æ–­ï¼Œå¾ªç¯ç­‰ï¼‰**

   **é‚£ä¹ˆï¼Œä»»ä½•ä¸€æ®µä»£ç ï¼Œéƒ½å¯ä»¥è¡¨è¾¾ä¸ºç±»ä¼¼äºå¦‚ä¸‹çš„æ ‘ç»“æ„ï¼š**

   <img src="MLC-LLM Usage/image-20240323151539137.png" alt="image-20240323151539137" style="zoom:50%;" />

   é€šå¸¸ï¼ŒAST æ˜¯æŒ‰ç…§ä¸­åºéå†æ¥é˜…è¯»çš„ï¼Œé‚£ä¹ˆï¼Œä¸Šé¢çš„ä»£ç ç¿»è¯‘ä¸º C++ï¼Œå°±æ˜¯ï¼š

   ```c++
   void main(int x) {
       if (x < 5) {
           x = x * 2;
       }
   }
   ```

   ç¿»è¯‘æˆ Pythonï¼Œå°±æ˜¯ï¼š

   ```python
   def main(x):
       if x < 5:
           x = x * 2
   ```

   **å³ä½¿ C++ å’Œ Python çš„è¯­æ³•ä¸åŒï¼Œåªè¦å®ç°ç›¸åº”çš„ç¿»è¯‘å™¨ï¼ˆä¹Ÿå°±æ˜¯ CodeGenï¼‰ï¼Œåœ¨ä¸­åºéå†çš„è¿‡ç¨‹ä¸­ï¼Œå°†æ ‘èŠ‚ç‚¹ç¿»è¯‘ä¸ºç›¸åº”è¯­æ³•çš„å­—ç¬¦ä¸²ï¼Œå°±å¯ä»¥å¾—åˆ°æœ€ç»ˆçš„æºä»£ç äº†ã€‚**

   <img src="MLC-LLM Usage/image-20240323151942538.png" alt="image-20240323151942538" style="zoom:50%;" />

   **æœ‰äº† ASTï¼ŒTIR å°±èƒ½è§£å†³å¦‚ä¸‹ç—›ç‚¹ï¼šç›¸åŒçš„è®¡ç®—æŒ‡ä»¤ã€åŠ é€ŸæŒ‡ä»¤åœ¨ä¸åŒç¡¬ä»¶ä¹‹é—´çš„è½¬æ¢ã€‚**

   ç›®å‰å¯¹ AST æœ‰äº†ä¸€å®šäº†è§£ï¼Œé‚£åˆ°åº•ä»€ä¹ˆæ˜¯ TIR å‘¢ï¼Ÿå¦‚ä½•æ„å»ºä¸€ä¸ª TIRï¼Ÿå¹¶ä¸” TIR åˆæ˜¯å¦‚ä½•è½¬å˜ä¸º AST çš„ï¼Ÿ

   ä»¥ä¸‹æ˜¯ä¸ªäººç†è§£ï¼š

   > TensorIR å°±æ˜¯ AST æœ¬èº«ï¼Œè€Œé€šå¸¸æˆ‘ä»¬æ‰€è¯´çš„ TensorIR æ˜¯ TensorIR AST çš„ç®€ç§°ï¼Œä¸ºäº†è®©æ¦‚å¿µå˜å¾—æ›´åŠ æ¸…æ™°å°† TensorIR code & TensorIR AST è¿›è¡ŒåŒºåˆ†
   >
   > AST å¯ä»¥ç¿»è¯‘æˆä¸ºå„ç§è¯­è¨€ï¼Œä½†æˆ‘ä»¬é€šå¸¸éœ€è¦é€‰æ‹©ä¸€ç§ä¸»è¯­è¨€æ¥å®Œæˆ TensorIR code ä¸ TensorIR AST ä¹‹é—´çš„è½¬æ¢ï¼Œè€Œ python æ˜¾ç„¶æ˜¯ä¸€ä¸ªä¸é”™çš„é€‰æ‹©
   >
   > ä½¿ç”¨ Python æ‰€å®ç°çš„ python TensorIR codeï¼Œæˆ‘ä»¬å°±ç§°ä¹‹ä¸º TVMScriptã€‚TVMScript å€ŸåŠ© python AST èƒ½å¤Ÿå°† code è½¬æ¢ä¸º TensorIR ASTï¼Œä»è€Œå†åˆ©ç”¨å…¶ä»–è¯­è¨€çš„ CodeGen è½¬æ¢ä¸ºå…¶ä»–è¯­è¨€ã€‚

- IRModule & PrimFunc & CodeGen

   ä½¿ç”¨ TVMScrip æ¥ç¼–å†™ python TensorIR code æœ‰å‡ ä¸ªé‡è¦çš„ç»„ä»¶ï¼š

   1. IRModuleï¼ŒIRModule æ˜¯å¯ä»¥è¢«ç¼–è¯‘çš„æœ€å°å•å…ƒï¼Œæ‰€æœ‰çš„ TensorIR code éƒ½å¿…é¡»åœ¨ IRModule ä¸­å®ç°
   2. PrimFuncï¼ŒPrimFunc æ˜¯ä¸€ä¸ªå®Œæ•´çš„å‡½æ•°ï¼Œèƒ½å¤Ÿä½œä¸º API å…¥å£è¢«ç¼–è¯‘åçš„ IRModule è°ƒç”¨

   ```python
   import tvm
   from tvm.ir.module import IRModule
   from tvm.script import tir as T
   import numpy as np
   
   @tvm.script.ir_module
   class MyModule:
       @T.prim_func
       def main(a: T.handle, b: T.handle):
           # We exchange data between function by handles, which are similar to pointer.
           T.func_attr({"global_symbol": "main", "tir.noalias": True})
           # Create buffer from handles.
           A = T.match_buffer(a, (8,), dtype="float32")
           B = T.match_buffer(b, (8,), dtype="float32")
           for i in range(8):
               # A block is an abstraction for computation.
               with T.block("B"):
                   # Define a spatial block iterator and bind it to value i.
                   vi = T.axis.spatial(8, i)
                   B[vi] = A[vi] + 1.0
   
   
   ir_module = MyModule
   print(type(ir_module))
   print(ir_module.script())
   ```

   3. Compileï¼Œç¼–è¯‘ IRModuleï¼Œçœ‹ä¸‹æ•ˆæœ

   ```python
   import numpy as np
   
   mod = tvm.build(ir_module, target="llvm")
   # mod = tvm.build(ir_module, target="cuda")
   
   a = tvm.nd.array(np.arange(8).astype("float32"))
   # [0. 1. 2. 3. 4. 5. 6. 7.]
   
   b = tvm.nd.array(np.zeros((8,)).astype("float32"))
   mod(a, b)
   # [1. 2. 3. 4. 5. 6. 7. 8.]
   ```

   `tvm.build` çš„æœ€åä¸€ä¸ªå‚æ•° targetï¼Œå°±æ˜¯ç”¨æ¥é€‰æ‹©ç”¨å“ªä¸€ä¸ª CodeGen æ¥ç¼–è¯‘ TIR AST

   > TIR AST -> C++/CUDA -> bin

- Algebraic Data Types (ADTs)

   é€šè¿‡ç»„åˆæ—§çš„æ•°æ®ç±»å‹æ¥å®šä¹‰æ–°çš„æ•°æ®ç±»å‹

   > ADTs are trying to define new types by combining exsisting types. (result from GPT)

- Expression & Statement

   [TVM è‡ªåº•å‘ä¸Šï¼ˆäºŒï¼‰ï¼šTIR çš„æ¦‚å¿µå’Œç¼–è¯‘åŸç†](https://zhuanlan.zhihu.com/p/533161438)

   CodeGenC ä¼šéå†åˆ°ä¸¤ç§ TIR Nodeï¼šExpressionï¼ˆè¡¨è¾¾å¼ï¼‰ å’Œ Statementï¼ˆè¯­å¥ï¼‰ã€‚Expressionï¼ˆè¡¨è¾¾å¼ï¼‰ä¸­åŒ…å«äº†å¸¸è§çš„å˜é‡å£°æ˜ã€è¿ç®—ã€åˆ¤æ–­ã€å‡½æ•°è°ƒç”¨ï¼Œè€Œ Statementï¼ˆè¯­å¥ï¼‰ä¸­åŒ…å«äº†æ§åˆ¶æµï¼ˆif-elseï¼ŒLoop ç­‰ï¼‰ã€å†…å­˜ç®¡ç†ã€èµ‹å€¼ï¼ˆAssignmentï¼‰ç­‰æ“ä½œ

- Frontend & Backbend & RelayIR & TensorIR

   [TVM åŸºæœ¬æ¡†æ¶å’Œæ¦‚å¿µ](https://zhuanlan.zhihu.com/p/532873577)

   å‘ä¸Šï¼Œå…¼å®¹æ‰€æœ‰ä¸åŒçš„æ·±åº¦å­¦ä¹ æ¡†æ¶ï¼ˆä¹Ÿå« frontendï¼‰ï¼Œä¾‹å¦‚ pytorchã€TensorFlowã€onnx

   å‘ä¸‹ï¼Œå…¼å®¹æ‰€æœ‰ä¸åŒçš„åº•å±‚ç¡¬ä»¶å’Œæ¨ç†æ¡†æ¶ï¼ˆä¹Ÿå« backendï¼‰ï¼ŒåŒæ—¶æ€§èƒ½æœ€å¤§åŒ–ï¼Œä¾‹å¦‚ x86 cpuã€arm cpuã€mali gpuã€nvidia gpu

   **å› æ­¤ï¼Œä¸ºäº†è¦†ç›–ä¸Šè¿°çš„å…¨éƒ¨åœºæ™¯ï¼ŒTVM ä¸­å¼•å…¥äº†ä¸¤ä¸ª IR**ï¼ˆIntermediate Representationï¼Œå³ä¸­é—´è¡¨ç¤ºï¼‰ï¼š

   1. ä¸ºäº†å‘ä¸Šå…¼å®¹çš„ **Relay IR**ï¼ˆç®€ç§° Relayï¼‰ï¼ŒåŸºäºä¸åŒæ·±åº¦å­¦ä¹ å¹³å°è®­ç»ƒå¥½çš„æ¨¡å‹ï¼Œåœ¨è¿›å…¥ TVM åéƒ½ä¼šé¦–å…ˆè¢«è½¬æ¢ä¸º Relay çš„è¡¨ç¤ºï¼Œæ¶ˆé™¤è¡¨ç¤ºå·®å¼‚ï¼›

   2. ä¸ºäº†å‘ä¸‹å…¼å®¹çš„ **Tensor IR**ï¼ˆç®€ç§° TIRï¼‰ï¼Œæ‰€æœ‰æ¨¡å‹åœ¨ç¼–è¯‘ä¸ºæŒ‡å®šç¡¬ä»¶ä¸Šçš„æºä»£ç ä¹‹å‰ï¼Œéƒ½è¦å…ˆ lower ä¸º TIRã€‚

      ![image-20240319111441580](MLC-LLM Usage/image-20240319111441580.png)

   ä¸ºä»€ä¹ˆè¦ä½¿ç”¨ä¸¤ç§ IRï¼Œä¸ºä»€ä¹ˆä¸åªè®¾è®¡ TensorIRï¼Œç›´æ¥ä» onnx -> cuda ä¸€æ­¥åˆ°ä½ã€‚ä¸ªäººç†è§£æœ‰ä»¥ä¸‹åŸå› ï¼š

   1. ä» pytorch/onnx è¡¨ç¤ºåˆ° CUDA è¡¨ç¤ºæœ‰è®¸å¤šä¼˜åŒ–æ˜¯å¯ä»¥è¿›è¡Œçš„ï¼Œåœ¨è¿™ä¸ªè¿‡ç¨‹ä¸­ï¼Œä½¿ç”¨å±‚çº§å¼çš„ä¼˜åŒ–æ˜¯æ›´å®¹æ˜“å®ç°çš„
   2. æ›´é«˜æŠ½è±¡çš„ IR æœ‰åˆ©äºå¿«é€Ÿåœ°è¡¨ç¤ºè®¡ç®—å›¾ï¼Œä¾‹å¦‚åœ¨ TVM ä¸­é€šå¸¸å°±ä¼šä½¿ç”¨ Relax IR æ¥å¿«é€Ÿæ­å»ºç½‘ç»œã€‚ä¹Ÿå°±æ˜¯è¯´æˆ‘ä»¬å¯ä»¥ç›´æ¥èˆå¼ƒä» ONNX/pytorch è½¬ Relax/RelayIR çš„è¿™ä¸ªè¿‡ç¨‹ï¼Œç›´æ¥ä½¿ç”¨ IR æ¥æ­å»ºç½‘ç»œ
   3. æ›´é«˜æŠ½è±¡çš„ IR æœ‰åˆ©äºåœ¨å›¾èåˆå±‚é¢è¿›è¡Œä¼˜åŒ–
   4. æ›´ä½æŠ½è±¡çš„ IR æœ‰åˆ©äºè®¾è®¡æ›´å¤šè¿ç®—ç»†èŠ‚ï¼Œä¾‹å¦‚é¢å‘ä¸åŒçš„ç¡¬ä»¶è®¾è®¡ä¸åŒçš„å¹¶è¡Œæ–¹å¼

## -----


- 

- å¦‚ä½•ä½¿ç”¨ Git-LFS (Large File System)

   git-lfs æ˜¯ç”¨äºç®¡ç† repo ä¸­çš„å¤§å‹æ–‡ä»¶ã€‚å®‰è£…æ–¹å¼ [link](https://packagecloud.io/github/git-lfs/install)

   ```shell
   curl -s https://packagecloud.io/install/repositories/github/git-lfs/script.deb.sh | sudo bash
   apt install git-lfs
   ```

   åœ¨ huggingface ä¸­ clone ä¸€ä¸ªæ¨¡å‹é€šå¸¸ä¼šå…ˆè¿è¡Œ `git lfs install`ï¼Œè¿™ä¸€æ­¥å°±ä¼šå¯¹ git è¿›è¡Œå…¨å±€çš„è®¾ç½®ï¼Œèƒ½å¤Ÿåœ¨ä½¿ç”¨ `git clone` çš„æ—¶å€™ä¸‹è½½ä»“åº“ä¸­çš„ LFS æ–‡ä»¶ï¼ˆä¸€èˆ¬ä¸ºæ¨¡å‹æƒé‡ï¼‰

   ```shell
   git lfs install
   git clone https://huggingface.co/openai-community/gpt2
   # If you want to clone without large files - just their pointers
   GIT_LFS_SKIP_SMUDGE=1 git clone https://huggingface.co/openai-community/gpt2
   ```

   è¿™é‡Œçš„è®¾ç½®æ˜¯å…¨å±€çš„ï¼Œåªç”¨è®¾ç½®ä¸€æ¬¡ã€‚ä½†æ˜¯æœ‰æ—¶å€™ä»“åº“ä¸­æœ‰å¾ˆå¤š LFS æ–‡ä»¶ï¼Œå¹¶ä¸æ˜¯æ‰€æœ‰çš„æ–‡ä»¶éƒ½æ˜¯æˆ‘ä»¬éœ€è¦çš„ï¼Œæ‰€ä»¥å¯ä»¥ä½¿ç”¨å¦‚ä¸‹æ–¹æ³•

   ```shell
   # skip lfs globally
   git lfs install --skip-smudge
   # clone repo first
   git clone https://huggingface.co/openai-community/gpt2
   
   # pull certain file you need
   git lfs pull --include "model.safetensors"
   # pull all lfs
   git lfs pull
   ```

   æˆ‘ä»¬å…ˆ clone ä»“åº“ï¼Œç„¶åå†è¿›å…¥ä»“åº“ï¼Œå¯¹è¯¥ä»“åº“è¿›è¡Œå•ç‹¬çš„é…ç½®ï¼Œæœ€åä½¿ç”¨ `git lfs pull` å•ç‹¬ä¸‹è½½ LFS æ–‡ä»¶

   å¯ä»¥é€šè¿‡ `git lfs uninstall` æ¥å–æ¶ˆé…ç½®

- Models and model lib

   æƒ³è¦ä½¿ç”¨ mlc-llm è¿è¡Œä¸€ä¸ª chat model éœ€è¦ä¸¤ä»¶äº‹æƒ…ï¼šç¬¦åˆ mlc è¦æ±‚çš„æ¨¡å‹æƒé‡å’Œæ¨¡å‹åº“ï¼ˆmodel weights and model libraryï¼‰

   è·å–é€”å¾„æœ‰ä¸¤ä¸ª

   1. ä½¿ç”¨ mlc-llm å·²ç»å‡†å¤‡å¥½çš„æ¨¡å‹æƒé‡ [model cards hf](https://huggingface.co/mlc-ai)ï¼Œæ¨¡å‹åº“ [binary-mlc-llm-libs](https://github.com/mlc-ai/binary-mlc-llm-libs)

      ```python
      # Download pre-conveted weights
      git lfs install && mkdir dist/
      git clone https://huggingface.co/mlc-ai/Llama-2-7b-chat-hf-q4f16_1-MLC \
                                         dist/Llama-2-7b-chat-hf-q4f16_1-MLC
      
      # Download pre-compiled model library
      git clone https://github.com/mlc-ai/binary-mlc-llm-libs.git dist/prebuilt_libs
      ```

   2. è‡ªå·±ç¼–è¯‘æ¨¡å‹æƒé‡å’Œæ¨¡å‹åº“ [convert model weights via mlc](https://llm.mlc.ai/docs/compilation/convert_weights.html)ï¼Œ[compile model libraries](https://llm.mlc.ai/docs/compilation/compile_models.html)

- ä½¿ç”¨ Python API è¿è¡Œ chat model

- é…ç½® MLCChatï¼Œmlc-llm æä¾›ä¸¤ä¸ª dataclass æ¥è®¾å®šé…ç½®

- **Convert Model Weights** and **Compile Model Library**

   pre-request: tvm unity compiler & mlc_chat

   ç›´æ¥ä» huggingface ä¸Šæ‹‰å–æ¨¡å‹ï¼Œç„¶åä½¿ç”¨å‘½ä»¤è¡Œå·¥å…·è½¬æ¢

   ```python
   # Create directory
   mkdir -p dist/models && cd dist/models
   # Clone HF weights
   git lfs install
   git clone https://huggingface.co/togethercomputer/RedPajama-INCITE-Instruct-3B-v1
   cd ../..
   # Convert weight
   mlc_chat convert_weight ./dist/models/RedPajama-INCITE-Instruct-3B-v1/ \
       --quantization q4f16_1 \
       -o dist/RedPajama-INCITE-Instruct-3B-v1-q4f16_1-MLC
   ```

   æ•™ç¨‹è¿˜è®©æˆ‘ä»¬ç”Ÿæˆ MLC Chat Configï¼Œä¸ºä¹‹åç”Ÿæˆ model libraries æä¾›ä¸€äº›ä¿¡æ¯

   ```shell
   mlc_chat compile ./dist/RedPajama-INCITE-Chat-3B-v1-q4f16_1-MLC/mlc-chat-config.json \
       --device cuda -o dist/libs/RedPajama-INCITE-Chat-3B-v1-q4f16_1-cuda.so
   ```

## Question

- mlc-llm ä¼¼ä¹æ²¡æœ‰ tvm çš„ auto tune åŠŸèƒ½ï¼Œè€Œæ˜¯é€‰æ‹©ä½¿ç”¨æ‰‹å·¥å®ç° tirï¼Œä¼¼ä¹åˆå›åˆ°äº†æ‰‹å·¥è®¾è®¡ç®—å­çš„æ—¶ä»£ [[Question] performance optimization](https://github.com/mlc-ai/mlc-llm/issues/1800)ã€‚ç°åœ¨ AutoTune è¿™ä¸ªåŠŸèƒ½å·²ç»ä¸æ˜¯å…¶æœ€å¤§çš„å–ç‚¹äº†ï¼
- mlc container on Orin [github](https://github.com/dusty-nv/jetson-containers/tree/dev/packages/llm/mlc)
