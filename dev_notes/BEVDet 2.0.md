# BEVDet 2.0

æƒ³è¦å­¦ä¹ çš„ç‚¹ï¼š

- [ ] CUDA
- [x] BEV Aug
- [ ] æ—¶åºæ•°æ®å¤„ç†ï¼ˆæ€»æ„Ÿè§‰è¿™é‡Œæœ‰æ›´å¥½çš„æ—¶åºå¤„ç†æ–¹å¼ï¼Œå¯ä»¥å€Ÿç”¨LLMä¸­å¤„ç†ä¸Šä¸‹æ–‡çš„èƒ½åŠ›
- [ ] TEHI æ•´ç†

## é˜…è¯»è®ºæ–‡ç¬”è®°

### BEVDet

- BEV augmentation

  åœ¨è®­ç»ƒè¿‡ç¨‹ä¸­ä½œè€…å‘ç°äº†è¿‡æ‹Ÿåˆç°è±¡ï¼ŒåŸå› å¯èƒ½åœ¨äºä»å›¾åƒç©ºé—´è½¬ç§»åˆ°BEVç©ºé—´æ—¶ï¼Œå›¾åƒçš„å¢å¹¿ä½œç”¨å¹¶ä¸èƒ½åŒæ ·ä½¿ç”¨äºBEVç©ºé—´ã€‚ä¸ºè§£å†³è¿™ä¸ªé—®é¢˜æå‡ºäº†åœ¨ BEV ç©ºé—´ä¸‹çš„å¢å¹¿

- Scaled-NMS ä»¥ç§»é™¤é‡å é€‰æ¡†

### BEVDet4D

- Align features

  éœ€è¦å°†è¿ç»­ä¸¤å¸§çš„å›¾åƒè¿›è¡Œè¿æ¥ï¼Œéœ€è¦å¯¹ä¸¤ä¸ªå¸§çš„ç‰¹å¾ç©ºé—´è¿›è¡Œç»Ÿä¸€ï¼Œæœ¬è´¨å°±æ˜¯åæ ‡ç³»çš„è½¬æ¢ï¼Œç„¶åå† concat èµ·æ¥ã€‚é—®é¢˜åœ¨äºå¯¹äºç§»åŠ¨ç‰©ä½“çš„ç‰¹å¾å¦‚ä½•ç»Ÿä¸€

## ä»£ç é˜…è¯»

### Install

1. pytorch 1.11+cu113

2. mmlab related

   ```shell
   pip install mmcv-full==1.5.3 -f https://download.openmmlab.com/mmcv/dist/cu113/torch1.11.0/index.html
   
   pip install mmdet==2.25.1 mmsegmentation==0.25.0
   ```

3. other packages

   ```shell
   pip install pycuda \
       lyft_dataset_sdk \
       networkx==2.2 \
       numba==0.53.0 \
       numpy \
       nuscenes-devkit \
       plyfile \
       scikit-image \
       tensorboard \
       trimesh==2.35.39
   ```

4. project itself

   ```shell
   pip install -v -e .
   ```

5. Dataset

   é¦–å…ˆå°† `tools/create_data_bevdet.py` ä¸­çš„ trainval æ”¹æˆ miniï¼Œå› ä¸ºæˆ‘åªæœ‰ mini åœ¨æ‰‹ä¸Šã€‚ç„¶å

   ```python
   python tools/create_data_bevdet.py
   ```

   ä½¿ç”¨ `samples_per_gpu=1` æˆåŠŸè·‘é€šï¼è¯´æ˜ BEVDet è¿˜æ˜¯éå¸¸å¹²å‡€çš„ç»“æ„ï¼Œä¸€è·¯å®‰è£…å®Œå…¨æ²¡å‘

### Dataset

ä½¿ç”¨ mmdet3d ä¸­çš„ `nuscenes_converter` å®Œæˆæ•°æ®å¤„ç†ï¼Œå…¶ä¸­å­—æ®µå¯ä»¥åœ¨ [nus](https://mmdetection3d.readthedocs.io/zh_CN/latest/datasets/nuscenes_det.html#) ä¸­æŸ¥çœ‹

æ²¡æœ‰çœ‹åˆ° BEVDet æœ‰å¤„ç†æ—¶åºçš„éƒ¨åˆ†ã€‚

`sweep[sensor2lidar`

### Pipline

#### PrepareImageInputs

- `PrepareImageInputs` æ˜¯ BEVDet è·å¾—æ•°æ®çš„æ ¸å¿ƒæ–¹æ³•ï¼Œç”¨äºè·å¾—ä»¥ä¸‹è¾“å‡º

  ```python
  return (imgs,	# (N_cam, 2, H, W)
   sensor2egos,	# (N_cam, 4, 4)
   ego2globals,	# (N_cam, 4, 4)
   intrins,		# (N_cam, 3, 3)
   post_rots,		# (N_cam, 3, 3) image augmentation rots
   post_trans)	# (N_cam, 3)
  ```

  æ‰€æœ‰çš„æ•°æ®éƒ½æ”¾åœ¨ `results['img_inputs']` å½“ä¸­ã€‚ä¸‹é¢ç»†çœ‹å¦‚ä½•è·å¾—è¿™äº›æ•°æ®

- `for cam_name in cam_names`ï¼Œå¯¹äºæ¯ä¸€ä¸ªç›¸æœº

  - è·å¾—å›¾åƒ `img`

  - ç”Ÿæˆæ•°æ®å¢å¼ºå‚æ•° `img_augs`ã€‚åŒ…æ‹¬ `resize, crop, flip, rotate`ï¼Œè¿™äº›æ•°æ®å¢å¼ºå‡å¯ç”± `PIL` åº“è¿›è¡Œå®Œæˆ

    ```python
        def img_transform_core(self, img, resize_dims, crop, flip, rotate):
            # adjust image
            img = img.resize(resize_dims)
            img = img.crop(crop)
            if flip:
                img = img.transpose(method=Image.FLIP_LEFT_RIGHT)
            img = img.rotate(rotate)
            return img
    ```

    ç›®å‰å›¾åƒæ•°æ®å¢å¼ºä½¿ç”¨çš„å¢å¼ºè¶Šæ¥è¶Šç®€å•ï¼Œä¾‹å¦‚ DINO åªç”¨äº† flip & resize & crop è¿™å‡ ç§ï¼Œå¹¶ä¸”éœ€è¦æ³¨æ„å¯¹æ ‡ç­¾è¿›è¡Œç›¸åº”çš„å¢å¼ºå¤„ç†ã€‚**ä½†æ˜¯ BEV é‡Œæ— æ³•è¿›è¡Œç®€å•å¤„ç†ï¼Œ**å› ä¸ºæ ‡ç­¾å¹¶ä¸å±äºå›¾åƒç©ºé—´ï¼Œè€Œå­˜åœ¨äºä¸‰ç»´ç©ºé—´

  - å›¾åƒçš„å¢å¹¿ä½¿ç”¨äº† `post_rot & post_trans` è¡¨ç¤ºï¼Œèƒ½å¤Ÿå¯¹ rotation, flip, crop åšç»Ÿä¸€çš„è¡¨ç¤ºã€‚å˜æ¢çŸ©é˜µé’ˆå¯¹çš„æ˜¯åƒç´ çš„åæ ‡

    ```python
    # pixel coords (x, y), (0, 0) is left corner
    new_coords = post_rot @ coords + post_trans
    ```

#### LoadAnnotationsBEVDetpth

- è·å¾—ä¸‰ç»´é€‰æ¡†çš„æ ‡ç­¾ `gt_boxes, gt_labels`ï¼Œå¹¶å¯¹å…¶ä½¿ç”¨æ•°æ®å¢å¼ºï¼Œå¹¶è®°å½•å…¶å¢å¼ºå‚æ•°ä¸º `bda_rot`

### BEVDet

- BEVDet ç»§æ‰¿äº CenterPointï¼Œåº”è¯¥åªç”¨ head éƒ¨åˆ†

- `self.extract_feat` å°±æ˜¯ç”¨äºä»å›¾åƒæå– BEV ç‰¹å¾çš„

  - `prepare_inputs` åŸºæœ¬ä¸Šä»€ä¹ˆéƒ½æ²¡å¹²ï¼Œåªæ˜¯å¤šäº†ä¸€ä¸ª `sensor2keyegos`ï¼Œè¿™ä¸ªçŸ©é˜µæ˜¯ `(B, N_cam, 4, 4)`ï¼Œå®Œå…¨å¯ä»¥ç†è§£ä¸º `sensor2egos`ï¼Œå› ä¸º keyego å°±æ˜¯ `CAM_FRONT` æ‰€åœ¨ timestamp æ—¶çš„ ego åæ ‡ç³»

  - ä½¿ç”¨ `self.image_encoder` å¯¹å›¾åƒè¿›è¡Œç¼–ç ï¼Œå³ä½¿ç”¨ ResNet + FPN è¿›è¡Œç‰¹å¾æå–ï¼Œè¿”å›ç‰¹å¾ `(B, N_cam, C, H, w)`ã€‚æœ€ç»ˆæ˜¯ 16 å€ä¸‹é‡‡æ ·

  - è·å¾—å›¾åƒç‰¹å¾åå°±è¦å°†ç‰¹å¾è½¬æ¢åˆ° BEV ç©ºé—´ä¸­ï¼Œä½¿ç”¨ `img_view_transformer`ï¼Œè¿™é‡Œå°±æ˜¯ BEVDet çš„**æ ¸å¿ƒæ¨¡å—** `LSSViewTransformer`

    - `LSSViewTransformer` å°†å®Œæˆè½¬æ¢å·¥ä½œï¼Œæ³¨æ„æ­¤ transformer è·Ÿ attention transformer æ²¡æœ‰ä¸€ä¸å…³ç³»

    - `self.craete_grid_infos` é€šè¿‡ grid config

      ```python
      grid_config = {
          'x': [-51.2, 51.2, 0.8],
          'y': [-51.2, 51.2, 0.8],
          'z': [-5, 3, 8],
          'depth': [1.0, 60.0, 1.0],
      }
      ```

      ç®€å•ç”Ÿæˆ3ä¸ªå˜é‡ï¼ˆdepth ä¿¡æ¯è¿™é‡Œæ²¡ç”¨åˆ°ï¼‰

      ```python
      self.grid_lower_bound	# config first col
      self.grid_interval		# config last col
      self.grid_size			# number of grids in each dim
      ```

      è¿™é‡Œçš„ grid å…¨éƒ¨éƒ½æ˜¯æŒ‡çš„ ego åæ ‡ç³»ä¸‹çš„ gridï¼Œè€Œä¸æ˜¯æŒ‡ image åæ ‡ç³»ï¼Œæ‰€ä»¥ç”¨ `x, y, z` æ¥æ ‡è¯†ï¼Œè€Œä¸æ˜¯ `D, H, W` æ ‡è¯†

      è¿™äº›å˜é‡ç”¨äºå°†ä¹‹åçš„ ego åæ ‡ç³»ä¸‹çš„ç‚¹è½¬ä¸º voxel index

    - `self.create_frustum` ä½¿ç”¨ grid config ä¸­çš„ depth ä»¥åŠ `input_size & downsample` æ¥è·å¾— frustum (é”¥å°ï¼Œæˆ–è€…è¯´è¿™é‡Œåº”ç†è§£ä¸ºè§†é”¥)ï¼Œå…¶å½¢çŠ¶ä¸º `(D, H, W, 3)`

      - `input_size & downsample` ç­‰ä»·äºè·å¾— image encoder ä¸­è¾“å‡ºçš„ç‰¹å¾å›¾å½¢çŠ¶
    
      - `grid_config['depth']` è¡¨ç¤ºäº†åœ¨æ·±åº¦ä¸Šçš„é‡‡æ ·ç‚¹
    
        ```python
        d = torch.arange(1, 60, 1)
        # expand to (D, H, W)
        d = d.view(-1, 1, 1).expand(-1, H_feat, W_feat)
        ```

        è¿™é‡Œè¿˜åˆ›å»ºäº†å±æ€§ `self.D = d.shape[0]` å°±æ˜¯æœ‰å¤šå°‘ä¸ª D é‡‡æ ·ç‚¹ï¼Œå½“å‰è®¾ç½®ä¸‹ä¸º 59
    
    - `self.depthnet` æ˜¯ä¸€ä¸ªç®€å•çš„äºŒç»´å·ç§¯

      ```python
      self.depth_net = nn.Conv2d(            in_channels, self.D + self.out_channels, kernel_size=1, padding=0)
      ```

      è¾“å‡ºçš„å‰ `self.D` ä¸ºæ·±åº¦åˆ†å¸ƒé¢„æµ‹ï¼Œåé¢çš„ç»´åº¦ä¸ºç‰¹å¾ç»´åº¦è½¬æ¢

    - **æ ¸å¿ƒ `forward`** 

      - å¯¹ `self.image_encoder` çš„è¾“å‡ºï¼Œä½¿ç”¨ `self.depthnet` è¿›è¡Œç‰¹å¾æå–ï¼Œå¹¶å°†æ·±åº¦å’Œç‰¹å¾é€šé“åˆ†ç¦»ï¼Œç„¶åå¯¹æ·±åº¦ logtis ä½¿ç”¨ softmaxï¼Œè·å¾—å½’ä¸€åŒ–åˆ†å¸ƒ

      - `self.view_transform` è¿›è¡Œç‰¹å¾è½¬æ¢ï¼Œä»¥ä¸‹æ‰€æœ‰æ•´ç†å‡è®¤ä¸º `self.accelerate=False`ï¼Œäº‹å®ä¸Šåœ¨è®­ç»ƒä¸­ä¹Ÿæ˜¯è¿™ä¹ˆé…ç½®çš„ï¼Œè¾“å‡ºä¸¤ä¸ªå¼ é‡ `bev_feat & depth`

        - ä½¿ç”¨ `sefl.get_lidar_coord`ï¼Œå°†ä¹‹å‰å®šä¹‰çš„ `self.frustum` è½¬ä¸ºä¸º ego åæ ‡ç³»ä¸­çš„ç‚¹
    
          é¦–å…ˆå°†é€†è½¬ image augmentation çš„æ•ˆæœ
    
          ```python
                  # post-transformation
                  # B x N x D x H x W x 3
                  points = self.frustum.to(sensor2ego) - post_trans.view(B, N, 1, 1, 1, 3)
                  points = torch.inverse(post_rots).view(B, N, 1, 1, 1, 3, 3)\
                      .matmul(points.unsqueeze(-1))
          ```
    
          ç„¶åæ ¹æ®é€è§†æŠ•å½± perspective projection çš„å…¬å¼
          $$
          Zx=K_f\Pi_0X
          $$
          å°±å¯ä»¥æ±‚å¾—ä¸åŒæ·±åº¦çš„ image frustum å…¶å¯¹åº”çš„ camera åæ ‡ç³»ä¸‹çš„ç‚¹
        
          æœ€åå†é€šè¿‡å¤–å‚è½¬æ¢ä¸º ego åæ ‡ç³»ä¸‹çš„ç‚¹ `coord` å¹¶åŠ å…¥ BEV augmentationï¼Œå½¢çŠ¶ä»ç„¶æ˜¯ `(B, N_cam, D, H, W, 3)`

        - `self.voxel_pooling_v2` èƒ½å¤Ÿå°†ç›¸åŒ voxel çš„ç‰¹å¾è¿›è¡Œæ•´åˆï¼Œä»è€Œå½¢æˆçœŸæ­£çš„ä¸‰ç»´ç©ºé—´ç‰¹å¾ or BEV ç©ºé—´ç‰¹å¾ `bev_feat: (B, Z, Y, X, C) or (B, Y, X, C)`
    
          BEVPool å’Œ BEVPool v2 çš„åŒºåˆ«
        
          ![image-20230522162540636](BEVDet 2.0/image-20230522162540636.png)
        
          çœ‹ä¸Šå›¾æ˜¯éå¸¸å¥½ç†è§£çš„ï¼Œä¹Ÿæ¨èçœ‹å®˜æ–¹çš„æŠ€æœ¯æŠ¥å‘Šï¼Œå¾ˆç®€çŸ­ï¼Œä½†æ˜¯å¾ˆæ¸…æ™°ã€‚è¿™é‡Œå…ˆæŠŠ `self.voxel_pooling_prepare_v2` ç®€å•æ•´ç†
        
          `self.voxel_pooling_prepare_v2` ç”¨æ¥ç”Ÿæˆ `bev_pool_v2` çš„å‰æœŸå‡†å¤‡ï¼Œè¾“å…¥å°±æ˜¯ä¸Šè¿° ego åæ ‡ç³»ä¸‹çš„ `coord` åŒ…æ‹¬å¦‚ä¸‹å˜é‡
        
          ```python
          ranks_bev
          ranks_depth		# range(0, num_points), num_points = B*N_cam*D*H*W
          ranks_feat		# range(0, num_points // D)
          interval_starts
          interval_lengths
          ```
        
          çœ‹ä¸€ä¸‹ `ranks_bev` çš„ä»£ç ï¼Œå°±æ˜¯å°†ç›¸åŒçš„ coord æ’åˆ—åˆ°ä¸€èµ·
        
          ```python
                  # get tensors from the same voxel next to each other
                  ranks_bev = coor[:, 3] * (
                      self.grid_size[2] * self.grid_size[1] * self.grid_size[0])
                  ranks_bev += coor[:, 2] * (self.grid_size[1] * self.grid_size[0])
                  ranks_bev += coor[:, 1] * self.grid_size[0] + coor[:, 0]
                  order = ranks_bev.argsort()
                  ranks_bev, ranks_depth, ranks_feat = \
                      ranks_bev[order], ranks_depth[order], ranks_feat[order]
          ```
      
  
  - è·å¾— `bev_feat` è¿‡åè¿˜è¦å†ç”¨ä¸€ä¸‹ FPNï¼Œç›¸å½“äº OpenPCDet ä¸­çš„ Backbone2Dï¼Œæä¸€ä¸ªå¤šå°ºåº¦å‡ºæ¥

- ç”Ÿæˆ `bev_feat` è¿‡åå°±å¥½åŠäº†ï¼Œç›´æ¥ä¸Š `CenterHead`ï¼Œå®Œäº‹å„¿å•¦ğŸ˜
