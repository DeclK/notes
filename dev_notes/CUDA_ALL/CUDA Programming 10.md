# CUDA Programming 10

Dive into [DeepGemm](https://github.com/deepseek-ai/DeepGEMM/tree/main)

- fp8 é‡åŒ–ï¼Œfp8 scaling è®¡ç®—
- hopper & blackwell gemm ä¼˜åŒ–æŠ€æœ¯
- ç®—å­èåˆ

DeepGemm æœ‰è¶‹åŠ¿è¦å–ä»£æ‰€æœ‰çš„ Gemm å®ç°ï¼Œin a clean & efficient wayã€‚æ‘†è„±äº†å¤æ‚çš„æ¨¡æ¿æ„å»ºï¼Œå¯¹äºå¼€å‘è€…æ¥è¯´æ˜¯æ›´åŠ å‹å¥½çš„å½¢å¼

é¦–å…ˆæˆ‘éœ€è¦çŸ¥é“å¯¹æ¯” Ampereï¼ŒHopper æ¶æ„å‡ºç°äº†å“ªäº›æ–°çš„ä¼˜åŒ–

1. Tensor Memory Acceleration
2. Warp Specialization and Persistant Scheduling
3. Cluster Level Programming

å¯¹æ¯” Hopperï¼ŒBlackwell æ¶æ„çš„ç‰¹æ€§ï¼š

1. ç¬¬äº”ä»£ Tensor Coreï¼Œæ”¯æŒ fp4ï¼Œé€Ÿåº¦æ˜¯ Hopper çš„ 2x~4x [link](https://docs.nvidia.com/cutlass/media/docs/cpp/blackwell_functionality.html)
2. åŸç”Ÿæ”¯æŒ block scaling
3. Tensor Memory ç”¨äºç´¯åŠ å™¨
4. CTA Pair èƒ½å¤Ÿæ¨ªæ¡†ä¸¤ä¸ª SM ååŒå·¥ä½œ

æˆ‘éœ€è¦å¯¹é‡Œé¢çš„ topic é€ä¸ªç†Ÿæ‚‰ï¼Œç„¶åå†æ¥å¯¹ DeepGemm ä»£ç è¿›è¡ŒåŠå­¦ä¹ å¯èƒ½ä¼šæ›´ç®€å•ä¸€äº›

[CalebDu/Awesome-Cute](https://github.com/CalebDu/Awesome-Cute/tree/main) å‚è€ƒ DeepGemm å®ç°äº† cute fp16 çš„ GEMMï¼Œè€Œ DeepGEMM æœ¬èº«ä¼¼ä¹æ›´å€¾å‘äºä½¿ç”¨ cuda æ›´åº•å±‚çš„å‘½ä»¤ã€‚å¯ä»¥å¯¹æ¯”ä¸€ä¸‹äºŒè€…çš„è¡¨ç°å·®å¼‚

## TMA

é¦–å…ˆæ˜ç¡®ä¸€ç‚¹ï¼šTMA ä¼˜åŒ–çš„æ˜¯æ•°æ®ä» global memory åˆ° shared memory è¿™ä¸ªè¿‡ç¨‹ï¼Œæ²¡æœ‰ä¼˜åŒ–ä» shared memory åˆ° registerã€‚

single thread can kick off a tma transfer, from [Deep Dive on the Hopper TMA Unit for FP8 GEMMs â€“ PyTorch](https://pytorch.org/blog/hopper-tma-unit/)

åœ¨ä¸Šé¢çš„ blog å½“ä¸­é¦–å…ˆä»‹ç»äº† TMA çš„å‡ å¤§ä¼˜åŠ¿

1. TMA is very lightweight as only a single thread is needed to kick off a TMA transfer.

   è¿™ä¼šå‡å°‘ register ä½¿ç”¨ã€‚ä¸ºä»€ä¹ˆéœ€è¦ä½¿ç”¨ registerï¼Ÿå› ä¸º global mem <-> shared mem ä¹‹é—´çš„è¿è¾“éœ€è¦ä½¿ç”¨ register æ¥ä¿å­˜äºŒè€…çš„åœ°å€

   <img src="CUDA Programming 10/fg2-3.png" alt="A100-style data movement vs H100 with TMA.  TMA hardware eliminates the need for a large amount of threads and registers participating in bulk data transfers." style="zoom:50%;" />

   ```cpp
   cute::copy(gmem_t, smem_t) // both of them need register to save
   ```

   æ‰€å‡å°‘çš„ register å°±å¯ä»¥ç”¨äºå­˜æ”¾æ›´å¤šçš„æ•°æ®ç”¨äº mma è®¡ç®—

   > Further, within threadblock clusters, producers can lower their max register requirements since they are only issuing TMA calls, and effectively transfer additional registers to MMA consumers, which helps to alleviate register pressure for consumers.

2. A single thread can issue large data movement instructions, allowing the majority of a given thread block to continue working on other instructions while data is in-flight.

   è¿™å‡å°‘äº†çº¿ç¨‹çš„ä½¿ç”¨ã€‚å¤šä½™çš„çº¿ç¨‹å¯ä»¥è¿›è¡Œæ›´å¤šçš„æ“ä½œã€‚ç¡®ä¿äº†å¤§éƒ¨åˆ†çš„çº¿ç¨‹éƒ½æ˜¯ç”¨äºè®¡ç®—ï¼Œé…åˆ async å¯ä»¥æ©è—æ‰æ•°æ®è¿è¾“æ—¶é—´

   > This lightweight invocation for data movement enables the creation of warp-group specialized kernels, where warp-groups take on different roles, namely producers and consumers. Producers elect a leader thread that fires off TMA requests, which are then asynchronously coordinated with the consumer (MMA) warp-groups via an arrival barrier. Consumers then process the data using warp-group MMA, and signal back to the producers when they have finished reading from the SMEM buffer and the cycle repeats.

3. TMA handles the address computation for the shared memory destination where the data requested should be placed. This is why calling threads (producers) can be so lightweight.

   TMA ä¼šè¿›è¡Œåœ°å€è®¡ç®—ï¼Œå°¤å…¶å¯¹äº swizzle layout æ¥è¯´é‡è¦

tma çš„åŸºæœ¬ç”¨æ³•

1. åœ¨ host ä¸Šæ„å»º TmaDescriptor (i.e. cuTensorMap) å¯¹è±¡ï¼Œä¼ å…¥åˆ° kernel å½“ä¸­ã€‚å¹¶ä¸”éœ€è¦ä»¥ `const __grid_constant__ CUtensorMap tensor_map_a` è¿›è¡Œä¿®é¥°

2. åªéœ€è¦ä¸€ä¸ªçº¿ç¨‹è¿›è¡Œ tma æ“ä½œã€‚éœ€è¦ç¡®è®¤ `cute::block(7)` load äº†å“ªä¸€ä¸ª block

3. mbarrier ä½œä¸º tma load çš„åŒæ­¥å·¥å…·ï¼Œlives in shared memory

   arrival count

   transaction bytes

   phase: used for wait, arrive count is hit => phase flip if not the first arrival; else pahse = 0

   ```python
   if arrive_acount is hit:
       if first_arrival:
           phase = 0;
       else:
           phase = flip phase (0 -> 1, 1 -> 0)
   ```

4. fence ä½œä¸º tma store çš„åŒæ­¥å·¥å…·

5. å¯ä»¥ä½¿ç”¨ `SM90_TMA_REDUCE_ADD` æ¥åœ¨ store çš„æ—¶å€™è¿›è¡Œ reduce

   ```python
   for cta_idx in range(number_of_ctas):
     gmem_dst[cta_idx] += smem_src[cta_idx]
     # or this:
     gmem_dst[cta_idx] = max(gmem_dst[cta_idx], smem_src[cta_idx])
     # or this:
     gmem_dst[cta_idx] = min(gmem_dst[cta_idx], smem_src[cta_idx])
   ```

6. tma åœ¨ cluster ä¸­å¯ä»¥å¹¿æ’­ smem æ•°æ®ä»¥è¾¾åˆ°æ•°æ®å¿«é€Ÿ loading (locality)

## wgmma

å‚è€ƒ [blog1](https://research.colfax-intl.com/cutlass-tutorial-wgmma-hopper/) [blog2](https://research.colfax-intl.com/cutlass-tutorial-design-of-a-gemm-kernel/)

ç¬¬ä¸€ç¯‡åšå®¢è¦è®¨è®ºçš„ topic è¿˜æŒºå¹¿æ³›çš„ï¼š

1. wgmma
2. warp specialization & ping pong
3. persistent kernel & stream-K

> We hope that after going through this series, readers will become experts on the GEMM algorithm, and can utilize some of the beautiful ideas that go into this algorithm to design and implement other kernels in their own work.

å¸Œæœ›è¯»å®Œè¿™ä¸ªç³»åˆ—è¿‡åå°±èƒ½æˆä¸º GEMM å¤§å¸ˆï¼

A *warpgroup* consists of four contiguous warps, i.e., 128 contiguous threads

This operation typically follows one of these forms, where matrix `C` serves as the accumulator:

- `C = A * B + C`
- `C = A * B`, where the input from accumulator `C` is disabled.

A notable requirement of WGMMA is that operand `B` must always be stored in shared memory (SMEM). In contrast, operand `A` can be located in either SMEM or register memory (RMEM), and the accumulator `C` is always held in RMEM.

è¿™é‡Œæäº†ä¸€ä¸ªå¾ˆé‡è¦çš„è§„åˆ™ï¼šB çŸ©é˜µä¸€å®šæ˜¯ä¿å­˜åœ¨ shared memory å½“ä¸­çš„ï¼Œè€Œ A çŸ©é˜µæ—¢å¯ä»¥åœ¨ shared memory ä¹Ÿå¯ä»¥åœ¨ global memoryã€‚ç´¯åŠ å™¨ C å¿…é¡»åœ¨ register memory

SM90 MMA atoms are then labeled as `SM90_MxNxK_XYZ_SS` or `SM90_MxNxK_XYZ_RS`

```cpp
TiledMMA tiled_mma = cute::make_tiled_mma(
  SM90_64x64x16_F16F16F16_SS<GMMA::Major::MN,GMMA::Major::MN>{});
```

åœ¨ DeepGEMM å½“ä¸­ï¼Œæ‰€æœ‰çš„ mma éƒ½æ˜¯ä½¿ç”¨ `SS` atomï¼Œä¹Ÿå°±æ˜¯è¯´ Tensor core éƒ½æ˜¯ç›´æ¥åœ¨ shared memory ä¸Šå»è·å¾—æ•°æ®ï¼Œè€Œä¸æ˜¯ register

- `X` and `Y` are the datatypes of the operands.
- `Z` is the datatype of the accumulator.
- `MxNxK` are the tile sizes that the `wgmma` instruction computes with â€” the â€œwgmma atomâ€. Not all values of `MxNxK` are possible. Here is the [list of allowed shapes](https://docs.nvidia.com/cuda/parallel-thread-execution/index.html#asynchronous-warpgroup-level-matrix-shape): `M` is always 64, `N` is a multiple of 8 from 8 to 256, and for 16-bit operand datatype, `K` is 16 (more generally, `K` is fixed to be 32 bytes).

wgmma çš„æ„å»ºå’Œ mma çš„æ„å»ºæ˜¯ç±»ä¼¼çš„ï¼Œéƒ½æœ‰ `AtomLayoutMNK` and `PermutationMNK` 

```cpp
TiledMMA tiled_mma = make_tiled_mma(
 SM90_64x64x16_F16F16F16_SS{},
 Layout<Shape<_2,_1,_1>>{});
```



**smem layout requirements**

1. M N K å¿…é¡»è¦èƒ½å¤Ÿè¢« mma tile shape æ•´é™¤

2. å¯¹ sA å’Œ sB çš„ layout æ ¹æ® swizzle function è€Œå®š

   > However, as a practical matter, we can always construct layouts guaranteed to be compatible with `wgmma` using certain pre-defined layout atoms provided by CUTLASS, followed by the `cute::tile_to_shape` method.

   tile to shape çš„å®é™…ç”¨é€”ã€‚ä¼¼ä¹å¿…é¡»ä½¿ç”¨ `GMMA:Layout_XX` ä¸­çš„ layout æ¥æ„å»º smem layout
   
   These layout atoms must then be passed into `tile_to_shape` with the SMEM shape for `sA` and `sB` given by `make_shape(bM,bK,bP)` or `make_shape(bN,bK,bP)`, with the modes of the shape given **in that order**, such that the tile sizes of the layout atoms divide into those of the larger SMEM shape.
   
   ```cpp
   GMMA::Layout_MN_INTER_Atom<T>
   GMMA::Layout_MN_SW32_Atom<T>
   GMMA::Layout_MN_SW64_Atom<T>
   GMMA::Layout_MN_SW128_Atom<T>
    
   GMMA::Layout_K_INTER_Atom<T>
   GMMA::Layout_K_SW32_Atom<T>
   GMMA::Layout_K_SW64_Atom<T>
   GMMA::Layout_K_SW128_Atom<T>
   ```
   
   è¿™ä¹Ÿçœçš„æˆ‘ä»¬è‡ªå·±å»æ„å»º swizzle äº†ï¼Œåº”è¯¥æ˜¯ä»¶å¥½äº‹å§



The WGMMA-specific thing to notice here is that `tCsA` isnâ€™t actually a thread-level slice of SMEM, but rather the entire SMEM tensor with a reorganized layout.

Next, printing the â€œfragmentsâ€ `tCrA` and `tCrB` for any thread index shows:

```cpp
tCrA: GMMA::DescriptorIterator o (_1,_2,_4,_3):(_0,_64,_256,_1024)
tCrB: GMMA::DescriptorIterator o (_1,_2,_4,_3):(_0,_64,_256,_1024)
```

Internally, CUTLASS constructs a â€œ[matrix descriptor](https://docs.nvidia.com/cuda/parallel-thread-execution/index.html#asynchronous-warpgroup-level-matrix-shared-memory-layout-matrix-descriptor)â€œ, which is 64-bit value held in registers that describes the SMEM in a way suitable for use by the `wgmma` instruction. For the programmer, the most important thing to bear in mind is that values of SMEM are **not** copied into RMEM; rather, accessing the values of `tCrA` and `tCrB` instead accesses these 64-bit descriptors. Moreover, these tensors being â€œiteratorsâ€ means that only the single 64-bit descriptor used for a given `wgmma` instruction is held in registers at a time (e.g., as opposed to all 24 of them).

ä¸Šé¢è¿™ä¸€æ®µè¯ä¹Ÿéå¸¸é‡è¦ï¼šæœ€ç»ˆç”Ÿæˆçš„æ˜¯ä¸€ä¸ª descriptor (just like tma did.)ï¼Œæˆ‘è®¤ä¸ºä¹Ÿç®€åŒ–äº†æˆ‘ä»¬å¯¹ layout çš„æ“ä½œï¼ŒæŠŠæ³¨æ„åŠ›é›†ä¸­äºå¯¹æ•°æ®ä½ç½®çš„æè¿°ï¼Œå‰©ä¸‹çš„äº¤ç»™ cuda å»ç®¡ç†



**synchronization in wgmma**

```cpp
cute::warpgroup_arrive();
cute::gemm(tiled_mma, tCrA(_,_,_,read_pipe), tCrB(_,_,_,read_pipe), tCrC);
cute::warpgroup_commit_batch();
cute::warpgroup_wait<0>();
```

- `warpgroup_arrive` å…¶å®ä¹Ÿæ˜¯ä¸€ä¸ª fenceï¼Œå…¶ä½œç”¨æ˜¯ä¿è¯ warpgroup çš„æ‰§è¡Œä¸€å®šåœ¨ memory æ“ä½œå®Œæˆä¹‹åæ‰§è¡Œã€‚

  > From Kimi
  >
  > **`warpgroup_arrive()` æ˜¯ä¸€é“â€œæŠ¤æ â€ï¼Œå®ƒå‘Šè¯‰ GPUï¼šæœ¬ warpgroup æ‰€æœ‰çº¿ç¨‹å¯¹å¯„å­˜å™¨/å…±äº«å†…å­˜çš„å†™æ“ä½œå·²ç»å®Œæˆï¼Œæ¥ä¸‹æ¥å¯ä»¥å®‰å…¨åœ°è®© `wgmma.mma_async` å»è¯»è¿™äº›åœ°å€ã€‚**
  >
  > `wgmma.mma_async` æ˜¯å¼‚æ­¥çš„ï¼Œç¡¬ä»¶å¯èƒ½æŠŠå®ƒçš„**è¯»æ“ä½œæå‰**ã€‚
  > å¦‚æœä½ åœ¨å®ƒä¹‹å‰è¿˜æœ‰å¾€å…±äº«å†…å­˜æˆ–å¯„å­˜å™¨å†™ A/B çŸ©é˜µæ•°æ®çš„æŒ‡ä»¤ï¼Œè€Œ**ä¸å†™ fence**ï¼Œå°±å¯èƒ½è¯»åˆ°**æ—§å€¼** â†’ ç»“æœé”™è¯¯ã€‚

  ä¸Šé¢çš„è§£é‡Šä¹ŸæŒ‡å‘äº† relaxed consistency modelã€‚ä¹‹å‰æ‰€è§åˆ°çš„æ˜¯ `fence.proxy.async`ï¼Œå…¶æ¶‰åŠåˆ° generic proxy å’Œ async proxy ä¹‹é—´çš„åŒæ­¥ï¼›è€Œåœ¨ wgmma å½“ä¸­çš„æ˜¯ `wgmma.fence.sync.aligned`ï¼Œè¿™å®é™…ä¸Šæ˜¯åœ¨ async proxy å†…éƒ¨çš„åŒæ­¥ï¼Œä¸æ¶‰åŠåˆ° generic proxyã€‚è¿™ä¹Ÿè¯´æ˜äº† relaxed consistency model ä¸ä»…å­˜åœ¨åœ¨ä¸åŒçš„ proxy ä¹‹é—´ï¼Œä¹Ÿå­˜åœ¨åœ¨ asycn proxy å†…éƒ¨ã€‚

- `warpgroup_commit_batch`

  è¿™é‡Œçš„ä½œç”¨ç±»ä¼¼äº `cp_async_fence`ï¼Œå…¶å®æ˜¯ä¸€ä¸ª commit å‘½ä»¤ï¼Œå°†å½“å‰çš„æ‰€æœ‰çš„ wgmma å‘½ä»¤æ‰“åŒ…æäº¤ï¼Œç„¶ååœ¨ä¹‹åä½¿ç”¨ wait å‘½ä»¤ç­‰å¾…å…·ä½“çš„å‘½ä»¤

- `warpgroup_wait`

  å…è®¸æœ€æ–°æäº¤çš„ä»»åŠ¡ä¸­ï¼Œæœ‰æœ€å¤š N ä¸ª wgmma ä»»åŠ¡æœªå®Œæˆã€‚N = 0 è¯´æ˜ç­‰å¾…æ‰€æœ‰çš„ wgmma ä»»åŠ¡å®Œæˆ

**Just like [TMA operations](https://research.colfax-intl.com/tutorial-hopper-tma/), `wgmma.mma_async` is performed in the [async proxy](https://docs.nvidia.com/cuda/parallel-thread-execution/#async-proxy).** 

In situations where the warpgroup has the opportunity to perform independent computation, flexibility with the parameter `N` comes in handy. For example, this comes into play with the GEMM-softmax overlapping strategy employed in the design of [FlashAttention-3](https://research.colfax-intl.com/flashattention-3-fast-and-accurate-attention-with-asynchrony-and-low-precision/).

**wgmma core matrices**

çœ‹ä¸Šå»å¯¹æˆ‘ä»¬æ„å»º kernel æ²¡ä»€ä¹ˆå¤§ç”¨ï¼Œæ„Ÿè§‰æ˜¯å¯¹ wgmma çš„ä¸€äº›åº•å±‚åŸç†ä»‹ç»ï¼šä¸ºä»€ä¹ˆå¯¹ smem layout æœ‰è¿™æ ·çš„è¦æ±‚ã€‚æˆ‘ä¸æƒ³æ·±å…¥æ¢ç´¢è¿™é‡Œçš„åº•å±‚åŸç†ã€‚

> From Kimi
>
> **Core matrix å°±æ˜¯ WGMMA åœ¨ Shared Memory é‡Œèƒ½â€œä¸€æ¬¡æ€§åƒè¿›å˜´é‡Œçš„æœ€å°æ•°æ®å—â€ï¼›è®°ä½å®ƒçš„å¤§å°ã€æ’å¸ƒæ–¹å¼å’Œ swizzling è§„åˆ™ï¼Œå°±èƒ½æŠŠ SMEM å¸ƒå±€å†™å¯¹ã€‚**
>
> ä½ åªéœ€åœ¨ CUTLASS é‡Œé€‰ `Layout_MN_SW128_Atom<>` è¿™ç±»åŸå­å¸ƒå±€ï¼Œå† `tile_to_shape`ï¼Œå°±èƒ½ä¿è¯ LBO/SBO/swizzle éƒ½åˆæ³•ï¼Œä¸å¿…æ‰‹ç®—ã€‚

## Warp Specialization

åœ¨ä»‹ç» warp specialization ä¹‹å‰å…ˆç®€å•ä»‹ç»äº†ä¸€äº›èƒŒæ™¯

1. ç°åœ¨çš„ tensor core è®¡ç®—èƒ½åŠ›è¿œå¼ºäºæ•°æ®çš„è¿è¾“èƒ½åŠ›ï¼Œæ‰€ä»¥ä¸€åˆ‡çš„ä¼˜åŒ–éƒ½å›´ç»•ç€å¦‚ä½•æ‰“æ»¡ tensor core çš„ç®—åŠ›ã€‚è¿™ä¸ªè¿‡ç¨‹å«åš "feading the beast"

2. æ€»ä½“ä¸Šæœ‰ä¸¤ç§ä¼˜åŒ–æŠ€å·§

   1. æœ‰æ•ˆçš„ threadblock schedulingï¼Œä»¥æå‡ L2 cache hits

      we refer curious readers to the techniques of [threadblock rasterization](https://github.com/NVIDIA/cutlass/blob/main/media/docs/efficient_gemm.md#threadblock-rasterization) and persistent kernels, for instance as implemented in CUTLASS.

   2. overlap copying with math computationï¼Œpipeline

è®¨è®ºä¸¤ç§æµæ°´çº¿ï¼šmulti-stage å’Œ warp-specializatioin

With warp-specialization, some warps are dedicated to memory fetches (*producers*), while others are dedicated to compute (*consumers*), and named barriers are used for synchronization between them. The idea is that the warp schedulers can then more easily hide the latency of copy operations within compute

The fastest Ampere GEMM kernels, as well as the famous FlashAttention-2, use the multistage kernel design.

It is not trivial to implement pipelines correctly and efficiently. Programmers must handle the multiple buffers as well as asynchronous load calls across multiple threads. In the next section, we show how to implement pipelining via a CUTLASS abstraction: the `Pipeline` class.

å¯ä»¥ä½¿ç”¨ cutlass ä¸­å®šä¹‰çš„ pipeline class å¿«é€Ÿå®Œæˆæµæ°´çº¿æ­å»ºï¼Œå› ä¸ºæµæ°´çº¿æ­å»ºçœŸçš„ä¸æ˜¯ä¸€ä»¶ç®€å•çš„äº‹æƒ…

buffer: shared memory with N stages

**Barriers.** To synchronize the buffer stages across the producer and the consumer, a Pipeline adheres to the standard *acquire and release model* that uses locks to manage accesses to the buffers. To this end, let `full_barrier` and `empty_barrier` be two arrays of *barrier objects*, both of size `N`. These barrier objects possess a *phase bit* value which is initialized to 0 and flips between 0 and 1.

å®šä¹‰äº† barriers æ¥è¿›è¡Œç®¡ç†è¿™äº› buffersï¼Œä»€ä¹ˆæ—¶å€™ lock ä»€ä¹ˆæ—¶å€™ release

Concretely, these barrier objects will be [mbarrier](https://docs.nvidia.com/cuda/parallel-thread-execution/index.html#parallel-synchronization-and-communication-instructions-mbarrier) objects resident in SMEM. An mbarrier object is initialized both with the aforementioned phase bit as well as an *arrival count*. It then supports arrive-on and wait operations and flips its phase based on reaching the arrival count threshold. Importantly, the values of these barrier objects can and should be visible to all threads.

æœ‰äº†è¿™äº›æ¦‚å¿µè¿‡åå†å»çœ‹ tma çš„ä¸€äº›ä»£ç å°±ä¼šè·Ÿæ¸…æ¥š

é¦–å…ˆå®šä¹‰äº† pipeline stateï¼Œå…¶æœ‰ä¸¤ä¸ªæ ¸å¿ƒæˆå‘˜ index & phaseã€‚pipeline state ä¼šé‡è½½ç®—ç¬¦ `++`ï¼Œæ­¤æ—¶ index ä¼šä¸æ–­é€’å¢ï¼Œç›´è‡³å¢åŠ åˆ° stage number Nï¼Œè€Œ phase åˆ™åœ¨ stage number å¢åŠ åˆ° 0 æ—¶ï¼Œç›¸ä½ç¿»è½¬

```cpp
    void operator++(int) {
      count += 1;
      if ((++stage_idx) == kStage) {
        phase ^= 1;
        stage_idx = 0;
      }
    }
```

é‚£ä¹ˆè¿™ä¸ª pipeline state æ˜¯å¦‚ä½•åŒæ­¥ producer & consumer çš„å‘¢ï¼Ÿ

**Synchronization**. We now explain how the barrier objects and thread-local pipeline states are used to synchronize producers and consumers. To avoid confusion, let us distinguish the producer *action* from the producer thread(s) issuing that action, as these may potentially be decoupled (think of TMA). First, the producer action will flip the phase of `full_barrier[i]` to signal that it has filled the `i`th stage of the buffer, so that the consumer threads can now read from it. Similarly, the consumer threads will flip the phase of `empty_barrier[i]` to signal that they have finished consuming the `i`th stage of the buffer, so that the producer can now write to it.

è¿™æ„å‘³ç€æˆ‘ä»¬æœ‰ N ä¸ª `full_barrier & empty barrier`ï¼Œæ¯ä¸€ä¸ª barrier éƒ½æœ‰ä¸€ä¸ªè‡ªå·±çš„ pipeline stateï¼Ÿarrival count åˆåœ¨å…¶ä¸­æ‰®æ¼”ä»€ä¹ˆè§’è‰²ï¼Ÿarrival count å’Œ stage æ˜¯ç›¸å…³çš„æ¦‚å¿µå—ï¼Ÿ

Finally, each thread, whether consumer or producer, keeps track of a phase to match against the phases of the barrier objects, and in fact threads taking on both consumer and producer roles will need to track *both* phases. These â€œinternalâ€ phases of the threads need to be flipped as well as the kernel proceeds through iterations of its mainloop.

æ•´ä¸ªè¿‡ç¨‹æè¿°ä¸‹æ¥è¿˜æ˜¯æ¯”è¾ƒæŠ½è±¡çš„ï¼Œè¿™æ˜¯å› ä¸ºæè¿°ä¸­ç¼ºå°‘äº†å¯¹ mbarrier å’Œ pipeline state ä¹‹é—´çš„è”ç³»ä¸åŒºåˆ†ï¼š

1. Mbarrierï¼Œç®¡ç†ä¸¤ä¸ªæˆå‘˜ï¼šarrival count & phase
2. PipelineStateï¼Œç®¡ç†ä¸¤ä¸ªæˆå‘˜ï¼šindex & phase

å¯ä»¥çœ‹åˆ°äºŒè€…éƒ½æ‹¥æœ‰å„è‡ªçš„ phaseï¼Œä½†æ˜¯äºŒè€…çš„ phase æ˜¯è”ç³»èµ·æ¥çœ‹å¾…ã€‚

é€šè¿‡é˜…è¯» PTX doc çŸ¥é“äº†å„ä¸ªå‘½ä»¤çš„æœ¬è´¨

1. mbarrier å®é™…ä¸Šæœ‰4ä¸ªæˆå‘˜ï¼šphase, arrive count, pending count, tx-count

   mbarrier çš„[åˆå§‹åŒ–](https://docs.nvidia.com/cuda/parallel-thread-execution/#parallel-synchronization-and-communication-instructions-mbarrier-init)åªä¼ å…¥ä¸€ä¸ª `count`ï¼Œæ­¤æ—¶

   - Initializing the current phase to 0.
   - Initializing the expected arrival count to `count`.
   - Initializing the pending arrival count to `count`.
   - Initializing the *tx-count* to 0.

2. [arrive](https://docs.nvidia.com/cuda/parallel-thread-execution/#parallel-synchronization-and-communication-instructions-mbarrier-arrive-on) ä¼š decreament pending count

3. [expect_tx](https://docs.nvidia.com/cuda/parallel-thread-execution/#parallel-synchronization-and-communication-instructions-mbarrier-expect-tx-operation)(bytes) ä¼šå¢åŠ  tx-count  += bytes

4. tma copy ä¼šè‡ªåŠ¨è°ƒç”¨ [complete_tx](https://docs.nvidia.com/cuda/parallel-thread-execution/#parallel-synchronization-and-communication-instructions-mbarrier-complete-tx-operation)ï¼Œä¼šå‡å°‘ tx-count -= bytes

5. å½“ pending count = 0 ä»¥åŠ tx-count = 0 æ—¶ï¼Œè§¦å‘ [phase complete](https://docs.nvidia.com/cuda/parallel-thread-execution/#parallel-synchronization-and-communication-instructions-mbarrier-phase-completion) æ¡ä»¶ï¼Œæ­¤æ—¶ï¼š

   1. phase flip: phase ^= 1
   2. pending count è¿˜åŸä¼š `count`

æ ¹æ®ä»¥ä¸Šæœºåˆ¶ï¼Œå°±å¯ä»¥é¡ºåˆ©æ¨ç†æ•´ä¸ªæµæ°´çº¿çš„åŒæ­¥è¿‡ç¨‹ã€‚å¦å¤–æ ¹æ® [zhihu](https://zhuanlan.zhihu.com/p/1905383022901059783) çš„è¯´æ³•ï¼šmbarrier.wait åªæ£€æŸ¥current phase çš„å®Œæˆï¼Œå³ phase = 1, barrier.wait(phase)ï¼Œè‹¥ barrier å†…ç½® phase ä¸º 0ï¼Œåˆ™æ­¤ wait ä¸ä¼šç­‰å¾…ã€‚è¿™ä¹Ÿæ˜¯ä¸ºä»€ä¹ˆä¸€å¼€å§‹è¦æŠŠ producer pipeline_state çš„ phase åˆå§‹åŒ–ä¸º 1ã€‚å› ä¸ºåˆå§‹åŒ–æ—¶ä¸å¿…ç­‰å¾… consumer å®Œæˆè®¡ç®—ï¼Œç›´æ¥å‘èµ· tma load



ç”±äº cutlass doc å½“ä¸­çš„ä»£ç å¹¶æ²¡æœ‰è¢« DeepGemm ä¸­é‡‡ç”¨ï¼Œè€Œä¸”æˆ‘æ‰€å­¦ä¹ çš„ cute ws ä»£ç ä¹Ÿæ˜¯å‚è€ƒ DeepGemm æ¥æ„å»ºçš„ï¼Œä¹‹åçš„å­¦ä¹ å…¨é¢é’ˆå¯¹ awesome cute å½“ä¸­çš„ä»£ç å­¦ä¹ 


ä¸ºä»€ä¹ˆè®¾ç½®äº†ä¸¤ä¸ªä¸ä¸€æ ·çš„ arrival countï¼Ÿ

```cpp
static constexpr int ConsumerArvCnt = size(TiledMma{}) * size(ClusterShape{}) / WarpSize;
static constexpr int ProducerArvCnt = 1;

for (int i = 0; i < Stage; i++) {
    shared_storage.pipelines.mainloop_full_bar[i].init(ProducerArvCnt);
    shared_storage.pipelines.mainloop_empty_bar[i].init(ConsumerArvCnt);
}
```

è¿™æ˜¯å› ä¸ºå¯¹äº full barrierï¼Œç”±äº tma æ“ä½œåªéœ€è¦ä¸€ä¸ªçº¿ç¨‹è¿›è¡Œå‘èµ·å³å¯ã€‚è€Œå¯¹äº empty barrer æ¥è¯´ç”±äº simt çš„åŸå› ï¼Œå¯èƒ½æ¯ä¸€ä¸ªçº¿ç¨‹éƒ½ä¼šå‘èµ·ä¸€ä¸ª arrival signalã€‚æ‰€ä»¥åœ¨å…·ä½“çš„ä»£ç é‡Œæœ‰ä¸€ä¸ª predicateï¼Œè®©æ¯ä¸€ä¸ª warp group åªç”±ä¸€ä¸ªï¼ˆæˆ–å¤šä¸ªï¼‰thread å‘èµ· arrival

```cpp
uint32_t lane_idx = threadIdx.x & 31;
uint32_t target_cta = lane_idx;
uint32_t pred_arrive = lane_idx < size(ClusterShape{}); // lane_id thread notify cluster_id cta barrier
// notify producer
shared_storage.pipelines.mainloop_empty_bar[pipeline_states.stage_idx].arrive(target_cta, pred_arrive);
```

å¯ä»¥çœ‹åˆ°ï¼Œå½“ cluser size = 1 çš„æ—¶å€™ï¼Œå…¶å®åªæœ‰æ¯ä¸€ä¸ª warp group çš„ 0 å·çº¿ç¨‹å‘èµ·äº† arrival signalã€‚é‚£ä¹ˆå°±æ­£å¥½ç¬¦åˆ `ConsumerArvCnt` çš„éœ€æ±‚

æå‡ºç–‘é—®ï¼šä¸ºä»€ä¹ˆä¸æŠŠ consumer arrival count ä¹Ÿè®¾ç½®ä¸ºä¸€ï¼Œè®© thread id = 0 çš„çº¿ç¨‹å»å‘èµ·å°±å¥½

> From Grok
>
> å¦‚æœå°† ConsumerArvCnt è®¾ä¸º 1ï¼Œåªè®© threadIdx.x == 0 çš„çº¿ç¨‹æ‰§è¡Œ arriveï¼Œå°±ä¼šå‡ºç°ä»¥ä¸‹é—®é¢˜ï¼š
>
> **æ— æ³•ä¿è¯æ‰€æœ‰çº¿ç¨‹å®Œæˆ**ï¼šthreadIdx.x == 0 çš„çº¿ç¨‹å¯èƒ½åœ¨è‡ªå·±çš„è®¡ç®—å®Œæˆåç«‹å³è°ƒç”¨ arriveï¼Œä½†å…¶ä»–çº¿ç¨‹ï¼ˆä¾‹å¦‚å…¶ä»– warpï¼‰å¯èƒ½å°šæœªå®Œæˆ MMA æ“ä½œã€‚è¿™æ ·ï¼Œempty barrier çš„ phase ä¼šè¿‡æ—©ç¿»è½¬ï¼Œproducer å¯èƒ½å¼€å§‹åŠ è½½æ–°æ•°æ®ï¼Œè¦†ç›– SMEM ä¸­ä»åœ¨è¢«å…¶ä»– warp ä½¿ç”¨çš„å†…å®¹ï¼Œå¯¼è‡´æ•°æ®ç«äº‰å’Œé”™è¯¯ç»“æœã€‚

æˆ‘æœ‰ä¸€ä¸ªç–‘é—®ï¼šåœ¨ä¹‹å‰çš„ SIMT ç¼–ç¨‹æ€æƒ³ä¸‹ï¼Œå†™ if-else åˆ†æ”¯æ˜¯æ•ˆç‡æ¯”è¾ƒä½çš„è¡Œä¸ºã€‚ä¸ºä»€ä¹ˆåœ¨ warp specialization å°±å¯ä»¥è¢«å…è®¸äº†

> From KIMI
>
> ç»å…¸ SIMT ä»¥ 32 çº¿ç¨‹çš„ warp ä¸ºæœ€å°è°ƒåº¦å•ä½ï¼ŒåŒä¸€ä¸ª warp é‡Œçš„çº¿ç¨‹åªè¦æ¡ä»¶ä¸åŒå°±ä¼šé¡ºåºæ‰§è¡Œ if å’Œ else ä¸¤æ®µæŒ‡ä»¤ï¼Œé€ æˆæµªè´¹ã€‚
> Hopper çš„ warp specialization æŠŠç²’åº¦æ‹‰å¤§åˆ°ã€Œæ•´ä¸ª warp-groupã€ï¼ˆé€šå¸¸æ˜¯ 128 çº¿ç¨‹ç”šè‡³ 4-warp-group çš„ 512 çº¿ç¨‹ï¼‰ã€‚ä¹Ÿå°±æ˜¯è¯´ï¼Œåªè¦ä¸€ä¸ª warp-group é‡Œçš„æ‰€æœ‰çº¿ç¨‹éƒ½èµ°åŒä¸€æ¡è·¯å¾„ï¼Œå°±ä¸ä¼šå‡ºç°ä¼ ç»Ÿæ„ä¹‰ä¸Šçš„ divergenceã€‚

è¿™è¯´æ˜æˆ‘ä¹‹å‰å¯¹ SIMT çš„ç†è§£æœ‰é”™è¯¯ï¼Œå…¶èŒƒå›´è¢«é™åˆ¶åœ¨äº† warp å¤§å°å†…ï¼Œè€Œä¸æ˜¯å¯¹æ•´ä¸ª block éƒ½éœ€è¦è¿›è¡Œ SIMTï¼Œåœ¨è¿™æ ·çš„æ„ä¹‰ä¸‹ï¼Œå°±å¯ä»¥è®© producer å’Œ consumer è¿›è¡Œç‹¬ç«‹è¿è¡Œï¼Œè¾¾åˆ° warp specialization çš„åŠŸèƒ½

é™¤æ­¤ä¹‹å¤–ï¼ŒHopper è¿˜å¯¹å¯„å­˜å™¨æœ‰ç€åŠ¨æ€åˆ†é…çš„æœºåˆ¶ï¼Œè¿™ä¹Ÿæ˜¯ä¸ºäº† warp specialization æœåŠ¡

> From DeepSeek
>
> 1. **ä¼ ç»Ÿé™åˆ¶**ï¼šåœ¨Hopperä¹‹å‰ï¼ŒGPU kernelå¯åŠ¨æ—¶**å›ºå®š**æ¯ä¸ªçº¿ç¨‹çš„å¯„å­˜å™¨æ•°é‡ï¼ˆç¼–è¯‘æ—¶æŒ‡å®šï¼‰ï¼Œæ•´ä¸ªkernelæ‰§è¡ŒæœŸé—´æ— æ³•æ”¹å˜
> 2. **Hopperåˆ›æ–°**ï¼š
>    - æ¯ä¸ªçº¿ç¨‹å—(CTA)ç»´æŠ¤ä¸€ä¸ª**å…±äº«å¯„å­˜å™¨æ± **
>    - Warp Groupså¯ä»¥åœ¨è¿è¡Œæ—¶**åŠ¨æ€ç”³è¯·/é‡Šæ”¾å¯„å­˜å™¨**
>    - é€šè¿‡`setmaxnreg`æŒ‡ä»¤å®ç°ï¼ˆPTX 8.0+ï¼‰
>
> `warpgroup_reg_alloc<232>()` å®é™…æ‰§è¡Œ PTX æŒ‡ä»¤ `setmaxnreg.inc.sync.aligned.u32 232;`
>
> - **ä½œç”¨**ï¼šä»CTAå¯„å­˜å™¨æ± **ç”³è¯·æ›´å¤šå¯„å­˜å™¨**
> - **è¡Œä¸º**ï¼š
>   1. å°†å½“å‰warp groupå†…æ¯ä¸ªçº¿ç¨‹çš„å¯„å­˜å™¨ä¸Šé™**æå‡åˆ°232ä¸ª**
>   2. å¦‚æœæ± ä¸­å¯„å­˜å™¨ä¸è¶³ï¼Œ**é˜»å¡ç­‰å¾…**ç›´åˆ°å…¶ä»–warpé‡Šæ”¾å¯„å­˜å™¨
>   3. æ–°å¢çš„å¯„å­˜å™¨å†…å®¹**æœªåˆå§‹åŒ–**ï¼ˆéœ€ç¨‹åºæ˜¾å¼åˆå§‹åŒ–ï¼‰
> - **ä½¿ç”¨åœºæ™¯**ï¼šConsumeréœ€è¦å¤§é‡å¯„å­˜å™¨è¿›è¡ŒMMAè®¡ç®—
>
> `warpgroup_reg_dealloc<40>()` å®é™…æ‰§è¡Œ PTX æŒ‡ä»¤ `setmaxnreg.dec.sync.aligned.u32 40;`
>
> - **ä½œç”¨**ï¼šå‘CTAå¯„å­˜å™¨æ± **é‡Šæ”¾å¤šä½™å¯„å­˜å™¨**
> - **è¡Œä¸º**ï¼š
>   1. å°†å½“å‰warp groupå†…æ¯ä¸ªçº¿ç¨‹çš„å¯„å­˜å™¨ä¸Šé™**é™è‡³40ä¸ª**
>   2. é‡Šæ”¾çš„å¯„å­˜å™¨**ç«‹å³å½’è¿˜**åˆ°CTAå…±äº«æ± 
>   3. åŸå¯„å­˜å™¨å†…å®¹**è¢«ä¸¢å¼ƒ**
> - **ä½¿ç”¨åœºæ™¯**ï¼šProduceråªéœ€å°‘é‡å¯„å­˜å™¨ç®¡ç†TMAåŠ è½½

æˆ‘æŒ‰ç…§ä¸Šé™è®¡ç®—äº†ä¸€ä¸‹æ¯ä¸ª cta æ‰€éœ€è¦çš„å¯„å­˜å™¨ä¸ªæ•°ä¸º 64512 =(40x128 + 232x128x2)ï¼Œä¼šç•¥ä½äºä¸€ä¸ª cta çš„å¯„å­˜å™¨ä¸Šé™ 65536ï¼Œè¿™åº”è¯¥ä¹Ÿæ˜¯ä¸ºäº†æ€§èƒ½è€ƒé‡ï¼Œç•™ä¸€ç‚¹å¯„å­˜å™¨ä½œä¸ºä½™é‡

æˆ‘å‘ç°æŠŠ PTX æ–‡æ¡£ä¸­çš„å†…å®¹ç›´æ¥ä¸¢ç»™ GPT è®©ä»–ä»¬å»æ•´ç†æ€»ç»“å…¶æ„ä¹‰ä¼šæ¯”è‡ªå·±å»è¯»è¦å®¹æ˜“å¾—å¤š

å¯¹äº warp çº§åˆ«çš„æ“ä½œï¼Œé¦–å…ˆè¦è€ƒè™‘çš„å°±æ˜¯æ´—ç‰Œå‡½æ•°ï¼Œåœ¨ä»£ç ä¸­ä¸€å¼€å§‹å°±ç”¨äº†æ´—ç‰Œå‡½æ•°æ¥ç¡®å®š warp group ç›¸å…³çš„ index

```cpp
    auto thread_idx = threadIdx.x;
    auto block_idx = blockIdx.x;
    auto lane_idx = thread_idx & 31;
    auto warp_idx = __shfl_sync(0xffffffff, thread_idx / WarpSize, 0);
    auto warp_idx_in_group = __shfl_sync(0xffffffff, warp_idx % 4, 0);
		auto warp_group_idx =  __shfl_sync(0xffffffff, thread_idx / WarpGroupSize, 0);
```

warp specialization çš„ä»£ç å…¶å®å¾ˆç®€å•ï¼Œå°±æ˜¯ä¸€ä¸ª if-else åˆ†æ”¯

```cpp
   	// WASP: consumer wg0, producer wg1
    // WASP_COOP: consumer wg0 wg1, producer wg2
    // WASP_PIPO: consumer wg0 wg1, producer wg2
    if (warp_group_idx == WarpGroupCnt - 1) {
      // producer
      // alloc 40 register for tma load
      cutlass::arch::warpgroup_reg_dealloc<40>();
      // elect 1 thread issue tma load
      if (warp_idx_in_group == 0 && elect_one_sync()) {
        producer(param, shared_storage, block_rank_in_cluster);
      }
    } else {
      // consumer
      // alloc 232 register for mma compute
      cutlass::arch::warpgroup_reg_alloc<232>();

      if constexpr (kernel_tag == KernelTag::WASP ||
                    kernel_tag == KernelTag::WASP_COOP) {
        ws_consumer(param, shared_storage);
      } else if constexpr (kernel_tag == KernelTag::WASP_PIPO) {
        ws_pipo_consumer(param, shared_storage);
      }
    }
```

åŒæ ·ç”±äº SIMT æ€æƒ³çš„ç–‘æƒ‘ï¼šå¯¹äº producer æ¥è¯´ï¼Œåªæœ‰ä¸€ä¸ª thread åœ¨è¿›è¡Œæ“ä½œï¼Œé‚£å…¶ä»–çš„ thread æ˜¯ä¸æ˜¯å°±æ²¡æœ‰å·¥ä½œäº†ï¼Ÿåœ¨æ­¤æƒ…å†µä¸‹è¿˜ä¼šç»™ä»–ä»¬ä¸€èµ·åˆ†é…å¯„å­˜å™¨ä¹‹ç±»çš„èµ„æºå—ï¼ˆæ ¹æ® SIMT ç¼–ç¨‹åŸåˆ™ï¼‰ï¼Ÿ

å¯¹äºæ­¤é—®é¢˜ï¼ŒDeepSeek å’Œ Kimi çš„å›ç­”éƒ½æ˜¯ï¼šä¼šç»™ä¸å·¥ä½œçš„çº¿ç¨‹ä¹Ÿåˆ†é…èµ„æºï¼Œä½†æ˜¯è¿™äº›çº¿ç¨‹çš„ç¡®ä¸ä¼šå·¥ä½œ

> From Kimi
>
> æ˜¯çš„ï¼Œ**æ•´ä¸ª warp group éƒ½ä¼šè¿›å…¥ producer åˆ†æ”¯**ï¼Œä½†**çœŸæ­£å¹²æ´»çš„åªæœ‰ warp group é‡Œè¢« `elect_one_sync()` é€‰å‡ºæ¥çš„é‚£ä¸€ä¸ª thread**ï¼Œå…¶ä½™ 127 ä¸ª thread åœ¨è¿™æ¡ä»£ç è·¯å¾„ä¸Šå°±æ˜¯â€œç©ºè½¬â€
>
> ä¸è¿‡ï¼Œ**å®ƒä»¬ä»ç„¶ä¼šè¢«ä¸€èµ·åˆ†é…å¯„å­˜å™¨**ï¼Œå› ä¸ºï¼š
>
> 1. **warp æ˜¯è°ƒåº¦/èµ„æºåˆ†é…çš„åŸºæœ¬å•ä½**ã€‚
>    åªè¦ä¸€ä¸ª warp é‡Œæœ‰ä¸€æ¡ thread éœ€è¦æ‰§è¡ŒæŸæ¡æŒ‡ä»¤ï¼Œæ•´ä¸ª warp éƒ½ä¼šè¢«ä¿ç•™ï¼Œå¯„å­˜å™¨ä¹Ÿä¼šæŒ‰ warp ç²’åº¦æ•´ä½“é¢„ç•™ã€‚
> 2. **SIMT æ‰§è¡Œæ¨¡å‹**å†³å®šäº† inactive lane ä¸ä¼šçœŸçš„æ‰§è¡ŒæŒ‡ä»¤ï¼Œä½†**èµ„æºï¼ˆå¯„å­˜å™¨ã€è°ƒåº¦æ§½ï¼‰ä»ç„¶è¢«å ç”¨**ã€‚
>    æ‰€ä»¥ï¼Œå³ä½¿ 127 ä¸ª thread åœ¨ `if (elect_one_sync())` ä¹‹åä»€ä¹ˆä¹Ÿä¸åšï¼Œå®ƒä»¬ä¹Ÿå¿…é¡»ä¿ç•™å¯„å­˜å™¨ä¸Šä¸‹æ–‡ï¼Œä¸èƒ½è¢«åˆ«çš„ warp å¤ç”¨ã€‚

å¦å¤–æˆ‘è¿˜è¯¢é—®äº†ï¼šå¯¹äº producer warp group æ˜¯ 128 ä¸ªçº¿ç¨‹éƒ½ä¼šåˆ†é…å¯„å­˜å™¨å—ï¼Ÿè¿˜æ˜¯ç»™å•ä¸ª warp åˆ†é…å¯„å­˜å™¨å°±è¡Œã€‚ç­”æ¡ˆæ˜¯ç»™ 128 ä¸ªçº¿ç¨‹éƒ½ä¼šåˆ†é…

> From Kimi
>
> åœ¨ Hopper æ¶æ„ï¼ˆSM9xï¼‰çš„ **WGMMAï¼ˆwarpgroup matrix multiply accumulateï¼‰æŒ‡ä»¤é›†**é‡Œï¼Œå¯„å­˜å™¨è°ƒåº¦/åˆ†é…çš„**æœ€å°ç²’åº¦æ˜¯â€œwarp groupâ€**ï¼ˆ4 ä¸ª warpï¼Œ128 lanesï¼‰ï¼Œè€Œ**ä¸æ˜¯å•ä¸ª warpï¼ˆ32 lanesï¼‰**
>
> From DeepSeek
>
> - **è®¾è®¡åˆç†æ€§**ï¼šè™½æœ‰æ•ˆç‡ç‰ºç‰²ï¼Œä½†é€šè¿‡å¯„å­˜å™¨èµ„æºå†åˆ†é… (dealloc & alloc) å’Œç®€åŒ–åŒæ­¥ï¼Œæ•´ä½“æ”¶ç›Šä¸ºæ­£ã€‚è¿™åœ¨å†…å­˜å—é™çš„ GEMM å†…æ ¸ä¸­å°¤ä¸ºå…³é”®ã€‚

## Main Functions

æœ‰å‡ ä¸ªå…³é”®çš„ç»„æˆéƒ¨åˆ†

### Template & helper function

1. Param & Args

   - Args æ˜¯ä¸»æœºç«¯è¾“å…¥ï¼Œç”±ç”¨æˆ·åœ¨ host ç«¯æ„é€ ï¼ŒåªåŒ…å« **åŸå§‹æŒ‡é’ˆ** å’Œ **çŸ©é˜µå°ºå¯¸**ï¼Œæ²¡æœ‰ä»»ä½•è®¾å¤‡ç«¯å¸ƒå±€æˆ–è°ƒåº¦ä¿¡æ¯

   - Param æ˜¯è®¾å¤‡ç«¯æ‰§è¡Œå‚æ•°ï¼ŒåŒ…å«äº† **TMA descriptor objectã€scheduler paramã€problem size** ï¼Œæ˜¯ kernel çœŸæ­£éœ€è¦çš„ä¸œè¥¿ã€‚problem size æ˜¯ args å’Œ param éƒ½æ²¡æ”¹å˜çš„ä¸œè¥¿

   å¦å¤– Param è¿˜éœ€è¦ä¸€äº›ä¿¡æ¯ï¼š`ClusterShape` & `CTATile` & `TMA` ç­‰ç­‰ï¼Œè¿™äº›ä¿¡æ¯æ¥è‡ªäº struct å½“ä¸­çš„æ¨¡æ¿ï¼Œå³å…ƒç¼–ç¨‹æ‰€æ¨å¯¼å‡ºæ¥çš„æ¨¡æ¿ç±»

   - Initialize_param

2. Shared storage

   æ‰€æœ‰æ”¾åœ¨ shared memory ç›¸å…³çš„æ•°æ®éƒ½åœ¨è¿™é‡Œï¼šmatrix ABC & mbarrierã€‚å¦å¤–ï¼Œä»–ä»¬éƒ½ä½¿ç”¨äº† aligned array or alignas æ¥è®©è¿™äº›æ•°æ®åœ¨å†…å­˜åœ°å€ä¸­è¿›è¡Œäº†å¯¹é½

   ```cpp
     struct alignas(128) SharedStorage {
       struct alignas(128) TensorStorage {
         cute::array_aligned<ABtype, cute::cosize_v<SmemLayoutA>> smem_A;
         ...
       } tensors;
       struct alignas(16) PipelineStorage {
         // mainloop pipeline barrier
         // 2stage consumer pingpong barrier
         ...
       } pipelines;
     };
   ```

   æˆ‘å°è¯•äº†ä¸€ä¸‹å»æ‰è¿™ä¸ª aignas ä»ç„¶èƒ½å¤ŸæˆåŠŸè¿è¡Œï¼Œå¯èƒ½ä¸éœ€è¦è¿‡éƒ½æ³¨æ„è¿™ä¸ªç»†èŠ‚

3. pipeline state

4. All kinds of tempalte meta programming

   æ„Ÿè§‰è¿™é‡Œæ‰æ˜¯æœ€éº»çƒ¦çš„åœ°æ–¹ï¼Œ~120 è¡Œï¼Œå¸Œæœ›æˆ‘èƒ½å¤Ÿæ•´ç†å‡ºä¸€ä¸ªæ¸…æ™°çš„é€»è¾‘ä»¥åŠç»“æ„ï¼Œè¿™æ ·æ‰èƒ½åœ¨ä¹‹åçš„ç¼–å†™ä¸­æœ‰ä¸€ä¸ªæ€è·¯å¯å¾ª
   
   0. æ¨¡æ¿å…ƒç¼–ç¨‹å‚æ•°ï¼šcta shape, stage number, cluster shapeï¼Œæƒ³è¦ç”Ÿæˆç‰¹åŒ–ä»£ç çš„å‚æ•°ã€‚è¿™äº›ç‰¹åŒ–ä»£ç åœ¨çœŸæ­£ç¼–è¯‘çš„æ—¶å€™éƒ½ä¼šè¢«ç¼–è¯‘ï¼Œå†ä» host ç«¯è¿› if-else è¿›è¡Œé€‰æ‹©
   
   1. ABCType and layoutï¼Œè¿™åº”è¯¥æ˜¯ args æ‰€æä¾›çš„æœ€åŸºç¡€çš„ä¿¡æ¯
   
   2. mma atom
   
   3. **copy atom**
   
      è¿™æ‰æ˜¯æ¨¡ç‰ˆä¸­å æ¯”æœ€å¤šçš„ atomï¼Œä¸ä»…éœ€è¦å®šä¹‰å„ä¸ªå­˜å‚¨ä¹‹é—´çš„ copy atom (gmem <-> smem <-> rmem)ï¼Œè¿˜è¦å®šä¹‰å„ä¸ªè¾“å…¥çŸ©é˜µéƒ½å•ç‹¬å®šä¹‰ä¸€ä¸ª copy atom (Tensor A B C)ã€‚å®šä¹‰ copy atom ä¹Ÿä¸å¯é¿å…åœ°éœ€è¦å¯¹ memory layout è¿›è¡Œå®šä¹‰ï¼Œæ‰€ä»¥æ•´ä¸ªçš„ä»£ç è¡Œæ•°å°±æ˜¯å¤§å‡ åè¡Œã€‚æ¥ä¸‹æ¥å°±æ˜¯ä¸€ä¸€è¿›è¡Œåˆ†æ
   
   å…¶å®ä¸ç”¨æŠŠä¸€å¤§å †çš„ static constexpr int å†™åœ¨ struct çš„æœ€å‰é¢ï¼Œæˆ‘è§‰å¾—åœ¨ä½¿ç”¨çš„æ—¶å€™å†è¿›è¡Œä¸€äº›è®¡ç®—ï¼Œå¯èƒ½ä¼šæ›´å¥½è¯»ä¸€äº›ï¼Œä¸ç„¶è¿™äº›å®šä¹‰è·ç¦»ä½¿ç”¨çš„åœ°æ–¹å¤ªè¿œäº†ï¼Œå†™çš„æ—¶å€™ä¸æ–¹ä¾¿ã€‚æˆ‘çœ‹ reed ä¸­çš„ gemm-multistage å°±æ˜¯è¿™ä¹ˆå¹²çš„ï¼Œè¿™äº› constexpr int åº”è¯¥ä¼šè¢«å¤„ç†ä¸ºç¼–è¯‘æœŸå¸¸é‡ï¼Œè€Œä¸ä¼šå ç”¨å¯„å­˜å™¨èµ„æºï¼ˆMaybe

### Compute Logic

1. producer

2. consumer

   1. coorperative
   2. pingpong

3. issue_mma

   å®Œæˆä¸€æ¬¡ big K iterationï¼Œi.e. å®Œæˆä¸€ä¸ª output tile çš„ç´¯åŠ è®¡ç®— (maybe?

4. mma tail

5. issue epilogue

6. Scheduler

ä¼¼ä¹æ•´ä¸ª GEMM å°±æ˜¯è¿™äº›å…³é”®åŠŸèƒ½çš„åˆä½œï¼Œæˆ‘åº”è¯¥è¦æŠŠä»–ä»¬çš„åŸºæœ¬åŠŸèƒ½å’ŒåŸç†éƒ½å¼„æ¸…æ¥šï¼Œå†è€ƒè™‘ä¸ deepgemm çš„å¯¹æ¯”

åœ¨è¿›è¡Œ gemm å­¦ä¹ æ—¶ä¸€ä¸ªç®€å•çš„å‡è®¾ä¼šä½¿å¾—æµæ°´çº¿çš„å›¾ç¤ºå˜ç®€å•ï¼šgemm æ˜¯ compute boundã€‚è¯¥å‡è®¾å°±ä¼šä½¿å¾—å–æ•°æ®çš„æ—¶é—´å°äºè®¡ç®—æ—¶é—´ï¼Œåœ¨è¿™æ ·çš„å‡è®¾ä¸‹æ‰èƒ½å¤Ÿåœ¨æµæ°´çº¿ä¸­å°†ç®—åŠ›æ‰“æ»¡ï¼ŒåŒæ—¶åœ¨è¿™æ ·çš„æ¡ä»¶ä¸‹æˆ‘ä»¬æ‰èƒ½å¤Ÿçœ‹åˆ°ï¼š epilogue & prologue çš„æ—¶å»¶è¢«è®¡ç®—æ‰€æ©è—

ç®€æ˜“çš„è¯æ˜ issue mma æ˜¯æœ€é«˜æ•ˆçš„ï¼š

1. smem_1 æŠµè¾¾ï¼Œmma_0 è¿˜æ²¡æœ‰è®¡ç®—å®Œæˆ

   æ­¤æ—¶ä¸º compute boundï¼Œæˆ‘ä»¬éœ€è¦ç­‰å¾… mma_0 è®¡ç®—å®Œæˆï¼Œæ‰èƒ½å¼€å§‹ mma_1 çš„è®¡ç®—ï¼Œæ­¤æ—¶ tensor core æ²¡æœ‰ç©ºé—²ï¼Œç®—åŠ›æ‰“æ»¡

2. Smem_1 æŠµè¾¾ï¼Œmma_0 çš„è®¡ç®—å·²ç»å®Œæˆï¼ˆä¸€æ®µæ—¶é—´äº†ï¼‰

   æ­¤æ—¶ä¸º memory boundï¼Œæˆ‘ä»¬å¿…é¡»ç­‰å¾… smem_1 çš„æŠµè¾¾æ‰èƒ½å¤Ÿå¼€å¯ mma_1 çš„è®¡ç®—ã€‚éœ€è¦æ³¨æ„çš„æ˜¯ï¼Œæˆ‘ä»¬åœ¨ mma_0 è®¡ç®—å®Œæˆçš„ç¬é—´ï¼Œå°±å·²ç»é€šçŸ¥ empty barrier åˆ°è¾¾ä¿¡æ¯ï¼Œè®© smem_0 å¤„äºå¯å†™çŠ¶æ€ã€‚æ­¤æ—¶ memory æ²¡æœ‰ç©ºé—²ï¼Œç®—åŠ›å—é™ï¼Œä½†æ— æ³•è¿›ä¸€æ­¥æå‡

åº”è¯¥ä¸éœ€è¦ä½¿ç”¨ prologue mma (one mma in-flight) çš„æ“ä½œï¼Ÿåƒ DeepGemm ä¸€æ ·ç›´æ¥ç­‰ mma è®¡ç®—å®Œå°±å®Œäº‹å„¿äº†ï¼è¿™ä¸€ç‚¹æˆ‘éœ€è¦è‡ªå·±å®éªŒä¸€ä¸‹æ‰çŸ¥é“å·®è·å¤šå¤§ã€‚å”¯ä¸€æˆ‘èƒ½å¤Ÿæƒ³åˆ°çš„å·®è·åœ¨äºï¼šç¬¬ä¸€æ¬¡ mma éœ€è¦ä½¿ç”¨

```cpp
    // fisrt mma with no accumulation to avoid init zeros
    tiled_mma.accumulate_ = GMMA::ScaleOut::Zero;
```

æ¥å‘Šè¯‰ mmaï¼šç›´æ¥ç”¨ `C = AB`ï¼Œè€Œä¸è¦ä½¿ç”¨ `C = AB + C`ã€‚è¿™æ ·èƒ½èŠ‚çœä¸€æ¬¡å¯¹ accumulator çš„æ¸…é›¶ã€‚ä½†è¿™å’Œ in-flight ä¸å¦æ— å…³

åœ¨ [efficient gemm](https://github.com/NVIDIA/cutlass/blob/main/media/docs/cpp/efficient_gemm.md) æ–‡æ¡£ä¸­ç®€è¦æè¿°äº† coorperative & ping pong kernel è®¾è®¡ï¼š

1. Cooperative

   ä¸¤ä¸ª warp group å®Œæˆä¸€ä¸ª tile çš„ mmaï¼Œä½†æ˜¯ä»–ä»¬ä¼šåœ¨ M ç»´åº¦è¿›è¡Œå¯¹åŠåˆ†ï¼Œå„è‡ªå®Œæˆä¸€åŠ tile mma

2. Ping-Pong

   ä¸¤ä¸ª warp group å®Œæˆä¸¤ä¸ª tile çš„ mmaï¼Œä»–ä»¬ä¼šé€šè¿‡é…åˆæ©è— prologue & epilogue

åœ¨ [ä¸ºä»€ä¹ˆHopperæ¶æ„ä¸Šwarp-specializationæ¯”multi-stageè¦å¥½ï¼Ÿ-zhihu](https://www.zhihu.com/question/11261005710) ä¸­æœ‰ç®€æ˜“çš„å›¾ç¤º 

## Sync function

åœ¨ä»£ç å½“ä¸­ä¼šé‡åˆ°å¾ˆå¤šç”¨äºåŒæ­¥çš„è¯­å¥ï¼Œéœ€è¦é€ä¸€ç†æ¸…ä»–ä»¬çš„ä½œç”¨ï¼Œç„¶åå’Œ function åŠŸèƒ½é…åˆèµ·æ¥ï¼Œå½»åº•è®© pipeline ç¼–ç¨‹ç™½ç›’

1. `cute::prefetch_tma_descriptor(param.tma_a.get_tma_descriptor());`

   > From Kimi
   >
   > ä½œç”¨æ˜¯**æå‰å°† TMAï¼ˆTensor Memory Acceleratorï¼‰æè¿°ç¬¦é¢„å–åˆ° GPU çš„ L2 cache ä¸­**ï¼Œä»¥å‡å°‘åç»­å®é™…æ‰§è¡Œ TMA åŠ è½½/å­˜å‚¨æ“ä½œæ—¶çš„å»¶è¿Ÿã€‚
   >
   > TMA æè¿°ç¬¦æœ¬èº«ä¹Ÿå­˜å‚¨åœ¨ global memory ä¸­ã€‚å¦‚æœä¸é¢„å–ï¼Œå½“ kernel ä¸­ç¬¬ä¸€æ¬¡ä½¿ç”¨ TMA åŠ è½½/å­˜å‚¨æ—¶ï¼ŒGPU éœ€è¦ä» global memory è¯»å–æè¿°ç¬¦ï¼Œè¿™ä¼šå¸¦æ¥é¢å¤–çš„å»¶è¿Ÿã€‚
   >
   > é€šè¿‡ `cute::prefetch_tma_descriptor()`ï¼Œæˆ‘ä»¬å¯ä»¥**åœ¨ kernel å¯åŠ¨çš„æ—©æœŸé˜¶æ®µ**ï¼ˆæ¯”å¦‚è¿˜åœ¨åšè®¡ç®—å‡†å¤‡æ—¶ï¼‰ï¼Œ**å°†è¿™äº›æè¿°ç¬¦æå‰åŠ è½½åˆ° L2 cache ä¸­**ï¼Œè¿™æ ·åç»­çœŸæ­£æ‰§è¡Œ TMA æ“ä½œæ—¶ï¼Œæè¿°ç¬¦å·²ç»åœ¨ cache é‡Œï¼Œå»¶è¿Ÿæ˜¾è‘—é™ä½ã€‚

   æˆ‘å‘ç° kimi çš„å›ç­”ä¸€ç›´éƒ½éå¸¸ç®€ç»ƒï¼Œåº”è¯¥æ˜¯åœ¨å›ç­”çš„å­—æ•°ä¸Šæœ‰æ‰€é™åˆ¶ï¼Œè€Œ Grok çš„å›ç­”åˆ™ä¼šæ— æ¯”å†—é•¿ï¼ŒDeepSeek ä»‹äºäºŒè€…ä¹‹é—´

2. `cutlass::arch::fence_barrier_init()`

   åœ¨ä¹‹å‰æˆ‘ä»¬è®¨è®ºäº† visibilityï¼Œå…¶å‘ç”Ÿåœ¨äº† generic proxy å’Œ async proxy ä¹‹é—´ã€‚å®é™…ä¸Šè¿™ç§ visibility ä¹Ÿå­˜åœ¨åœ¨ cta å’Œ cta ä¹‹é—´ã€‚ç”±äº Hopper æ¶æ„å¼•å…¥äº† cluster levelï¼Œæ‰€ä»¥åœ¨ cluster ä¹‹é—´ä¹Ÿéœ€è¦åŒæ­¥ä¸é€šä¿¡ã€‚å½“æˆ‘ä»¬åˆå§‹åŒ–äº† barrier è¿‡åï¼ŒåŒä¸€ä¸ª cluster çš„ cta ä¹‹é—´å…¶å®æ˜¯çœ‹ä¸è§å„è‡ª barrier çš„åˆå§‹åŒ–æƒ…å†µçš„ï¼Œæ‰€ä»¥ä¸ºäº†è®© barrier åˆå§‹åŒ–æƒ…å†µåœ¨ cluster ä¹‹å†… visibleï¼Œå°±éœ€è¦ä½¿ç”¨è¯¥å‘½ä»¤ `cutlass::arch::fence_barrier_init()`

   `fence_barrier_init` ä¸€èˆ¬ä¼šå’Œ `fence_view_async_shared` ä¸€èµ·ä½¿ç”¨

   ```cpp
   cutlass::arch::fence_view_async_shared();
   cutlass:arch::fence_barrier_init();
   ```

   å‰è€…æ˜¯è®© barrier å¯¹ async proxy å¯è§ï¼ˆe.g. tmaï¼‰ï¼Œè€Œåè€…å°±æ˜¯è®© barrier å¯¹ï¼ˆåŒä¸€ cluster å†…çš„ï¼‰å…¶ä»– cta å¯è§

   è¿˜æœ‰ä¸€ä¸ªé…åˆè¿™ä¸¤ä¸ªå‘½ä»¤çš„æ˜¯ `cluster_sync` or `__syncthreads`

   ```cpp
   (kNumTMAMulticast > 1) ? cute::cluster_sync() : __syncthreads();
   ```

   ç”¨äºè®©æ‰€æœ‰çš„çº¿ç¨‹è¿›è¡ŒåŒæ­¥ï¼Œé¿å…åœ¨ä¹‹åçš„ warp specialization æ“ä½œä¸­æœ‰çš„çº¿ç¨‹å·²ç»å¼€å§‹ä½¿ç”¨ barrier äº†

   > From Kimi
   >
   > **è¿™ä¸ª barrier æ˜¯ä¸ºäº†ç¡®ä¿æ‰€æœ‰çº¿ç¨‹éƒ½å®Œæˆäº†å…±äº« barrier çš„åˆå§‹åŒ–ï¼Œé¿å… producer å’Œ consumer åœ¨ä½¿ç”¨æœªå°±ç»ªçš„åŒæ­¥åŸè¯­æ—¶å‡ºç°ç«æ€æˆ–æ­»é”ã€‚**

## Cluster Programming

sync in clusers

1. `cute::cluster_sync()`

2. `cutlass::arch::fence_barrier_init()`

   make the barrier init visible to the clusterï¼Œjust a rule needs to be followed...

**visibility**

è¿™ä¸ªæ¦‚å¿µä¼šåœ¨æè¿°ä¸­ç»å¸¸çœ‹åˆ°ï¼Œè¿™æ˜¯ Grok æ‰€ç»™å‡ºçš„å®šä¹‰

> **visibility** ensures that memory operations (e.g., mbarrier initialization, TMA writes to SMEM) are observable by the appropriate threads, CTAs, or hardware components (e.g., the TMA unit) at the right time.
>
> **Invisibility** occurs when these operations are not yet propagated due to the lack of synchronization, leading to race conditions, data corruption, or kernel failures.

è¿™æ ·çš„è§£é‡Šè¿˜æ˜¯æ¯”è¾ƒæ¸…æ™°çš„ã€‚ä»¥å‘ smem å†™å…¥ä¸ºä¾‹ï¼Œå¯¹äº thread idx = 0 çš„çº¿ç¨‹æ¥è¯´ï¼Œå‡è®¾å®ƒå·²ç»æŠŠæ•°æ®å†™å…¥åˆ°äº† smem å½“ä¸­ï¼Œå…¶ä»–çº¿ç¨‹æˆ–è€… TMA æ˜¯å¦‚ä½•çŸ¥é“å®ƒå·²ç»å®Œæˆå†™å…¥äº†å‘¢ï¼Ÿæ‰€ä»¥éœ€è¦æœ‰ä¸€ä¸ªè¿‡ç¨‹ï¼Œæ¥è®©â€œå†™å…¥å®Œæˆâ€è¿™ä¸€ç»“æœå˜å¾—å¯¹å…¶ä»–å•å…ƒï¼ˆçº¿ç¨‹ã€clusterã€tmaï¼‰å¯è§ï¼Œè¿™å°±æ˜¯ visibilityã€‚è€Œè¿™ä¸ªè¿‡ç¨‹é€šå¸¸å°±æ˜¯ä¸€ä¸ª fense or barrier (sync)

**fence & barrier & sync**

è¿™ä¸‰ä¸ªçš„ä½œç”¨æœ‰ä¸€ç‚¹æ··æ·†ï¼Œéœ€è¦å¼„æ¸…æ¥šï¼

barrier æ›´ä¸ºå…·è±¡ï¼šæ‰€æœ‰çš„çº¿ç¨‹å¿…é¡»è¦æ‰§è¡Œåˆ°è¿™ä¸€è¡Œä»£ç ï¼Œæˆ–è€…æŸä¸ªæ¡ä»¶æ»¡è¶³è¿‡åï¼Œæ‰èƒ½å¤Ÿç»§ç»­æ‰§è¡Œä¸‹ä¸€ä¸ªä»£ç 

fence æ›´ä¸ºæŠ½è±¡ï¼šé€šå¸¸æœ‰å…¶â€œé…åˆçš„å‘½ä»¤â€ï¼Œä¿è¯äº†åœ¨â€œé…åˆçš„å‘½ä»¤â€è¿è¡Œä¹‹å‰ï¼Œfence ä¹‹å‰çš„å„ä¸ªçº¿ç¨‹çš„ä»£ç å·²ç»æ‰§è¡Œå®Œæ•´ã€‚å’Œ barrier æœ€å¤§çš„åŒºåˆ«æ˜¯ä¸é˜»å¡çº¿ç¨‹

äºŒè€…éƒ½æ˜¯ç”¨äºçº¿ç¨‹åŒæ­¥çš„å·¥å…·ï¼Œä¿è¯çº¿ç¨‹ä»»åŠ¡éƒ½å¤„äºæ»¡è¶³è¦æ±‚çš„çŠ¶æ€ï¼Œä»è€Œä¿è¯ç¨‹åºçš„æ­£ç¡®æ€§

ä¸ºä»€ä¹ˆåœ¨ sync è¿‡åè¿˜è¦ä½¿ç”¨ä¸€ä¸ª tma store fenceï¼Ÿä¸éƒ½å·²ç»åŒæ­¥è¿‡äº†å—ï¼Ÿæ•°æ®æ˜æ˜éƒ½å·²ç»å†™å…¥åˆ°äº† smem å½“ä¸­äº†ï¼æ‰€æœ‰çš„è§£é‡Šéƒ½æ˜¯ï¼šsmem å®Œæˆäº†å†™å…¥ï¼Œä½†æ˜¯ tma å¹¶ä¸çŸ¥é“ smem å®Œæˆäº†å†™å…¥ï¼Œæˆ‘ä»¬éœ€è¦ fence æ¥å‘ŠçŸ¥ tmaï¼šæ‰€æœ‰çš„çº¿ç¨‹éƒ½å·²ç»å®Œæˆäº† smem å†™å…¥ï¼Œè¯·ä½ æ¬è¿è¿™äº›å†™å…¥çš„æ•°æ®ï¼ˆè¿™ä¸ªè¿‡ç¨‹ä¹Ÿæ˜¯è®©æ•°æ®å¯¹ tma visible çš„è¿‡ç¨‹ï¼‰ã€‚

ä»¥ä¸Šçš„æè¿°è¿‡äºå½¢è±¡åŒ–ï¼Œè€Œä¸å¤Ÿä¸¥è°¨ã€‚æˆ‘æ‹·æ‰“äº† Grok å¾ˆä¹…ï¼Œå®ƒä¹Ÿåªæ˜¯åœ¨è¿™å‡ ä¸ªåè¯ä¹‹é—´ç»•æ¥ç»•å»ã€‚æˆ‘çš„é€»è¾‘å¾ˆç®€å•ï¼š

1. Generic proxy å¯¹ smem è¿›è¡Œäº†å†™å…¥ï¼Œå¹¶ä¸”ä½¿ç”¨ syncthreads ä¿è¯äº†å†™å…¥çš„å®Œæˆ
2. ä¸æ·»åŠ  fence ä½¿å¾— async proxy æ— æ³•çœ‹è§è¿™äº›å†™å…¥æ“ä½œï¼ˆinvisibleï¼‰ï¼Œå…¶çœ‹è§çš„æ˜¯ outdated æ•°æ®
3. async proxy çœ‹è§çš„ smem å’Œ generic çœ‹è§çš„ smem ä¸ä¸€æ ·
4. smem åœ¨åŒä¸€æ—¶åˆ»åªèƒ½æœ‰ä¸€ç§çŠ¶æ€

ä»¥ä¸Šå°±æ¨å‡ºäº†çŸ›ç›¾ç‚¹ã€‚æ‰€ä»¥æˆ‘è®¤ä¸ºç”¨ visible æ¥æè¿°è¿™ä¸ªè¿‡ç¨‹æ˜¯ä¸åˆ©äºæˆ‘ä»¬å¯¹ GPU æ¨¡å‹çš„ç†è§£çš„ã€‚ä½†æ˜¯åœ¨æ‹·æ‰“ Grok çš„è¿‡ç¨‹ä¸­ï¼Œå…¶ä¸æ–­åœ°æå‡ºå¦ä¸€ä¸ªæ¦‚å¿µ **relaxed memory consistency model**ã€‚å¯¹è¿™ä¸ªæ¦‚å¿µè¿›è¡Œè§£é‡Šï¼š

> From Kimi
>
> åœ¨ GPU å†…å­˜ä¸­ï¼Œ**relaxed consistency modelï¼ˆæ”¾æ¾ä¸€è‡´æ€§æ¨¡å‹ï¼‰** æ˜¯ä¸€ç§æ¯”é¡ºåºä¸€è‡´æ€§ï¼ˆSequential Consistency, SCï¼‰æˆ– Total Store Orderï¼ˆTSOï¼‰æ›´å¼±çš„å†…å­˜ä¸€è‡´æ€§æ¨¡å‹ï¼Œå…¶é»˜è®¤å…è®¸å†…å­˜æ“ä½œï¼ˆå¦‚åŠ è½½å’Œå­˜å‚¨ï¼‰è¢«é‡æ’åºï¼Œé™¤éç¨‹åºå‘˜é€šè¿‡æ˜¾å¼çš„åŒæ­¥æœºåˆ¶ï¼ˆå¦‚ `FENCE` æˆ– `__threadfence()` ç­‰ï¼‰æŒ‡å®šé¡ºåº [ref link](https://www.sigarch.org/gpu-memory-consistency-specifications-testing-and-opportunities-for-performance-tooling/#:~:text=g.%2C%20device,block%28%29%7C)

å¦‚æ­¤ä¸€æ¥å°±èƒ½è§£é‡Šé€šäº†ï¼štma store å’Œ smem write ç”±ä¸¤ä¸ªä¸åŒçš„ proxy æ‰§è¡Œï¼Œä»–ä»¬äºŒè€…çš„åœ¨æ‰§è¡Œæ—¶å¹¶ä¸ä¿è¯ä¸¥æ ¼çš„é¡ºåºï¼Œå¯èƒ½ tma store åœ¨ smem write çš„è¿‡ç¨‹ä¸­å°±å¼€å§‹äº†ï¼Œæ‰€ä»¥å…¶çœ‹åˆ°çš„å†…å®¹å°±æ˜¯ outdatedï¼Œæ‰€ä»¥å¿…é¡»è¦ä½¿ç”¨ fence æ¥ä¿è¯ï¼Œtma store çš„å‘èµ·åœ¨ smem å†™å…¥ä¹‹åï¼Œè€Œ tma store æ€ä¹ˆçœ‹ä¸åˆ° generic proxy å¯¹ smem çš„æ“ä½œï¼Œæ‰€ä»¥é¦–å…ˆå¿…é¡»è¦è®© generic proxy çš„è¿™äº›æ“ä½œå¯¹ async proxy æ“ä½œå¯è§ã€‚åœ¨æ“ä½œå¯è§ä¹‹åï¼Œæ–¹å¯å®Œæˆåˆ¤æ–­ï¼šè¿™äº›æ“ä½œæ˜¯å¦å®Œæˆï¼Œä»è€Œæ§åˆ¶ tma store çš„é¡ºåºä¸€å®šåœ¨ smem ä¹‹å

**fence æœ€æ ¸å¿ƒçš„ç›®çš„å…¶å®æ˜¯ç”¨äºä¿è¯æ“ä½œæŒ‰ç…§æœŸæœ›çš„é¡ºåºæ‰§è¡Œ**ï¼Œè€Œè¿™ä¹Ÿæ˜¯ç”± relaxed consistency model æ‰€äº§ç”Ÿçš„ç›´æ¥å½±å“ã€‚

æœ‰ä¸€ä¸ªå¾ˆå½¢è±¡ä½†ä¹Ÿè®¸ä¸å‡†ç¡®çš„è¯´æ³•ï¼šbarrier æ˜¯ç­‰çº¿ç¨‹ï¼›è€Œ fence æ˜¯ç­‰æ•°æ®

barrier ä¸€å®šä¼šé˜»å¡çº¿ç¨‹çš„æ‰§è¡Œï¼Œä¾‹å¦‚ `syncthreads` å°±æ˜¯æœ€å¸¸ç”¨çš„ barrier

å¯¹äº gmem -> smem ä½¿ç”¨ mbarrier æ¥è¿›è¡ŒåŒæ­¥ï¼Œsmem -> gmem ä½¿ç”¨ fence æ¥è¿›è¡ŒåŒæ­¥

**`get_slice` in cluster**



## Questions

1. Split-K or Stream-K æ˜¯å¦èƒ½åŠ é€Ÿ gemv or small batch decodingï¼Ÿ

2. what is a qualifier

   åœ¨ PTX å½“ä¸­ `xxx.yyy.zz` ä¸­çš„ `xxx & yyy & zz` å°±æ˜¯ qualifier 

3. ä¸ºä»€ä¹ˆè¯´ Hopper æ¶æ„æ˜¯ç¬¬ä¸€ä»£çœŸæ­£çš„å¼‚æ­¥ GPUï¼Ÿ

   [ä¸ºä»€ä¹ˆHopperæ¶æ„ä¸Šwarp-specializationæ¯”multi-stageè¦å¥½-zhihu](https://www.zhihu.com/question/11261005710/answer/1925679279854851325) è¿™ä½ä½¬çš„çŸ¥ä¹ä¹Ÿæœ‰å¾ˆå¤šå¹²è´§

4. ä»€ä¹ˆæ˜¯ async proxyï¼Ÿæˆ‘åœ¨ wgmma å’Œ tma å½“ä¸­éƒ½çœ‹è§äº†è¿™ä¸ªæ¦‚å¿µ

5. `cutlass::arch::fence_view_async_shared()` è¿™ä¸ªå‘½ä»¤åœ¨ DeeGEMM å½“ä¸­æœ‰çœ‹åˆ°ï¼ŒåŠŸèƒ½æœªçŸ¥

6. å¦‚ä½•åˆ©ç”¨ mbarrier æ„å»º sm80 pipelineï¼Ÿ

7. ä¸ºä»€ä¹ˆ warp specialization æ¯” multi-stage è¦å¥½ï¼Ÿ

   [ä¸ºä»€ä¹ˆHopperæ¶æ„ä¸Šwarp-specializationæ¯”multi-stageè¦å¥½ï¼Ÿ-zhihu](https://www.zhihu.com/question/11261005710) ä¹‹å‰çœ‹åˆ°çš„å›ç­”ï¼špersistant warp specialization ä¼šéšè— prologue & epilogue çš„æ—¶é—´ã€‚ä½†æ˜¯é—®é¢˜æ¥äº†ï¼šä»€ä¹ˆæ˜¯ persistantï¼Ÿ

   åœ¨ [Nvidia Cute å®æˆ˜-WarpSpecialization Gemm for Hopper[zhihu](https://zhuanlan.zhihu.com/p/1905383022901059783) ä¸­æœ‰æåˆ° persistant çš„å«ä¹‰ï¼š

   > **Persistent Scheduler and CTA Swizzle**
   >
   > Persistent Scheduler ä¸åŒäºä¼ ç»Ÿçš„ data parallelï¼šgrid å›ºå®šlaunch CTA æ•°ç›®=SMæ•°ç›®**ï¼ˆcluster size=2æ¡ä»¶ä¸‹æœ€ä¼˜çš„é…ç½®ï¼‰**ï¼Œä¿è¯æ¯ä¸ª CTA è¿è¡Œå¤šä¸ª Gemm Tile ä»è€Œå¯ä»¥ä»ç¬¬äºŒä¸ª Tile å¼€å§‹éšè— prologue çš„å¼€é”€ã€‚

   ä¹‹å‰æ€»æ˜¯æŠŠ persistant å’Œ warp specialization ä¸€èµ·å‡ºç°ï¼Œä½†æ˜¯äºŒè€…å¹¶æ²¡æœ‰æœ¬è´¨ä¸Šçš„è”ç³»ã€‚è€Œ persistant å’Œ scheduler è”ç³»èµ·æ¥æ‰ä¼šæ˜¾å¾—é€»è¾‘æ›´è‡ªç„¶

   åœ¨ Ampere æ¶æ„å½“ä¸­ï¼Œgrid dimension çš„åˆ’åˆ†å°±æ˜¯æ ¹æ® cta tile æ¥ç®€å•åˆ’åˆ†

   ```cpp
   dim3 gridDim = {ceil(M/BM), ceil(N/BN)}
   ```

   æ¯ä¸€ä¸ª cta åªä¼šå¤„ç†è‡ªå·±çš„ tileã€‚å¤„ç†å®Œè¿‡åä¸Šä¸‹æ–‡å°±ä¼šè¿›è¡Œåˆ‡æ¢ï¼Œäº¤ç”±å…¶ä»–çš„ cta ç»§ç»­å®Œæˆä¸‹ä¸€ä¸ª tile

   è€Œå¯¹äº persistant schedulerï¼Œæˆ‘ä»¬å›ºå®šä¸‹æ¥äº† cta çš„æ•°é‡ï¼Œæ¯ä¸€ä¸ª cta ä¼šå¤„ç†å¤šä¸ª tileï¼Œè¿™æ ·å°±çœç•¥æ‰äº†ä¸Šä¸‹æ–‡åˆ‡æ¢çš„æ—¶é—´ï¼Œå¹¶ä¸”åœ¨å¤„ç†è¿ç»­çš„ä¸¤ä¸ª tile æ—¶ï¼Œå¯ä»¥éšè— tile é—´çš„ prologue æ—¶é—´

8. å¯¹æ¯” fp16 & fp8 çš„ gemm å®ç°å½“ä¸­ï¼Œæˆ‘å‘ç° fp8 gemm æ²¡æœ‰ mma prologueï¼Œä¹Ÿå°±æ˜¯å…ˆå¯åŠ¨ä¸€ä¸ª mmaï¼Œç„¶åç”¨ mma tail è¿›è¡Œæ”¶å°¾ã€‚å¦å¤– fp8 deepgemm ä½¿ç”¨äº†å¤šä¸ª accumulatorï¼Œä¸ºä»€ä¹ˆè¦å¤šä¸ªç´¯åŠ å™¨ï¼Ÿè¿™ä¸ä¼šé€ æˆå¯„å­˜å™¨ç´§å¼ å—ï¼Ÿ

9. å¦‚ä½•æ„å»ºæµæ°´çº¿çš„æ€§èƒ½æ¨¡å‹ï¼Œå…¶ä¸­å¸¸è§çš„æ–¹å¼æ˜¯ç”¨æµæ°´çº¿å›¾æ¥ç®€å•å¯¹æ¯”

10. issue epilogue å’Œ issue_mma ä¹‹é—´æ˜¯å¦æ˜¯ asyncï¼Ÿåªæœ‰æ˜¯ async å½¢å¼ï¼Œæ‰èƒ½å¤Ÿéšè—æ‰ tile ä¹‹é—´çš„ prologue æ—¶é—´ã€‚åŒæ—¶å¿…é¡»è¦ä½¿ç”¨ ping-pong consumer æ‰èƒ½éšè—æ‰ epilogue çš„æ—¶é—´

11. tma ä¼šè‡ªåŠ¨åˆ¤æ–­æ•°æ® out of bound å—ï¼Ÿå…·ä½“çš„è¡¨ç°å’Œä½¿ç”¨å½¢å¼æ˜¯æ€ä¹ˆæ ·çš„ï¼Ÿ

12. ä»€ä¹ˆæ˜¯ waveï¼Ÿ

13. å¦‚æœä¸ä½¿ç”¨ one mma in-flight ä¼šé™ä½å¤šå°‘è¡¨ç°ï¼Ÿ

14. ä¸ºä»€ä¹ˆä½¿ç”¨ struct è€Œä¸æ˜¯ä½¿ç”¨ class æ¥è¿›è¡Œ kernel æ„å»º

    > From Kimi
    >
    > åœ¨ C++ ä¸­ï¼Œ`struct` å’Œ `class` åœ¨è¯­æ³•ä¸Šå‡ ä¹ç­‰ä»·ï¼ŒåŒºåˆ«åªåœ¨äºé»˜è®¤è®¿é—®æƒé™ï¼›åœ¨ CUDA kernel è®¾è®¡ä¸­ç”¨ `struct` æ›´å¤šæ˜¯å‡ºäº**çº¦å®šã€ç®€æ´æ€§å’Œ POD é£æ ¼**çš„è€ƒè™‘ï¼Œè€Œä¸æ˜¯æŠ€æœ¯é™åˆ¶ã€‚

    ç®€æ´æ€§æ¥è‡ªäº POD é£æ ¼

    > From Kimi & DeepSeek
    >
    > **POD å°±æ˜¯â€œé•¿å¾—åƒ C è¯­è¨€é‡Œçš„ç»“æ„ä½“â€â€”â€”ç®€å•ã€æ²¡æœ‰éšè—è¡Œä¸ºï¼›é POD å°±æ˜¯â€œå¸¦ C++ ç‰¹æ€§çš„ç±»â€â€”â€”æœ‰æ„é€ ã€ææ„ã€è™šå‡½æ•°ã€ç»§æ‰¿ç­‰â€œé¢å¤–åŠ¨ä½œâ€ã€‚**
    >
    > å¹¶ä¸” POD é£æ ¼åªæœ‰é™æ€æ–¹æ³•ï¼Œæ²¡æœ‰æˆå‘˜å˜é‡ï¼Œè¿™æ ·é¿å…äº†å®ä¾‹åŒ–ã€‚åŒæ—¶ä¹Ÿè¡¨å¾äº†ï¼šå†…æ ¸æœ¬èº«**ä¸éœ€è¦ç»´æŠ¤è‡ªèº«çŠ¶æ€**ï¼ˆæ‰€æœ‰æ•°æ®é€šè¿‡å‚æ•°ä¼ é€’ï¼‰

    å¦å¤– struct çš„æˆå‘˜é»˜è®¤éƒ½æ˜¯ public å±æ€§ï¼Œè€Œ class æˆå‘˜é»˜è®¤ä¸º private å±æ€§ï¼Œè‡ªç„¶ä»£ç ä¼šæ›´åŠ ç®€å•

    é™¤æ­¤ä¹‹å¤–æˆ‘è¿˜çœ‹åˆ°æœ‰çš„å‡½æ•°åŠ äº† inline è€Œæœ‰çš„å‡½æ•°æ²¡æœ‰åŠ  inlineï¼Œä½†å®é™…ä¸Šéƒ½å¯ä»¥ä¸åŠ ï¼Œä»–ä»¬éƒ½æ˜¯å®šä¹‰åœ¨ç»“æ„ä½“ä¹‹å†…çš„ï¼Œä¼šè¢«é»˜è®¤å½“åš inline å‡½æ•°ï¼ˆéšå¼ inlineï¼‰

    > From Kimi
    >
    > **åªè¦å‡½æ•°ä½“å†™åœ¨ç±»ï¼ˆæˆ–ç»“æ„ä½“ï¼‰çš„å¤§æ‹¬å·é‡Œé¢ï¼Œå®ƒå°±æ˜¯éšå¼ inlineï¼›å†™åœ¨ç±»å¤–å°±å¿…é¡»è‡ªå·±åŠ  inlineï¼Œé™¤éå®ƒæ˜¯æ¨¡æ¿ã€‚**

15. constexpr

    è®© Kimi å’Œ DeepSeek åˆ†åˆ«å¯¹ constexpr è¿›è¡Œäº†è§£é‡Š

    > From Kimi
    >
    > åœ¨ C++11 ä¹‹å‰ï¼Œæƒ³è®©ç¼–è¯‘å™¨åœ¨ç¼–è¯‘æœŸå°±æŠŠä¸€ä¸ªå€¼ç®—å‡ºæ¥ï¼Œåªèƒ½é ã€Œæ¨¡æ¿å…ƒç¼–ç¨‹ã€æˆ–ã€Œå®ã€ä¹‹ç±»çš„å¥‡æŠ€æ·«å·§ï¼Œä»£ç æ™¦æ¶©éš¾è¯»ã€‚
    > C++11 å¼•å…¥äº† `constexpr`ï¼Œè®©â€œå†™æ™®é€šå‡½æ•°/å˜é‡å°±èƒ½åœ¨ç¼–è¯‘æœŸå®Œæˆè®¡ç®—â€æˆä¸ºç°å®ï¼šåªè¦å‘Šè¯‰ç¼–è¯‘å™¨â€œè¿™ä¸œè¥¿å¯ä»¥åœ¨ç¼–è¯‘æœŸæ±‚å€¼â€ï¼Œç¼–è¯‘å™¨å°±ä¼šå°½é‡åœ¨ç¼–è¯‘æœŸæŠŠå®ƒç®—å‡ºæ¥ã€‚
    >
    > åˆ°åº•ä»€ä¹ˆæ˜¯ constexprï¼Ÿ
    >
    > ä¸€å¥è¯ï¼š
    > **constexpr = â€œæ­¤å®ä½“ï¼ˆå˜é‡/å‡½æ•°/æ„é€ å‡½æ•°/ææ„å‡½æ•° â€¦ï¼‰å¯ä»¥åœ¨ç¼–è¯‘æœŸæ±‚å€¼ï¼Œå¹¶ä¸”æ»¡è¶³ä¸€å®šçº¦æŸâ€ã€‚**
    >
    > - å½“å®ƒè¢«å½“ä½œâ€œå¸¸é‡è¡¨è¾¾å¼â€(constant expression) ä½¿ç”¨æ—¶ï¼Œç¼–è¯‘å™¨**å¿…é¡»**èƒ½åœ¨ç¼–è¯‘æœŸç®—å‡ºç»“æœï¼›
    > - å½“å®ƒè¢«å½“ä½œæ™®é€šå˜é‡/å‡½æ•°ä½¿ç”¨æ—¶ï¼Œä»ç„¶å¯ä»¥åœ¨è¿è¡ŒæœŸä½¿ç”¨ï¼Œ**ä¸ä¼šæŸå¤±ä»»ä½•åŠŸèƒ½**ã€‚

    > From DeepSeek
    >
    > è¿™è§¦åŠäº† `constexpr` å‡½æ•°çš„æ ¸å¿ƒç‰¹æ€§â€”â€”**åŒé‡æ€§**ï¼ˆç¼–è¯‘æœŸå’Œè¿è¡Œæ—¶çš„åŒé‡å¯ç”¨æ€§ï¼‰
    >
    > ```cpp
    > constexpr int add(int n, int m) {
    >     return n + m;
    > }
    > 
    > // æƒ…å†µ1ï¼šç¼–è¯‘æ—¶è®¡ç®—
    > constexpr int sum = add(3, 4);  // âœ… ç¼–è¯‘æ—¶è®¡ç®—
    > 
    > // æƒ…å†µ2ï¼šè¿è¡Œæ—¶è®¡ç®—
    > int y = 10;
    > int runtime_sum = add(y, 5);    // ğŸ”´ è¿è¡Œæ—¶è®¡ç®—
    > ```
    >
    > **`constexpr` å‡½æ•°çš„åŒé‡æ€§è´¨**ï¼š
    >
    > - å®ƒä¸æ˜¯"åªèƒ½åœ¨ç¼–è¯‘æœŸè¿è¡Œ"çš„å‡½æ•°
    > - è€Œæ˜¯"æ»¡è¶³æ¡ä»¶æ—¶**å¯ä»¥**åœ¨ç¼–è¯‘æœŸè¿è¡Œ"çš„å‡½æ•°
    > - å½“æ¡ä»¶ä¸æ»¡è¶³æ—¶ï¼Œè‡ªåŠ¨é€€åŒ–ä¸ºæ™®é€šè¿è¡Œæ—¶å‡½æ•°

    åœ¨è¿›è¡Œ kernel æ¨¡æ¿ç¼–ç¨‹çš„æ—¶å€™ï¼Œä¸€èˆ¬éœ€è¦æ­é… `static`

    ```cpp
    template <KernelTag kernel_tag_, class CtaTile_, class ClusterShape_,
              int Stage_>
    struct GemmKernelSM90A {
    
      static constexpr int WarpSize = 32;
      static constexpr int WarpGroupSize = 128;
      ...
    }
    ```

    å¦åˆ™ç¼–è¯‘å°±ä¼šæŠ¥é”™ï¼Œè¿™æ˜¯å› ä¸º Non-`static` data members cannot be declared as `constexpr`. [StackOverflow](https://stackoverflow.com/questions/50332569/why-i-am-getting-this-error-constexpr-is-not-valid-here)

16. é€‰æ‹©å“ªäº›å‚æ•°ä½œä¸ºæ¨¡æ¿å…ƒç¼–ç¨‹çš„å‚æ•°ï¼Ÿ

    æ¨¡æ¿å…ƒç¼–ç¨‹æ˜¯åœ¨å¯¹ä»£ç ç¼–ç¨‹ï¼Œè€Œä¸æ˜¯ç¼–ç¨‹æœ¬èº«ã€‚åˆ©ç”¨å…ƒç¼–ç¨‹å¯ä»¥æ§åˆ¶åœ¨ç¼–è¯‘æ—¶ä»£ç çš„å…·ä½“å®ç°ã€‚æœ‰ç‚¹ç±»ä¼¼äºï¼šä¸ä½¿ç”¨ if-else æ¥å®ç°å¤šç§ä»£ç çš„æ‰‹æ®µã€‚æ›´å‡†ç¡®çš„æ¥è¯´ï¼Œæ¨¡æ¿å…ƒç¼–ç¨‹çš„æ ¸å¿ƒç›®çš„åœ¨äº

    > From DeepSeek
    >
    > **æ¨¡æ¿å…ƒç¼–ç¨‹æ˜¯é€šè¿‡ç¼–è¯‘å™¨å¯¹æ¨¡æ¿çš„é€’å½’å®ä¾‹åŒ–å’Œç‰¹åŒ–æœºåˆ¶ï¼Œåœ¨ç¼–è¯‘æœŸç”Ÿæˆç±»å‹ä¸“å±ä»£ç æˆ–å®Œæˆè®¡ç®—çš„æŠ€æœ¯ï¼Œæœ¬è´¨æ˜¯å°†è¿è¡Œæ—¶çš„é€»è¾‘åˆ¤æ–­è½¬ç§»åˆ°ç¼–è¯‘æœŸï¼Œå®ç°é›¶å¼€é”€æŠ½è±¡**

    è¿™å¯¹äº if-else ä¸å‹å¥½çš„ CUDA ç¼–ç¨‹æ¥è¯´æ˜¯éå¸¸æœ‰ç”¨çš„ã€‚ä½†å…¶å® if-else ä¸ä¼šæ¶ˆå¤±ï¼Œè€Œæ˜¯ä» kernel ç«¯ç§»åŠ¨åˆ°äº† host ç«¯ï¼ŒåŸå› åœ¨äºï¼šå¦‚æœä½ æƒ³è¦è¿è¡Œè¿™æ ·çš„ç‰¹åŒ–ä»£ç ï¼Œå°±å¿…é¡»è¦è¿›è¡Œç¼–è¯‘ï¼Œè€Œä½ æƒ³è¦èƒ½å¤Ÿè¿è¡Œæ‰€æœ‰çš„ç‰¹åŒ–ä»£ç ï¼Œé‚£å°±è¦å¯¹æ‰€æœ‰çš„ç‰¹åŒ–ä»£ç è¿›è¡Œç¼–è¯‘ã€‚æ‰€ä»¥æœ‰ä¸¤ç§é€‰æ‹©ï¼š

    1. é€šå¸¸ä½¿ç”¨ host ç«¯çš„ if-else æ¥è¿›è¡Œç‰¹åŒ–ä»£ç é€‰æ‹©

       ```cpp
       // From sglang-kernel
       template <typename OutType>
       void sm90_fp8_dispatch_shape(
           torch::Tensor& out,
           const torch::Tensor& a,
           const torch::Tensor& b,
           const torch::Tensor& scales_a,
           const torch::Tensor& scales_b,
           const c10::optional<torch::Tensor>& bias) {
         uint32_t const m = a.size(0);
         using FastPingpongScheduler = cutlass::gemm::KernelTmaWarpSpecializedPingpongFP8FastAccum;
         using FastBasicScheduler = cutlass::gemm::KernelTmaWarpSpecializedFP8FastAccum;
         using PersistentTileScheduler = cutlass::gemm::PersistentScheduler;
         using BasicTileScheduler = void;
         if (m <= 1) {
           return sm90_fp8_dispatch_bias<
               OutType,
               Shape<_64, _64, _128>,
               Shape<_1, _8, _1>,
               FastBasicScheduler,
               BasicTileScheduler>(out, a, b, scales_a, scales_b, bias);
         }
         if (m <= 64) {
           // m in [1, 64]
           return sm90_fp8_dispatch_bias<
               OutType,
               Shape<_64, _64, _128>,
               Shape<_1, _4, _1>,
               FastPingpongScheduler,
               PersistentTileScheduler>(out, a, b, scales_a, scales_b, bias);
         } else if (m <= 256) {
           // m in (64, 256]
           ...
         } 
         ...
       ```

    2. ä½¿ç”¨ jit (just in time) çš„æ–¹å¼è¿›è¡Œå³æ—¶ç¼–è¯‘ï¼Œä»è€Œè·å¾—åŠ¨æ€çš„ç¼–è¯‘ä»£ç 

    