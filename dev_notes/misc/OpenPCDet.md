# OpenPCDet

OpenPCDet å¹¶æ²¡æœ‰åƒ MMDetection ä¸€æ ·æœ‰éå¸¸è¯¦å°½çš„æ–‡æ¡£ï¼Œåªèƒ½è‡ªå·±å»çœ‹æºç äº†ï¼Œè¿™ä¹Ÿæ˜¯å¯¹è‡ªå·±çš„ä¸€ç§é”»ç‚¼ğŸ¤”è¿™ç¯‡ç¬”è®°æ‰“ç®—å¯¹ OpenPCDet çš„è¿è¡Œæµç¨‹è¿›è¡Œä¸€ä¸ªæ€»ç»“ï¼Œå¹¶ä¸”å¯¹ SECOND å’Œ Voxel R-CNN çš„ç›¸å…³ä»£ç è¿›è¡Œè¯¦ç»†ç ”ç©¶

## Test.py

ä¸€äº›é‡è¦çš„å‚æ•°

```python
--cfg_file
--batch_size
--workers
--ckpt
--start_epoch
--save_to_file
```

å…¶ä¸­å¯¹äº `--workers` çš„ä½œç”¨éœ€è¦æ›´å¤šçš„ç†è§£ï¼Œå‚è€ƒ [CSDN](https://blog.csdn.net/jiongjiongxia123/article/details/112850223)ï¼Œä¸ªäººç†è§£å°±æ˜¯ CPU ä½œä¸ºæ¬è¿å·¥ workers æå‰å°†éœ€è¦çš„ batch æ”¾å…¥å†…å­˜ RAM ä¸­ï¼ˆéæ˜¾å­˜ï¼‰ï¼Œç„¶å GPU å¤„ç†å®Œä¸€ä¸ª batch è¿‡åæ¥å–

## EasyDict

é¡¹ç›®å†™äº†ä¸€ä¸ª `EasyDict` ç±»ä½œä¸ºæ›´å¥½ç”¨çš„å­—å…¸ï¼Œèƒ½å¤Ÿå°† `key` ç›´æ¥ä½œä¸º `attribute` è¿›è¡Œè°ƒç”¨

```python
# Get attributes

>>> d = EasyDict({'foo':3})
>>> d['foo']
3
>>> d.foo
3
```

å½“ç„¶è¿˜æœ‰å…¶ä»–ç‰¹æ€§ï¼Œè¿™é‡Œå°±ä¸ä»‹ç»äº†

`__class__` & `__dict__` & `__setattr__` & `__setitem__` 

æ¨¡å‹çš„å‚æ•°æ˜¯ä»¥ [yaml](https://www.runoob.com/w3cnote/yaml-intro.html) æ ¼å¼

[class](https://luobuda.github.io/2015/01/16/python-class/) [dict](https://www.jianshu.com/p/c390d591ce65) [all & init](https://stackoverflow.com/questions/44834/can-someone-explain-all-in-python)

`__all__` å®šä¹‰åœ¨ `__init__.py` ä¸­ï¼Œä»£è¡¨ç€ä»…åœ¨è¿™ä¸€å±‚ packageï¼Œä½ æƒ³è¦æš´éœ²çš„æ¥å£ï¼Œå¤–éƒ¨å¦‚æœä»è¿™ä¸ªåŒ…é‡Œ importï¼Œåªèƒ½ import `__all__` åˆ—è¡¨ä¸­åŒ…å«çš„æ¨¡å—ã€‚å¦‚æœç¡®å®å¸Œæœ›å¯¼å…¥æŸä¸ªæ¨¡å—ï¼Œä½†è¯¥æ¨¡å—ä¸å† `__all__` ä¸­ï¼Œå¯ä»¥é€šè¿‡å…·ä½“çš„è·¯å¾„è¿›è¡Œå¯¼å…¥ 

```python
import yaml

with open(file, mode='r') as f:
    cfg_dict = yaml.load(f, Loader=FullLoader)
```

## pathlib

ä¸€ä¸ªå¥½ç”¨çš„æ–‡ä»¶è·¯å¾„åº“ï¼Œä¸€äº›åŸºæœ¬ä½¿ç”¨å‚è€ƒ [çŸ¥ä¹](https://zhuanlan.zhihu.com/p/33524938)

æ›´è¯¦ç»†çš„æ€»ç»“ [çŸ¥ä¹](https://zhuanlan.zhihu.com/p/139783331)

## logging

ç”¨äºè®°å½•æ—¥å¿— [çŸ¥ä¹](https://zhuanlan.zhihu.com/p/360306588)





https://zhuanlan.zhihu.com/p/417286741

https://zhuanlan.zhihu.com/p/152120636

å¯ä»¥æŒ‰ç…§ä»¥ä¸‹äº”ä¸ªæ¨¡å—è¿›è¡Œç³»ç»Ÿå­¦ä¹ 

![image-20211104205646529](OpenPCDet/image-20211104205646529.png)

## KITTI æ•°æ®é›†å¤„ç†

<img src="OpenPCDet/image-20211105141924194.png" style="zoom:50%;" />

https://blog.csdn.net/weixin_44128857/article/details/108516213

https://zhuanlan.zhihu.com/p/99114433



numpy fromfile, tofile

skimage.io è¯»å–å›¾åƒ

æ„å»ºäº† Object3d ç±»å­˜å‚¨ç›®æ ‡/æ ‡ç­¾



Calibration ç±»ï¼Œç›®å‰ä¸çŸ¥é“æ€ä¹ˆç”¨ï¼Œå¯èƒ½éœ€è¦å¯è§†åŒ–æ¥å¸®åŠ©ä¸€ä¸‹

<img src="OpenPCDet/image-20211105214225556.png" alt="image-20211105214225556" style="zoom:50%;" />



<img src="OpenPCDet/image-20211105214139494.png" alt="image-20211105214139494" style="zoom: 50%;" />

## åˆ†å¸ƒå¼è®­ç»ƒ

https://zhuanlan.zhihu.com/p/113694038

æ‰“åŒ…æ•°æ®é›†ï¼Œæ‰“åŒ…æ¨¡å‹



tqdm åŒ…ç”¨äºå±•ç¤ºè¿›åº¦æ¡

https://zhuanlan.zhihu.com/p/163613814

set_postfix update refresh

# å¦‚ä½•å­¦ä¹ ä¸€ä¸ª Python é¡¹ç›®

1. å­¦ä¹  `main.py`
2. å­¦ä¹ æ¨¡å—ï¼Œå­¦ä¹ ç±»

python çš„å˜é‡æ˜¯éå¸¸çµæ´»çš„ï¼Œæœ‰æ—¶å€™å¹¶ä¸çŸ¥é“å“ªäº›å˜é‡ä»£è¡¨ç€ä»€ä¹ˆï¼Œå¦‚æœæœ‰ä¸€ä¸ªæŠ½è±¡çš„å®šä¹‰ï¼Œèƒ½å¦è®©ä½ ç†è§£è¿™ä¸ªæ¨¡å—çš„åŠŸèƒ½æ˜¯æœ€å¥½çš„

## å¯è§†åŒ–

tensorboard summarywriter

https://www.bilibili.com/video/BV1Qf4y1C7kz

https://pytorch.org/docs/stable/tensorboard.html



info.pkl æ–‡ä»¶æ ¼å¼ï¼Œä¸»è¦æ˜¯ä¸€äº›æ ‡ç­¾ä¿¡æ¯ï¼Œæ²¡æœ‰åŸå§‹ç‚¹äº‘ä¿¡æ¯

```shell
key: point_cloud
        num_features:4
        lidar_idx:000000
--------------------------
key: image
        image_idx:000000
        image_shape:[ 370 1224]
--------------------------
key: calib
        P2:...
        R0_rect:...
        Tr_velo_to_cam:...
--------------------------
key: annos
        name:['Pedestrian']
        truncated:[0.]
        occluded:[0.]
        alpha:[-0.2]
        bbox:[[712.4  143.   810.73 307.92]]
        dimensions:[[1.2  1.89 0.48]]
        location:[[1.84 1.47 8.41]]
        rotation_y:[0.01]
        score:[-1.]
        difficulty:[0]
        index:[0]
        gt_boxes_lidar:[[ 8.73138046 -1.85591757 -0.65469939  1.2         0.48        1.89
  -1.58079633]]
        num_points_in_gt:[377]
--------------------------
```

calib çŸ©é˜µæ˜¯ç”¨äºè½¬æ¢ç‚¹äº‘åæ ‡çš„ï¼Œå°†ç‚¹äº‘åæ ‡ä»ä¸€ä¸ªåæ ‡ç³»è½¬ç§»åˆ°å¦ä¸€ä¸ªåæ ‡ç³»ï¼Œæ¯”å¦‚ä»æ¿€å…‰é›·è¾¾ç›¸æœºåæ ‡ç³»ï¼Œè½¬ç§»åˆ°RGBç›¸æœºåæ ‡ç³»ï¼ŒR0_rect çŸ©é˜µæ˜¯ç”±äºåœ¨é•¿æ—¶é—´çš„è¿è¡Œä¸­ï¼ˆè½¦å­åœ¨å¼€ï¼‰ï¼Œåæ ‡ç³»ä¹‹é—´çš„ç›¸å¯¹ä½ç½®ä¼šå‘ç”Ÿå˜åŒ–



## ä¼˜åŒ–ç­–ç•¥ onecycle

https://blog.csdn.net/xys430381_1/article/details/89102866

one cycle ç­–ç•¥åˆ°åº•æ˜¯ä¸ªå•¥



use road plane åº”è¯¥ä¸ä¼šç‰¹åˆ«å½±å“ç»“æœ

The ground plane is just for GT sampling augmentation, and it also almost doesn't affect the final results much.



Field of view è§†åœºï¼Œè¡¨ç°è§†é‡èŒƒå›´

https://blog.csdn.net/gbmaotai/article/details/104835991



evaluation

model structure



æƒ³è¦ç»˜å›¾ï¼Œç›´æ¥ç”¨ matplotlib ç»å¯¹å¤Ÿç”¨ï¼Œä¸è®ºæ˜¯ç”»çŸ©å½¢æ¡†è¿˜æ˜¯æ·»åŠ æ–‡å­—

opencv å¯ä»¥å½“ä½œä¸šä½™çˆ±å¥½å¤ç°ä¸€ä¸‹åˆ«äººçš„é¡¹ç›®

## æ¨¡å‹å­¦ä¹ 

frame_id
gt_boxes
points
use_lead_xyz
voxels
voxel_coords
voxel_num_points
image_shape



collections æ¨¡å—

https://zhuanlan.zhihu.com/p/110476502



collate_fn

https://zhuanlan.zhihu.com/p/361830892



è¯»å– pickle æ–‡ä»¶ pkl

ä½¿ç”¨ np.fromfile è¯»å– bin æ–‡ä»¶ä¸º ndarrayï¼Œæ³¨æ„ dtype è¦ä¸æ•°æ®ä¸€è‡´ # å·²ç»æ€»ç»“åˆ° cheatsheet å½“ä¸­



numpy

nonzero å¯ä»¥è¿”å›éé›¶å€¼

## data_dict è·Ÿè¸ª

1. build_dataloader

   ```python
   train_set, train_loader, train_sampler = build_dataloader(
       dataset_cfg=cfg.DATA_CONFIG,
       class_names=cfg.CLASS_NAMES,
       batch_size=args.batch_size,
       dist=dist_train, workers=args.workers,
       logger=logger,
       training=True,
       merge_all_iters_to_one_epoch=args.merge_all_iters_to_one_epoch,
       total_epochs=args.epochs
   )
   ```

   1. init kitti dataset

      ```python
          dataset = __all__[dataset_cfg.DATASET](
              dataset_cfg=dataset_cfg,
              class_names=class_names,
              root_path=root_path,
              training=training,
              logger=logger,
          )
      ```

      1. init dataset template

         ```python
         super().__init__(
             dataset_cfg=dataset_cfg, class_names=class_names, training=training, root_path=root_path, logger=logger
         )
         ```

         ```python
                 Args:
                     root_path: none
                     dataset_cfg: cfg.DATA_CONFIG
                     class_names: pedestrian car cyclist
                     training:
                     logger:
                 çœ‹çœ‹æ•°æ®é›†åŸºç±»çš„ç»“æ„ï¼š
                 Attributes:
                     - dataset config
                     - training
                     - class_names
                     - root_path, é€šå¸¸åœ¨ dataset config ä¸­å·²ç»æŒ‡å®š DATA_PATH
                     - è‡ªå·±çš„ logger
                     - ç‚¹äº‘èŒƒå›´ point cloud range
                     - ç‚¹äº‘ç‰¹å¾ç¼–ç å™¨ point feature encoder
                     - æ•°æ®å¢å¼ºå™¨ sampling & rotation
                     - æ•°æ®å¤„ç†å™¨ voxelization
         ```

         1. init Point Feature encoder

            ```python
            POINT_FEATURE_ENCODING: {
                encoding_type: absolute_coordinates_encoding,
                used_feature_list: ['x', 'y', 'z', 'intensity'],
                src_feature_list: ['x', 'y', 'z', 'intensity'],
            }
            ```

         2. init DataAugmentor

            ```python
                    Args:
                        - root_path: DATA_PATH
                        - augmenter_config: DATA_AUGMENTOR ä»¥ KITTI ä¸ºä¾‹
                        -----------------------------------------------
                        DATA_AUGMENTOR:
                            DISABLE_AUG_LIST: ['placeholder']
                            AUG_CONFIG_LIST:
                                - NAME: random_world_flip
                                ALONG_AXIS_LIST: ['x']
                                ...
                                ...
                        -----------------------------------------------
                    Attributes:
                        - data_augmentor_queueï¼Œæ•°æ®å¢å¼ºå™¨ç»„æˆçš„åˆ—è¡¨
            ```

            é™¤äº†å°† augmentor ç»„æˆåˆ—è¡¨å¤–ï¼Œè¿˜å»é™¤äº†ä¸ç¬¦åˆè¦æ±‚çš„ gt æ ‡ç­¾

            ```shell
            2021-11-10 08:07:48,480   INFO  Database filter by min points Car: 14357 => 13532
            2021-11-10 08:07:48,482   INFO  Database filter by min points Pedestrian: 2207 => 2168
            2021-11-10 08:07:48,483   INFO  Database filter by min points Cyclist: 734 => 705
            2021-11-10 08:07:48,527   INFO  Database filter by difficulty Car: 13532 => 10759
            2021-11-10 08:07:48,535   INFO  Database filter by difficulty Pedestrian: 2168 => 2075
            2021-11-10 08:07:48,538   INFO  Database filter by difficulty Cyclist: 705 => 581
            ```

            å¯¹ kitti_dbinfos_train.pkl ä¸­çš„å†…å®¹è¿›è¡Œè¿‡æ»¤

            ```python
                        - NAME: gt_sampling
                        USE_ROAD_PLANE: True
                        DB_INFO_PATH:
                            - kitti_dbinfos_train.pkl
                        PREPARE: {
                            filter_by_min_points: ['Car:5', 'Pedestrian:5', 'Cyclist:5'],
                            filter_by_difficulty: [-1],
                        }
            
                        SAMPLE_GROUPS: ['Car:20','Pedestrian:15', 'Cyclist:15']
                        NUM_POINT_FEATURES: 4
                        DATABASE_WITH_FAKELIDAR: False
                        REMOVE_EXTRA_WIDTH: [0.0, 0.0, 0.0]
                        LIMIT_WHOLE_SCENE: True
            ```

         3. init data porcessor

            ```python
                        DATA_PROCESSOR:
                            - NAME: mask_points_and_boxes_outside_range
                            REMOVE_OUTSIDE_BOXES: True
            
                            - NAME: shuffle_points
                            SHUFFLE_ENABLED: {
                                'train': True,
                                'test': False
                            }
            
                            - NAME: transform_points_to_voxels
                            VOXEL_SIZE: [0.05, 0.05, 0.1]
                            MAX_POINTS_PER_VOXEL: 5
                            MAX_NUMBER_OF_VOXELS: {
                                'train': 16000,
                                'test': 40000
                            }
            ```

      2. è·å¾— split æ–‡ä»¶è·¯å¾„å¦‚ ImageSets/train.txt

      3. è·å¾—æ ·æœ¬åˆ—è¡¨ self.sample_id_list

      4. åŠ è½½ kitti_info_train.pkl ä¿¡æ¯ self.kitti_infos = []

   2. åˆ†å¸ƒå¼æ‰“åŒ…æ•°æ®é›†

      ```python
      sampler = torch.utils.data.distributed.DistributedSampler(dataset)
      ```

   3. init Dataloader

      ```python
      dataloader = DataLoader(
          dataset, batch_size=batch_size, pin_memory=True, num_workers=workers,
          shuffle=(sampler is None) and training, collate_fn=dataset.collate_batch,
          drop_last=False, sampler=sampler, timeout=0
      ```

2. build networks

   ```python
   model_info_dict = {
       'module_list': [],
       # ä¸‹é¢ä¸¤ä¸ª featrue åˆå§‹åŒ–éƒ½æ˜¯ 4 (x, y, z, intensity)
       'num_rawpoint_features': self.dataset.point_feature_encoder.num_point_features,
       'num_point_features': self.dataset.point_feature_encoder.num_point_features,
       'grid_size': self.dataset.grid_size,
       'point_cloud_range': self.dataset.point_cloud_range,
       'voxel_size': self.dataset.voxel_size,
       # æœ‰çš„æ²¡æœ‰ downsample ä¸º None
       'depth_downsample_factor': self.dataset.depth_downsample_factor
   }
   ```

   ```python
   self.add_module(module_name, module)
   ```

   åˆå§‹åŒ–ç½‘ç»œï¼Œadd_module å°†æ¨¡å—ä½œä¸ºå­æ¨¡å—ï¼Œself.module_list åŒ…å«äº†æ‰€æœ‰æ¨¡å—\

3. build optimizer

4. ï¼ˆå¦‚æœæœ‰ï¼‰åŠ è½½ checkpoint

5. build scheduler

   ```python
   lr_scheduler, lr_warmup_scheduler = build_scheduler(
       optimizer, total_iters_each_epoch=len(train_loader), total_epochs=args.epochs,
       last_epoch=last_epoch, optim_cfg=cfg.OPTIMIZATION
   )
   ```

6. train a model

   ```python
   train_model(
       model,
       optimizer,
       train_loader,
       model_func=model_fn_decorator(),
       lr_scheduler=lr_scheduler,
       optim_cfg=cfg.OPTIMIZATION,
       start_epoch=start_epoch,
       total_epochs=args.epochs,
       start_iter=it,
       rank=cfg.LOCAL_RANK,
       tb_log=tb_log,
       ckpt_save_dir=ckpt_dir,
       train_sampler=train_sampler,
       lr_warmup_scheduler=lr_warmup_scheduler,
       ckpt_save_interval=args.ckpt_save_interval,
       max_ckpt_save_num=args.max_ckpt_save_num,
       merge_all_iters_to_one_epoch=args.merge_all_iters_to_one_epoch
   )
   ```

   1. è·å–æ•°æ® dataloader_iter = iter(data_loader)	`next(dataloader_iter)`

      è¿™é‡Œæ— æ³•ä½¿ç”¨è°ƒè¯•è·å¾— next é‡Œé¢çš„ç»†èŠ‚ï¼Œåªèƒ½è‡ªå·±ä¸€ä¸ªä¸€ä¸ªçœ‹äº†ï¼ï¼å…ˆä¸Š`data_dict` ç»“æœï¼Œå¯ä»¥çœ‹åˆ°ç»“æœæ˜¯æœ‰å¢å¼ºçš„ï¼Œæ¯”å¦‚ gt_boxes, points

      ```shell
      frame_id
      (4,)
      gt_boxes
      (4, 42, 8)
      points
      (89649, 5)
      use_lead_xyz
      (4,)
      voxels
      (64000, 5, 4)
      voxel_coords
      (64000, 4)
      voxel_num_points
      (64000,)
      image_shape
      (4, 2)
      batch_size
      4
      ```

      1. å…ˆçœ‹ `__getitem__` æ–¹æ³•ï¼Œæœ¬è´¨æ˜¯æ ¹æ® self.kitti_infos åˆ—è¡¨ä¸­å¾—åˆ°ç‚¹äº‘å’Œæ ‡ç­¾çš„ä¿¡æ¯ï¼Œç„¶åé€šè¿‡æ•°æ®å¢å¼ºå’Œæ•°æ®å¤„ç†ï¼Œå­˜å‚¨ä¸º `data_dict` å­—å…¸ï¼Œä½œä¸ºæœ€ç»ˆè®­ç»ƒçš„æ•°æ®ã€‚æ‰€ä»¥è¿™ä¸ª `data_dict` å°±æ˜¯æ ¸å¿ƒä¸­çš„æ ¸å¿ƒï¼Œéå¸¸é‡è¦

          ```python
                  --------------------------
                  key: point_cloud
                          num_features:4
                          lidar_idx:000000
                  --------------------------
                  key: image
                          image_idx:000000
                          image_shape:[ 370 1224]
                  --------------------------
                  key: calib
                          P2:...
                          R0_rect:...
                          Tr_velo_to_cam:...
                  --------------------------
                  key: annos
                          name:['Pedestrian']
                          truncated:[0.]
                          occluded:[0.]
                          alpha:[-0.2]
                          bbox:[[712.4  143.   810.73 307.92]]
                          dimensions:[[1.2  1.89 0.48]]
                          location:[[1.84 1.47 8.41]]
                          rotation_y:[0.01]
                          score:[-1.]
                          difficulty:[0]
                          index:[0]
                          gt_boxes_lidar:[[ 8.73138046 -1.85591757 -0.65469939  1.2         0.48        1.89
                  -1.58079633]]
                          num_points_in_gt:[377]
                  --------------------------
          ```

          ç°åœ¨å‡†å¤‡ä¸€ä¸ª input_dict ä½œä¸º prepare_data çš„è¾“å…¥ï¼Œinput dict çš„å†…å®¹å¤§è‡´å’Œ kitti_inofs ç›¸åŒï¼Œæœ‰ä¸¤ç‚¹æ“ä½œéœ€è¦æ³¨æ„ä¸€ä¸‹ï¼š

          1. å¯¹ **gt boxes** åšäº†ä¸€äº›å¤„ç†ï¼Œä¸€ä¸ªæ˜¯å°†ä¸­å¿ƒã€å¤§å°ã€æ—‹è½¬è§’ä¸‰ä¸ªç‰¹å¾åˆå¹¶ä¸ºä¸€ä¸ª ndarrayï¼Œå¦ä¸€ä¸ªæ˜¯åæ ‡ç³»çš„è½¬æ¢ï¼Œä» camera åæ ‡ç³»è½¬åŒ–ä¸º lidar åæ ‡ç³»
          2. è·å¾—åŸå§‹ç‚¹äº‘ **points**ï¼Œå¹¶å»é™¤ä¸æ˜¯ FOV è§†åœºè§’ä¸­çš„ç‚¹ï¼Œè¿™å°†å‡å°‘å¤§é‡çš„ç‚¹äº‘æ•°æ®ï¼Œå¤§çº¦ä» 100k -> 20k
          
      2. å†çœ‹ prepare_dataï¼ŒåŸºæœ¬ç”±ä»¥ä¸‹ä¸‰ä¸ªéƒ¨åˆ†ç»„æˆ

          ```python
          data_dict = self.prepare_data(data_dict=input_dict)
          ```
      
          1. data_augmentor.forward
      
              1. gt_sampling
      
                  é™¤äº†ä¹‹å‰çš„å¯¹ç‚¹å°‘çš„ gt è¿›è¡Œç­›é€‰ä¹‹å¤–ï¼Œè¿™é‡Œè¿˜æœ‰æ–°çš„æ“ä½œï¼Œå°±æ˜¯å°†æ‰€æœ‰çš„ gt database ä½œä¸ºä¸€ä¸ªå¤§æ ·æœ¬æ± ï¼Œè¿›è¡Œé‡‡æ · `SAMPLE_GROUPS: ['Car:20','Pedestrian:15', 'Cyclist:15']` ç„¶åå°†è¿™äº›ç‚¹æ”¾å…¥çš„åˆ°ç‚¹äº‘åœºæ™¯ä¸­ï¼Œè¦å»é™¤ä¸æ»¡è¶³è¦æ±‚çš„æ ·æœ¬ï¼Œä¾‹å¦‚é‡åˆæ ·æœ¬
      
              2.  random rotation & filp & scaling 
      
          2. ç»™ boxes åŠ å…¥ç±»åˆ«ç‰¹å¾ï¼ˆone hotï¼‰ï¼Œè‡³æ­¤ boxes ç»´åº¦ç”±7å˜ä¸º8
      
          3. point_feature_encoding.forward
      
              ![image-20211110183032199](OpenPCDet/image-20211110183032199.png)
      
              ![image-20211110183045377](OpenPCDet/image-20211110183045377.png)
      
              åŸºæœ¬ä¸Šæ²¡æœ‰å˜åŒ–ï¼Œdata_dict åªå¤šäº†ä¸€ä¸ª used_xyz
      
          4. data_processor.forward
      
              ![image-20211110184159897](OpenPCDet/image-20211110184159897.png)
      
              ![image-20211110184217297](OpenPCDet/image-20211110184217297.png)
      
              ![image-20211110184313679](OpenPCDet/image-20211110184313679.png)
      
              ä¸»è¦æ˜¯ä½¿ç”¨ spconv è¿›è¡Œä½“ç´ åŒ–ï¼Œdata_dict å¤šäº†ä¸€äº›å†…å®¹
      
              ```python
              # voxels: [M, max_points, ndim] float tensor. only contain points.
              # coordinates: [M, 3] int32 tensor. zyx format.
              # num_points_per_voxel: [M] int32 tensor.
              ```
      
              æ­¤æ—¶åº”è¯¥è¿˜æ²¡æœ‰å¯¹ä½“ç´ ç‰¹å¾è¿›è¡Œå¤„ç†
              
          5. post process, collate_fnï¼Œç»§ç»­å¯¹æ ·æœ¬è¿›è¡Œå¤„ç†ï¼š
      
              1. ç»™ 'points' å’Œ 'voxel_coords' åŠ å…¥ç‰¹å¾ batch_idx åœ¨æœ€å‰é¢ï¼Œè¡¨æ˜æ˜¯è¿™ä¸ªç‚¹æ˜¯æ¥è‡ªäºè¯¥ batch ä¸­çš„ç¬¬å‡ ä¸ª sample
              2. ç”±äº batch ä¸­æ¯ä¸ª gt æ ‡ç­¾ä¸ªæ•°å¯èƒ½ä¸ä¸€æ ·
      
      3. æ ¹æ® epoch æ›´æ–°å­¦ä¹ ç‡ï¼Œmodel.trainï¼Œoptimizer.zero_grad()
      
      4. **è®¡ç®— loss**
      
      5. loss.backward() & optimizer.step()

## result.pkl

```shellname (3,)
name (3,)
['Car' 'Car' 'Car']
-------------------------------------
truncated (3,)
[0. 0. 0.]
-------------------------------------
occluded (3,)
[0. 0. 0.]
-------------------------------------
alpha (3,)
[-7.9 -4.6 -4.3]
-------------------------------------
bbox (3, 4)
[[764.6 173.1 811.6 209.8]
 [392.1 181.5 416.8 201.7]
 [217.8 188.6 273.4 213.2]]
-------------------------------------
dimensions (3, 3)
[[3.5 1.4 1.5]
 [3.9 1.5 1.6]
 [4.1 1.4 1.6]]
-------------------------------------
location (3, 3)
[[  7.1   1.4  29.3]
 [-16.7   2.3  58.5]
 [-23.5   2.5  46.5]]
-------------------------------------
rotation_y (3,)
[-7.7 -4.9 -4.7]
-------------------------------------
score (3,)
[0.5 0.5 0.2]
-------------------------------------
boxes_lidar (3, 7)
[[29.6 -7.1 -0.5  3.5  1.5  1.4  6.1]
 [58.8 16.7 -0.8  3.9  1.6  1.5  3.3]
 [46.8 23.5 -1.1  4.1  1.6  1.4  3.1]]
-------------------------------------
frame_id 000001
