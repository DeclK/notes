# SGLang Kernel

ä¸€å¼€å§‹æˆ‘è¿˜åœ¨çº ç»“çœ‹ sglang å¥½ï¼Œè¿˜æ˜¯çœ‹ vllm å¥½ï¼Œæœ€åå‘ç°ä¸¤ä¸ªéƒ½ä¸å¥½ä¸Šæ‰‹ã€‚ä»¥ä¸‹æ˜¯æˆ‘è¿˜åœ¨çº ç»“æ—¶çš„ç¬”è®°ï¼š

ç»¼åˆçœ‹ä¸‹æ¥ï¼Œsglang çš„ä»£ç å…¶å®æ¯” vllm å†™å¾—æ›´åŠ ç®€å•ï¼Œè™½ç„¶å¤§å®¶éƒ½åœ¨è¯´ vllm æ¯” sglang å¥½ä¸Šæ‰‹ï¼Œä½†ä»ä»£ç é‡æ¥çœ‹å¹¶éå¦‚æ­¤

```txt
ğŸ‘‰SGLANGğŸ‘ˆ
--------------------------------------------------------------------------------
Language                      files          blank        comment           code
--------------------------------------------------------------------------------
CUDA                             36           1107            927           8801
C++                              20           1062            814           7247

ğŸ‘‰VLLMğŸ‘ˆ
-------------------------------------------------------------------------------
Language                     files          blank        comment           code
-------------------------------------------------------------------------------
CUDA                           112           5072           3888          30277
C/C++ Header                    44           1515           1047           7752
C++                             13            424            305           2618
```

å¯ä»¥çœ‹åˆ° vllm çš„ä»£ç æ•°é‡å‡ ä¹æ˜¯ sglang çš„ä¸‰å€ã€‚è¿™æ˜¯å› ä¸º sglang ä¸­è¿˜å€Ÿç”¨äº† vllm çš„ä»£ç ï¼Œä¾‹å¦‚ sglang é‡Œå°±æ²¡æœ‰æä¾› w4a16 marlin kernel çš„å®ç°ï¼Œè€Œæ˜¯ç›´æ¥å¤ç”¨äº† vllm ä¸­çš„ layerï¼Œæˆ–è®¸æˆ‘ä»¬å¯ä»¥è‡ªå·±é›†æˆåˆ° sglang å½“ä¸­ğŸ¤”

sglang é¢å¤–ç»™ sm80 å†™äº† cutlass exetensionï¼Œçœ‹ä¸Šå»æ˜¯æŠŠ cutlass 2.x çš„ä¸¤ä¸ªæ–‡ä»¶ç»™æ¬è¿‡æ¥äº†ã€‚çœ‹æ¥æˆ‘åŠ¿å¿…å¾—æŠŠ cutlass 2.x å’Œ cutlass 3.x åˆ†å¼€æ¥ç”¨æ‰è¡Œï¼Œæ˜¾ç„¶ 3.x å¯¹ 2.x çš„å…¼å®¹å¹¶ä¸å¥½

æˆ‘æœ¬æ¥å¸Œæœ›å®Œæˆçš„å­¦ä¹ ç›®æ ‡ï¼š

1. å¦‚ä½•ä½¿ç”¨ cutlass api å®Œæˆæ‰€éœ€è¦çš„çŸ©é˜µä¹˜æ³•
2. å¦‚ä½•ä½¿ç”¨ epilogue å®Œæˆç®—å­èåˆ

3. å¦‚ä½•é«˜æ•ˆåœ°æ„å»º profile/benchmark è„šæœ¬

   - å¦‚ä½•åœ¨ python ä¸­æ„å»ºæµ‹è¯•è„šæœ¬
   - å¦‚ä½•å°† cuda kernel ç»‘å®šåˆ° torch
     - å¦‚ä½•æ„å»º `CMakelists.txt & setup.py`
     - å¦‚ä½•å°†é¡¹ç›®è¿›è¡Œæ‰“åŒ…ï¼Œå½¢æˆä¸€ä¸ª wheel æ–‡ä»¶

ä¸­é€”è¿˜å‘ç°äº† [gemm-int8](https://github.com/IST-DASLab/gemm-int8) é¡¹ç›®ï¼Œæœ¬æ¥æƒ³æ·±å…¥å­¦ä¹ è¿™ä¸ªå°é¡¹ç›®çš„ï¼Œå‘ç°è¿™ä¸ªé¡¹ç›®åœ¨ hopper ä¸Šæ€§èƒ½å¾ˆå·®ï¼Œå‡ ä¹è·Ÿ fp16 ä¸€æ ·ï¼Œæ‰€ä»¥å¿…é¡»ä½¿ç”¨ cutlass 3.x æ¥å£æ¥åŠ é€Ÿ

æœ€åç»è¿‡ä¸€ç•ªæ€è€ƒè¿˜æ˜¯å¾—å‡ºç»“è®ºï¼šcutlass ä¸é€‚åˆå­¦ä¹ ï¼Œåªé€‚åˆä½¿ç”¨ã€‚åŸºäºè¿™ä¸ªç»“è®ºï¼Œæˆ‘å…¶å®è¦åšçš„å°±æ˜¯å­¦ä¹ é‚£äº› sglang æ˜¯å¦‚ä½•ä½¿ç”¨ cutlass çš„ï¼Œæˆ‘åªéœ€è¦å€Ÿç”¨å…¶ä»£ç ï¼Œä½œä¸ºæˆ‘çš„ç®—å­â€œä»£ç†â€å³å¯ã€‚å¦‚æœæˆ‘çœŸçš„è¦æ·±å…¥å­¦ï¼Œæˆ‘ä¼°è®¡ä¼šçœ‹ svdquant ä¸­çš„æ¨ç†å¼•æ“æ¡†æ¶ï¼Œå…¶æœ‰è‡ªå·±çš„ gemm structï¼Œå°† mainloop & epilogue åªåšäº†ç®€å•çš„æŠ½è±¡ï¼Œæ²¡æœ‰ cutlass å¤æ‚çš„æ¨¡æ¿ï¼Œå¹¶ä¸”åŒ…å«å„ç§èåˆç®—å­ã€‚å¦å¤–å†çœ‹ svdquant ä¸­å‘ç° Hopper GPU ä¸æ”¯æŒ 4-bit tensor core [issue](https://github.com/mit-han-lab/nunchaku/issues/268)

æ€»ç»“ï¼šå­¦ä¹ ç›®æ ‡å°±å¤§ç¼©æ°´ï¼Œæ ¸å¿ƒå˜ä¸ºäº†å¦‚ä½•æ„å»º cuda cpp python é¡¹ç›®ï¼Œä»¥ sglang-kernel ä¸ºä¾‹

## How to debug CUDA

åœ¨è§‚çœ‹ [bilibili](https://www.bilibili.com/video/BV1kToTY6Eh5?spm_id_from=333.788.videopod.episodes&p=8) çš„æ—¶å€™å‘ç°äº† CUDA å…¶å®æ˜¯å¯ä»¥è¿›è¡Œ debug çš„ï¼Œä½†æ˜¯åœ¨è‡ªå·±å®é™…æ“ä½œçš„æ—¶å€™å‘ç°ï¼Œæ˜¯çœŸçš„ä¸å¥½ç”¨ã€‚ä¸è¿‡è¿˜æ˜¯å°†ç»éªŒæ€»ç»“ä¸€ä¸‹ï¼Œæ¯•ç«ŸèŠ±äº†ä¸€æ•´å¤©çœ‹è¿™ä¸ªğŸ˜…å‚è€ƒèµ„æ–™ [zhihu](https://zhuanlan.zhihu.com/p/508810115) [blog](https://fancyerii.github.io/2024/01/17/vscode-cuda-debug/) [github issue](https://github.com/graphdeco-inria/gaussian-splatting/issues/827)

å¯¹äº vscode æ¥è¯´ï¼Œåªéœ€è¦å®‰è£…ä¸¤ä¸ªæ’ä»¶ c++ & nsight system å³å¯ï¼Œç„¶åé€šè¿‡ `launch.json` é…ç½®éœ€è¦è¿è¡Œçš„ executable å³å¯ã€‚è€Œè·å¾— executable éœ€è¦æœ‰ debug ä¿¡æ¯æ‰èƒ½æ­£å¸¸è¿›å…¥æ–­ç‚¹ã€‚æ­¤æ—¶éœ€è¦å†ç¼–è¯‘çš„æ—¶å€™åŠ å…¥ `-g -G` flag ä»¥åŠ å…¥ debug ä¿¡æ¯ï¼Œå…¶ä¸­å¤§å° g åˆ†åˆ«ä»£è¡¨ host code & device code

å¦‚æœç›´æ¥ä½¿ç”¨ `nvcc` æ¥è¿›è¡Œç¼–è¯‘ï¼Œé‚£ä¹ˆç›´æ¥åŠ  `-g -G` å³å¯ã€‚ä½†é€šå¸¸é¡¹ç›®æ„å»ºä¼šä½¿ç”¨ cmakeï¼Œæ‰€ä»¥éœ€è¦ç”¨ cmake å‘½ä»¤

```cmake
target_compile_options(your_target PRIVATE $<$<COMPILE_LANGUAGE:CUDA>:-g -G>)
```

å½“è¿›è¡Œé…ç½®è¿‡åçš„ç¡®èƒ½å¾ˆå®¹æ˜“è¿›å…¥ host code debug æ–­ç‚¹ï¼Œä½†æ˜¯å¯¹äº cuda code debug æ–­ç‚¹è¡¨ç°å¾—ç›¸å½“å¥‡æ€ªï¼Œä»¥ä¸‹æ˜¯ä¸€äº›ç®€è¦ç°è±¡ï¼š

1. æ— æ³•é€šè¿‡ step in è¿›å…¥ cuda codeï¼Œå¿…é¡»åœ¨ cuda code é‡Œæ‰“ä¸‹æ–­ç‚¹ï¼Œæ‰èƒ½åœ¨åœåœ¨ cuda code ä¸­çš„æ–­ç‚¹é‡Œã€‚æ¢å¥è¯è¯´ï¼Œå¦‚æœ cuda code é‡Œæ²¡æœ‰æ–­ç‚¹ï¼Œæ˜¯æ— æ³•è¿›å…¥ cuda code debug çš„
2. å¯ä»¥ç›´æ¥ä½¿ç”¨ `cuda-gdb .program` åŠ  `step` å‘½ä»¤æ¥æŸ¥çœ‹ä»£ç è¿è¡Œä½ç½®
3. åŠ å…¥äº† debug flag è¿‡åï¼ŒçœŸå®è¿è¡Œç¨‹åºå¯èƒ½ä¼šè¡¨ç°ä¸ä¸€æ ·ï¼ŒåŒ…æ‹¬ä½†ä¸é™äºï¼šç¨‹åºå‡ºé”™ã€ç¨‹åºå¡æ­»ç­‰
4. **print æ‰æ˜¯ cuda æœ€ç»ˆçš„ debug æ–¹æ³•ï¼**

## .cu .cuh .h .cpp .cc

å¤´æ–‡ä»¶ç±»ï¼š`.cuh & .h`ï¼Œè¿™ä¸€ç±»æ–‡ä»¶æ˜¯ä¸ä¼šå‡ºç°åœ¨ `add_library or add_executable` å½“ä¸­çš„ï¼Œè€Œä¸”ä¸€èˆ¬ä¸ä¼šå°†å®ç°æ”¾åœ¨å…¶ä¸­ï¼Œé™¤éä¸ºäº†æ•ˆç‡è€ƒé‡ï¼Œä¼šå°† inline function å†™åœ¨å¤´æ–‡ä»¶å½“ä¸­ã€‚åœ¨å¤´æ–‡ä»¶ä¸­é€šå¸¸ä¼šå†™å…¥ä¸‰ç±»ä»£ç ï¼š

1. function/class declaration
2. macro helper
3. inline function
4. template function/struct

æºæ–‡ä»¶ç±»ï¼š`.cu & .cc & .cpp`ï¼Œè¿™ä¸‰ä¸ªæ˜¯ cuda & c++ æºæ–‡ä»¶ï¼Œæ˜¯ cooking çš„â€œåŸææ–™â€ï¼Œä¼šå®é™…åœ°è¿›è¡Œç¼–è¯‘ï¼

åœ¨ sglang kernel ä¸­ä»£ç å®ç°æŒ‰ç…§å¦‚ä¸‹

```txt
sglang/sgl-kernel/csrc
â”œâ”€â”€ allreduce
â”‚   â”œâ”€â”€ custom_all_reduce.cu
â”‚   â”œâ”€â”€ custom_all_reduce.cuh
|	...
â”œâ”€â”€ attention
â”‚   â”œâ”€â”€ cascade.cu
â”‚   â”œâ”€â”€ cutlass_mla_kernel.cu
|	...
â”œâ”€â”€ cpu
â”‚   â”œâ”€â”€ CMakeLists.txt
â”‚   â”œâ”€â”€ activation.cpp
|	...
â”œâ”€â”€ cutlass_extensions
â”‚   â”œâ”€â”€ epilogue
â”‚   â”‚   â””â”€â”€ epilogue_per_row_per_col_scale.h
â”‚   â””â”€â”€ gemm
â”‚       â”œâ”€â”€ gemm_universal_base_compat.h
â”‚       â””â”€â”€ gemm_with_epilogue_visitor.h
â”œâ”€â”€ elementwise
â”‚   â”œâ”€â”€ activation.cu
â”‚   â”œâ”€â”€ fused_add_rms_norm_kernel.cu
â”‚   â””â”€â”€ rope.cu
â”œâ”€â”€ gemm
â”‚   â”œâ”€â”€ awq_kernel.cu
â”‚   â”œâ”€â”€ bmm_fp8.cu
|	...
â”œâ”€â”€ moe
â”‚   â”œâ”€â”€ cutlass_moe_helper.cu
â”‚   â”œâ”€â”€ fp8_blockwise_moe_kernel.cu
|	...
â”œâ”€â”€ common_extension.cc
â”œâ”€â”€ flash_extension.cc
â””â”€â”€ torch_extension_rocm.cc
```

`csrc` åŒ…å«äº†æ‰€æœ‰çš„ `.cu` æ–‡ä»¶ï¼ˆkernel å®ç°ï¼‰ï¼Œç„¶åé€šè¿‡ `.cc` æ–‡ä»¶ binding åˆ° pytorch å½“ä¸­ã€‚å…¶ä¸­ `.cc` æ–‡ä»¶ä¸­çš„ kernel å…¨éƒ¨ç”±å¤´æ–‡ä»¶å£°æ˜å¼•å…¥ï¼Œè€Œå¤´æ–‡ä»¶å•ç‹¬æ”¾åœ¨ `csrc` ä¹‹å¤–çš„ `include` æ–‡ä»¶å¤¹å½“ä¸­

```txt
sglang/sgl-kernel/include
â”œâ”€â”€ sgl_flash_kernel_ops.h
â”œâ”€â”€ sgl_kernel_ops.h
â”œâ”€â”€ sgl_kernel_torch_shim.h
â””â”€â”€ utils.h
```

æœ€ç»ˆå°†æ‰€æœ‰çš„ `.cc & .cu` æºæ–‡ä»¶æ·»åŠ åˆ° library å½“ä¸­ï¼Œå®Œæˆç¼–è¯‘

```cmake
include_directories(
    ${PROJECT_SOURCE_DIR}/include
    ${PROJECT_SOURCE_DIR}/csrc
    ${repo-cutlass_SOURCE_DIR}/include
    ${repo-cutlass_SOURCE_DIR}/tools/util/include
    ${repo-flashinfer_SOURCE_DIR}/include
    ${repo-flashinfer_SOURCE_DIR}/csrc
)
set(SOURCES
    "csrc/allreduce/custom_all_reduce.cu"
    "csrc/attention/cascade.cu"
    ...
    "csrc/common_extension.cc"
)

Python_add_library(common_ops MODULE USE_SABI ${SKBUILD_SABI_VERSION} WITH_SOABI ${SOURCES})
```

å…¶ä¸­å°† `csrc` æ–‡ä»¶å¤¹ä¹Ÿæ·»åŠ åˆ° include è·¯å¾„å½“ä¸­ï¼Œæ˜¯å› ä¸ºå…¶ä¸­ä¹Ÿæœ‰ä¸€äº›å­ç›®å½•ä¸­åŒ…å«å¤´æ–‡ä»¶ï¼ˆä¾‹å¦‚ `cutlass_extention`ï¼‰ï¼Œé€šè¿‡å¤šçº§è·¯å¾„è¿›è¡Œ include `#include "cutlass_extentions/..."`

## kernel launch and dispatch wrapper

ä¸€èˆ¬åœ¨ pytorch ä¸­è°ƒç”¨ kernel çš„é€»è¾‘æœ‰å››å±‚ï¼Œæˆ‘è‡ªåº•å‘ä¸Šè¿›è¡Œæ•´ç†

1. global kernel functionï¼Œæ ¸å¿ƒçš„ CUDA kernel ä»£ç ï¼Œä»¥ `__global__` è¿›è¡Œæ ‡è¯†
2. launching functionï¼Œä¸º host functionï¼Œç”¨äº laucn kernelï¼Œéœ€è¦å¡«å…¥ launch å‚æ•°ï¼šgridï¼Œblockï¼Œstreamï¼Œshared memoryã€‚è¿™ä¸€æ­¥ä¸€èˆ¬åœ¨ cutlass ä¸­å·²ç»è¢«åŒ…è£…å¥½äº†ï¼Œè°ƒç”¨çš„æ˜¯ `gemm_op(Â·)`
3. torch functionï¼Œå°† launch function åŒ…è£…èµ·æ¥ï¼Œä½¿å¾—å…¶èƒ½å¤Ÿæ¥å—è¾“å…¥å‚æ•°ä¸º torch tensorã€‚é€šè¿‡ä¼ å…¥ torch tensor çš„ç›¸å…³ä¿¡æ¯ï¼ˆtensor shapeï¼Œdata pointerï¼‰ç»™ launch functionï¼Œä»è€Œè¿è¡Œ GPUã€‚æ­¤æ—¶ç”±äº cutlass çš„åŸå› ï¼Œtorch function è¿˜å¯èƒ½æ˜¯ä¸€ä¸ªæ¨¡æ¿å‡½æ•°ï¼Œè¿™äº›æ¨¡æ¿å‚æ•°ä¼šè¢« cutlass ä½¿ç”¨åˆ°ã€‚é‚£ä¹ˆä¸ºäº†å°† torch template function è¿›è¡Œå®ä¾‹åŒ–ï¼Œåˆ™è¯ç”Ÿäº†ä¸‹ä¸€å±‚çš„ dispatch é€»è¾‘
4. dispatch functionï¼Œéœ€è¦ç¡®å®š gemm æ¨¡æ¿å‚æ•°ï¼ŒåŒ…æ‹¬ï¼škernel shape, output dtype, sm version ç­‰ï¼Œæ­¤æ—¶å°±éœ€è¦ dispatch function æ¥ç»†åŒ–ã€‚å¯¹äºä¸åŒ shape çš„è¾“å…¥ tensorï¼Œå¯ä»¥é€‰æ‹©ä¸åŒ kernel shape æ¥è·å¾—æ›´ä¼˜æ€§èƒ½ã€‚åŒæ—¶åœ¨ dispatch ä¹‹å‰è¿˜ä¼šå¯¹è¾“å…¥è¿›è¡Œä¸€äº› checkï¼Œä»¥ç»™å‡ºæŠ¥é”™ä¿¡æ¯

å…¶å®å¦‚æœæ²¡æœ‰ cutlass æ¨¡æ¿çš„è¯ï¼Œ ç¬¬äºŒå±‚å’Œç¬¬ä¸‰å±‚çš„è°ƒç”¨é€»è¾‘å°±å¯ä»¥åˆå¹¶èµ·æ¥ï¼Œä½¿å¾—æ•´ä¸ªç»“æ„å˜å¾—ç®€å•

## cmake command

å¯¹ cmake ä¸­çš„å‘½ä»¤åšä¸€äº›æ•´ç†ï¼Œå¹¶ç»™å‡ºä¸€ä¸ªä¸€èˆ¬çš„æ„å»º cuda extention æµç¨‹

1. Compile options

   sglang é¦–å…ˆå®šä¹‰äº†ä¸€äº›åŸºç¡€ nvcc flagsï¼Œç„¶åæ ¹æ® cuda version æˆ–è€… enable option å†å¯¹ flag è°ƒæ•´ã€‚è¿™é‡Œæˆ‘å¯¹ä¸€äº›å¸¸è§çš„ flags åšæ•´ç†

   ```cmake
   set(SGL_KERNEL_CUDA_FLAGS
       "-DNDEBUG"	# Defines NDEBUG macro
       "-DOPERATOR_NAMESPACE=sgl-kernel"
       "-O3"		# O3, is the highest optimization level
       "-gencode=arch=compute_75,code=sm_75"	# Generates code for different NVIDIA GPUs
       "-gencode=arch=compute_80,code=sm_80"
       "-gencode=arch=compute_89,code=sm_89"
       "-gencode=arch=compute_90,code=sm_90"
       "-std=c++17"
       "--expt-relaxed-constexpr"	# Allow host & device code to invoke __device__ & __host__ constexpr functions
       "--expt-extended-lambda"	# Allow __host__, __device__ annotations in lambda declaration
       "--threads=32"				# Threads for compile
   
       # Suppress warnings
       "-Xcompiler=-Wconversion"
       "-Xcompiler=-fno-strict-aliasing"
       # "-use_fast_math" # Fast math method for older CUDA versions
   )
   ```

2. find packages

   æˆ‘ä»¬éœ€è¦ä½¿ç”¨ python & torch package æ¥æ„å»º torch extensionï¼Œå½“ç„¶ cuda package è‚¯å®šä¹Ÿæ˜¯éœ€è¦çš„

   ```cmake
   # Python
   find_package(Python COMPONENTS Interpreter Development.Module ${SKBUILD_SABI_COMPONENT} REQUIRED)
   # SKBUILD_SABI_COMPONENT is automatically introduced by python cmake config (if has it)
   
   # CUDA
   find_package(CUDAToolkit REQUIRED)
   set_property(GLOBAL PROPERTY CUDA_SEPARABLE_COMPILATION ON)
   # implicitly enbale separate compilation for cuda, might not be necessary but recommend
   
   # Torch
   find_package(Torch REQUIRED)
   ```

   æœ‰æ—¶å€™æˆ‘åœ¨ä¸€ä¸ª venv å½“ä¸­æ‰¾ä¸åˆ° torchï¼Œå¯èƒ½æ˜¯å› ä¸ºæˆ‘çš„ torch æ˜¯ä» system-packages å½“ä¸­å¯¼å…¥ï¼Œè‡ªç„¶ä¸åœ¨ venv ä¸­çš„ site-packages å½“ä¸­ï¼Œæ‰€ä»¥éœ€è¦å°† torch çš„ cmake config è·¯å¾„ä¼ å…¥

   ```cmake
   list(APPEND CMAKE_PREFIX_PATH "/usr/local/lib/python3.10/dist-packages/torch/share/cmake")
   ```

3. python add library

   åœ¨ä¹‹å‰ç¼–è¯‘åº“éƒ½æ˜¯ç›´æ¥ç”¨ `add_library`ï¼Œä½†æ˜¯ç°åœ¨è¦ç¼–è¯‘çš„åº“éœ€è¦èƒ½å¤Ÿåœ¨ python å½“ä¸­é€šè¿‡ `import` è¿›è¡ŒåŠ è½½ (load)ï¼Œæ‰€ä»¥éœ€è¦ä½¿ç”¨ `Python_add_library` å‘½ä»¤ã€‚åœ¨ add library è¿‡ååˆ™éœ€è¦æŒ‡æ˜ include è·¯å¾„å’Œé¢å¤–æ‰€éœ€çš„ libraryï¼špytorch & cuda

   ```cmake
   Python_add_library(common_ops MODULE USE_SABI ${SKBUILD_SABI_VERSION} WITH_SOABI ${SOURCES})
   # the ABI part can be treated as fixed tempalte in python binding
   target_include_directories(common_ops PRIVATE ...)
   target_link_libraries(common_ops PRIVATE ${TORCH_LIBRARIES} c10 cuda cublas cublasLt)
   ```

4. Fetch content

   FetchContent å¯ç”¨äºä¸‹è½½å’Œé›†æˆå¤–éƒ¨é¡¹ç›®ï¼Œä¸€èˆ¬ç”¨æ³•å¦‚ä¸‹

   > - `FetchContent_Declare`: Specifies the repository details:
   >   - `GIT_REPOSITORY:` The URL (e.g., https://github.com/NVIDIA/cutlass).
   >   - `GIT_TAG`: The commit or tag to use (e.g., f115c3f8... for cutlass).
   > - `FetchContent_Populate`: Downloads the repository into the build directory (e.g., `_deps/repo-cutlass-src`).

   é€šè¿‡ declare å½“ä¸­çš„ name æ¥è·å¾—è¯¥é¡¹ç›®çš„æºæ–‡ä»¶è·¯å¾„ï¼Œlike `repo-flashinfer_SOURCE_DIR`

5. ccache

   `ccache`ï¼ˆCompiler Cacheï¼‰æ˜¯ä¸€ä¸ªç¼–è¯‘å™¨ç¼“å­˜å·¥å…·ï¼Œä¸»è¦ç”¨äº **åŠ é€Ÿé‡å¤ç¼–è¯‘**ã€‚æˆ‘ä¹Ÿå½“åšå›ºå®šæµç¨‹æ¥ç†è§£å¥½äº†

   ```cmake
   # ccache option
   option(ENABLE_CCACHE "Whether to use ccache" ON)
   find_program(CCACHE_FOUND ccache)
   if(CCACHE_FOUND AND ENABLE_CCACHE AND DEFINED ENV{CCACHE_DIR})	# env var must have CCACHE_DIR
       message(STATUS "Building with CCACHE enabled")
       set_property(GLOBAL PROPERTY RULE_LAUNCH_COMPILE "ccache")
       set_property(GLOBAL PROPERTY RULE_LAUNCH_LINK "ccache")
   endif()
   ```

   åœ¨å¯ç”¨ ccache æ—¶ï¼Œéœ€è¦æŒ‡å®šä¸€äº›ç¯å¢ƒå˜é‡

   ```shell
   apt-get install -y ccache
   # Building with ccache is enabled when ccache is installed and CCACHE_DIR is set.
   export CCACHE_DIR=/path/to/your/ccache/dir
   export CCACHE_BACKEND=""
   export CCACHE_KEEP_LOCAL_STORAGE="TRUE"
   unset CCACHE_READONLY
   python -m uv build --wheel -Cbuild-dir=build --color=always .
   ```

6. install

   åœ¨ CMake ä¸­ï¼Œ`install()` å‘½ä»¤ç”¨äºå®šä¹‰é¡¹ç›®å®‰è£…è§„åˆ™ï¼ŒæŒ‡å®šæ„å»ºäº§ç‰©ï¼ˆå¯æ‰§è¡Œæ–‡ä»¶ã€åº“ã€å¤´æ–‡ä»¶ç­‰ï¼‰åœ¨ç³»ç»Ÿä¸Šçš„æœ€ç»ˆå®‰è£…ä½ç½®ã€‚å½“ç”¨æˆ·æ‰§è¡Œ `make install`ï¼ˆæˆ–ç­‰ä»·å‘½ä»¤ï¼‰æ—¶ï¼Œè¿™äº›æ–‡ä»¶ä¼šè¢«å¤åˆ¶åˆ°æŒ‡å®šè·¯å¾„

   ```cmake
   install(TARGETS common_ops LIBRARY DESTINATION sgl_kernel)
   ```

   `common_ops.so` ä¼šè¢«ç§»åŠ¨åˆ°ç›®å½• `sgl_kernel` ä¸‹ï¼Œå…¶å‰ç¼€ç›®å½•å†³å®šäº `CMAKE_INSTALL_PREFIX`ã€‚å¦‚æœä½¿ç”¨ wheel æ¥æ‰“åŒ…çš„è¯ï¼Œç›®å½•ä¼šå˜æˆ wheel æ‰“åŒ…æ–‡ä»¶å¤¹ç›®å½•ï¼Œå…·ä½“æƒ…å†µå¯è§ä¸‹ä¸€ä¸ªå°èŠ‚

7. together with `pyproject.toml`

   ```toml
   [build-system]
   requires = [
     "scikit-build-core>=0.10",
     "torch>=2.6.0",
     "wheel",
   ]
   build-backend = "scikit_build_core.build"
   
   [project]
   dependencies = []
   
   [tool.wheel]
   exclude = [
     "dist*",
     "tests*",
   ]
   
   [tool.scikit-build]
   cmake.build-type = "Release"
   minimum-version = "build-system.requires"
   
   wheel.py-api = "cp39"
   wheel.license-files = []
   wheel.packages = ["python/sgl_kernel"]
   ```

   å°†æ‰€ç¼–è¯‘çš„ `.so` ä»¥åŠå…¶ä»–æ–‡ä»¶å…¨éƒ¨æ‰“åŒ…åˆ°ä¸€ä¸ª `.whl` æ–‡ä»¶å½“ä¸­ï¼Œç„¶åé€šè¿‡ `pip install *.whl` å®Œæˆä¸‹è½½ï¼Œå…¶ä¸­éœ€è¦é…ç½®çš„åªæœ‰ `wheel.packages`ï¼Œè¿™é‡ŒåŒ…å«äº†æƒ³è¦åŒ…å«çš„ package è·¯å¾„ï¼Œå…¶ä¸­å¿…é¡»è¦æœ‰ `__init__.py` æ–‡ä»¶ã€‚åŒæ—¶åœ¨æ‰“åŒ…çš„æ—¶å€™ï¼Œä¼šå°† cmake å½“ä¸­ `install` æ–‡ä»¶ä¸€å—æ‰“åŒ…ï¼Œå¹¶ä¸”ä¼šå°†åŒåçš„ä¾èµ–è¿›è¡Œåˆå¹¶ï¼ˆä¾‹å¦‚ `common_ops.so` åˆå¹¶åˆ° `sgl_kernel` ç›®å½•ä¹‹ä¸‹ï¼‰ï¼Œå…¶ç»“æ„ç›®å½•ç±»ä¼¼å¦‚ä¸‹

   ```txt
   sgl_kernel-0.1.4.data/
     â””â”€â”€ purelib/
         â”œâ”€â”€ sgl_kernel/          # æ¥è‡ª wheel.packages
         â”‚   â”œâ”€â”€ __init__.py
         â”‚   â”œâ”€â”€ common_ops.so    # ä»ä¸´æ—¶ç›®å½•åˆå¹¶è€Œæ¥
         â”‚   â””â”€â”€ other_module.py
         â””â”€â”€ deep_gemm/          # æ¥è‡ª install(DIRECTORY)
             â”œâ”€â”€ __init__.py
             â””â”€â”€ include/
                 â”œâ”€â”€ cute/
                 â””â”€â”€ cutlass/
   ```

## torch binding

ç›´æ¥å‚è€ƒç”± DeepSeek æ€»ç»“çš„æ­¥éª¤

```c++
#include <torch/library.h>       // å¿…é¡»åŒ…å«çš„æ ¸å¿ƒæ³¨å†Œå¤´æ–‡ä»¶
#include <ATen/core/dispatch/Dispatcher.h>  // è°ƒåº¦å™¨ï¼ˆé€šå¸¸éšå¼åŒ…å«ï¼‰
#include "your_custom_kernels.h" // è‡ªå®šä¹‰ç®—å­å®ç°çš„å¤´æ–‡ä»¶

// ä½¿ç”¨ TORCH_LIBRARY_FRAGMENT æ³¨å†Œç®—å­ï¼ˆæ¨èç‰‡æ®µå¼æ³¨å†Œï¼‰
TORCH_LIBRARY_FRAGMENT(sgl_kernel, m) {  // 'sgl_kernel' æ˜¯åº“å
    
    // æ­¥éª¤ 1: å£°æ˜ç®—å­ç­¾åï¼ˆSchemaï¼‰
    // æ— è¿”å›å€¼ç®—å­
    m.def("dispose() -> ()");  // è¯­æ³•ï¼šç®—å­å(å‚æ•°ç±»å‹) -> è¿”å›å€¼ç±»å‹
    m.def("meta_size() -> int");
    
    // å«å‚æ•°ç®—å­ï¼ˆTensor! è¡¨ç¤ºè¾“å‡º/åŸä½ä¿®æ”¹ï¼‰
    m.def("all_reduce(int fa, Tensor inp, Tensor! out, int reg, int reg_sz) -> ()");
    
    // å¤æ‚ç±»å‹ç¤ºä¾‹ï¼ˆint[] è¡¨ç¤ºæ•´å‹åˆ—è¡¨ï¼‰
    m.def("init_custom_ar(int[] ipc_tensors, Tensor rank, int rank, bool full_nvlink) -> int");
    
    // æ­¥éª¤ 2: ç»‘å®šå®ç°åˆ°è®¾å¤‡åç«¯
    // CUDA å®ç°
    m.impl("dispose", torch::kCUDA, &dispose);  // & æŒ‡å‘ C++ å‡½æ•°
    m.impl("all_reduce", torch::kCUDA, &all_reduce);
    m.impl("init_custom_ar", torch::kCUDA, &init_custom_ar);
    
    // å¯é€‰ï¼šæ³¨å†Œ CPU å®ç°
    // m.impl("dispose", torch::kCPU, &cpu_dispose);
}
```

æ ¸å¿ƒæ­¥éª¤

1. **ç®—å­ç­¾åè§„èŒƒ**ï¼š
   - **è¾“å…¥å¼ é‡**ï¼šç”¨ `Tensor` å£°æ˜ï¼ˆå¦‚ `Tensor inp`ï¼‰
   - **è¾“å‡º/åŸä½å¼ é‡**ï¼šç”¨ `Tensor!` å£°æ˜ï¼ˆå¦‚ `Tensor! out`ï¼‰
   - **åŸºç¡€ç±»å‹**ï¼šç›´æ¥å†™ç±»å‹åï¼ˆå¦‚ `int`, `bool`, `float`ï¼‰
   - **å¤åˆç±»å‹**ï¼šç”¨ `ç±»å‹[]` è¡¨ç¤ºåˆ—è¡¨ï¼ˆå¦‚ `int[]`ï¼‰
2. **è®¾å¤‡åˆ†å‘**ï¼š
   - `torch::kCUDA`/`torch::kCPU` æŒ‡å®šè®¾å¤‡åç«¯
   - åŒä¸€ç®—å­å¯ç»‘å®šå¤šè®¾å¤‡å®ç°ï¼ˆå¦‚ CUDA + CPUï¼‰
3. **å‘½åç©ºé—´**ï¼š
   - åº“å `sgl_kernel` éœ€ä¸ PyTorch ä¾§è°ƒç”¨ä¸€è‡´ï¼ˆPython ä¸­ `torch.ops.sgl_kernel.xxx`ï¼‰
4. **å‡½æ•°å®ç°è¦æ±‚**ï¼š
   - å‡½æ•°ç­¾åéœ€ä¸¥æ ¼åŒ¹é…å£°æ˜çš„ Schemaï¼ˆå‚æ•°é¡ºåº/ç±»å‹ï¼‰

## A general way to build python extension

1. **å®šä¹‰é¡¹ç›®å’Œä¾èµ–**
    åœ¨ `CMakeLists.txt` æ–‡ä»¶ä¸­ï¼š

   - ä½¿ç”¨ `project` å‘½ä»¤å®šä¹‰é¡¹ç›®åç§°å’Œæ”¯æŒçš„è¯­è¨€ï¼ˆé€šå¸¸åŒ…æ‹¬ C++ å’Œ CUDAï¼‰ã€‚

   - ä½¿ç”¨ `find_package` å‘½ä»¤æŸ¥æ‰¾ Python å’Œ PyTorch çš„åº“å’Œå¤´æ–‡ä»¶

2. **è®¾ç½®ç¼–è¯‘é€‰é¡¹**
    æ ¹æ®éœ€è¦ä¸º C++ å’Œ CUDA è®¾ç½®ç¼–è¯‘é€‰é¡¹ï¼Œä¾‹å¦‚ï¼š

   - ä½¿ç”¨ set å‘½ä»¤æŒ‡å®š C++ æ ‡å‡†

   - ä½¿ç”¨ `target_compile_options` è®¾ç½®ä¼˜åŒ–çº§åˆ«æˆ–è°ƒè¯•é€‰é¡¹ï¼Œç¡®ä¿ä¸ PyTorch çš„å…¼å®¹æ€§ã€‚

3. **æŒ‡å®šæºæ–‡ä»¶**
    å®šä¹‰ä¸€ä¸ªå˜é‡ï¼šå¦‚ `set(SOURCES file1.cpp file2.cu)`ï¼Œåˆ—å‡ºæ‰€æœ‰éœ€è¦ç¼–è¯‘çš„æºæ–‡ä»¶ï¼Œé€šå¸¸åŒ…æ‹¬ C++ æ–‡ä»¶ï¼ˆ.cppï¼‰å’Œ CUDA æ–‡ä»¶ï¼ˆ.cuï¼‰

4. **æ„å»ºåŠ¨æ€é“¾æ¥åº“**
    ä½¿ç”¨ `Python_add_library` å‘½ä»¤æ„å»ºä¸€ä¸ª MODULE ç±»å‹çš„åŠ¨æ€é“¾æ¥åº“

5. **é“¾æ¥åº“**
    ä½¿ç”¨ `target_link_libraries` å‘½ä»¤å°†ç”Ÿæˆçš„åº“é“¾æ¥åˆ° Python å’Œ PyTorch çš„åº“
6. **å®‰è£…æˆ–å¯¼å‡º**
    ä½¿ç”¨ install å‘½ä»¤æŒ‡å®šåº“çš„å®‰è£…è·¯å¾„

## Question

- gemm å½“ä¸­çš„ ABC layout åˆ†åˆ«æ˜¯ row col rowï¼Œä½†æ˜¯æˆ‘ä»¬ä¼ å…¥çš„ B çŸ©é˜µçš„ layout åº”è¯¥éƒ½æ˜¯ rowï¼Œè¿™åœ¨ cutlass å½“ä¸­æ˜¯æ€ä¹ˆè¿›è¡Œå¤„ç†çš„ï¼Ÿ

  åœ¨ torch ä¸­ transpose ç›®å‰æ˜¯åªæ”¹å˜ shape & strideï¼Œè€Œä¸æ”¹å˜å†…å­˜æ•°æ®æ’å¸ƒ

  ```python
  import torch
  
  a = torch.randn((3, 4), device='cuda')
  b = a.t()
  b.is_contiguous()	# False
  b.shape				# (4, 3)
  ```

  åœ¨è¿›è¡Œ cutlass gemm çš„æ—¶å€™é€šå¸¸è¦æ±‚ B matrix ä¸º column majorï¼Œä»¥ linear weight ä¸ºä¾‹ï¼Œåœ¨ pytorch å½“ä¸­å½¢çŠ¶ä¸º (N, K)ï¼Œæ­¤æ—¶æ’åˆ—ä¸º row majorã€‚æŒ‰ç…§ cutlass çš„æ€æƒ³ï¼Œæˆ‘ä»¬éœ€è¦çš„ B matrix ä¸º (K, N)ï¼Œæ’åˆ—ä¸º column majorã€‚ä¸ºäº†å®Œæˆ cutlass çš„è¦æ±‚ï¼Œå…¶å®è¯¥ linear weight åªéœ€è¦é‡æ–°æ’åˆ—å…¶ shape & strideï¼Œå†…å­˜æ’å¸ƒå…¶å®æ˜¯ä¸éœ€è¦æ”¹å˜çš„

  ```python
  Cutlass_Layout = (Shape=(K,  N), Stride=(1, K))
  Pytorch_Layout = (Shape=(N,  K), Stride=(K, 1))
  ```

  æ‰€ä»¥æˆ‘ä»¬åœ¨ linear ä¸­ä½¿ç”¨ cutlass gemm çš„æ—¶å€™ç›´æ¥å°† weight å…¶è¿›è¡Œ transposeï¼Œä¸‹é¢å°±æ˜¯ sglang/vllm åœ¨æ„å»º w8a8 linear weight æ—¶çš„ä»£ç ï¼Œå…¶å°† `input_dim & output_dim` è¿›è¡Œäº†é‡æ’

  ```python
  weight = ModelWeightParameter(
      data=torch.empty(
          sum(output_partition_sizes), input_size_per_partition, dtype=torch.int8
      ),
      input_dim=1,
      output_dim=0,
      weight_loader=weight_loader,
  )
  layer.register_parameter("weight", weight)
  ```

- How to do benchmark?

  å¯ä»¥ä½¿ç”¨ `triton.testing.do_bench` åšä¸€ä¸ªç®€å•çš„ benchmarkï¼Œç°åœ¨ torch éƒ½æ˜¯è‡ªå¸¦ `triton`ï¼Œç”¨èµ·æ¥æ¯”è¾ƒæ–¹ä¾¿

- ä¸ºä»€ä¹ˆ ccache ä¸èµ·ä½œç”¨ï¼Ÿæˆ‘ä¼¼ä¹è¿˜æ˜¯ä»å¤´ç¼–è¯‘çš„ï¼Ÿ

- deepgemm å½“ä¸­çš„ fp8 æ˜¯æ€ä¹ˆè®¡ç®—çš„ï¼Ÿ

  å‚è€ƒ `tests/test_core.py` è®¡ç®—æ–¹å¼ï¼Œå¯ä»¥çœ‹ä¸‹åˆ†å¸ƒæƒ…å†µ
