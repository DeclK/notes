# Train COCO on MMDetection

ç›®çš„ï¼Œèƒ½å¤Ÿè·‘é€š coco æ•°æ®é›†ï¼Œäº†è§£ coco æ ¼å¼

æ›´é‡è¦çš„æ˜¯çœ‹çœ‹ detr æ˜¯æ€ä¹ˆè·‘çš„

## ä¸‹è½½ COCO

è™½ç„¶ç™¾åº¦ç½‘ç›˜æå…¶ğŸ¶ï¼Œä½†æ˜¯è¿™é‡Œæˆ‘ä¾ç„¶ä½¿ç”¨äº†ç™¾åº¦ç½‘ç›˜ä¸‹è½½ï¼Œéœ€è¦å¼€å¯ä¸€ä¸‹é—²ç½®å¸¦å®½ä¼˜åŒ–ä¸‹è½½ã€‚åªè¦æ˜¯çƒ­é—¨èµ„æºä¸‹è½½é€Ÿåº¦éƒ½ä¼šæ¯”è¾ƒå¿«çš„

ä¸‹è½½å®Œåï¼Œè§£å‹æ”¾åœ¨å¦‚ä¸‹ä½ç½®

```txt
mmdetection
â”œâ”€â”€ mmdet
â”œâ”€â”€ tools
â”œâ”€â”€ configs
â”œâ”€â”€ data
â”‚   â”œâ”€â”€ coco
â”‚   â”‚   â”œâ”€â”€ annotations
â”‚   â”‚   â”œâ”€â”€ train2017
â”‚   â”‚   â”œâ”€â”€ val2017
â”‚   â”‚   â”œâ”€â”€ test2017
```

ä¸‹è½½å®Œ coco æ•°æ®é›†ç„¶åè§£å‹

## MMEngine

**è¿™é‡Œæ•´ç† MMEngine çš„æ ¸å¿ƒéƒ¨åˆ†**ï¼Œæˆ‘ä¹‹å‰çš„æ•´ç†éƒ½è¿‡äºéµä»äºå®˜æ–¹æ–‡æ¡£äº†ï¼Œå³å¤ªè¿‡äºå…³æ³¨ç»†èŠ‚ï¼Œä¾ç„¶æ²¡æœ‰å»ºç«‹èµ·æ•´ä½“çš„æ¶æ„

### Registry

**æ³¨å†Œå™¨çš„åŠŸèƒ½ï¼Œå°±æ˜¯åˆ©ç”¨é…ç½®æ–‡ä»¶æ„å»ºç±»çš„å®ä¾‹**

è¦åšåˆ°è¿™ä¸€ç‚¹ï¼Œå°±è¦å…ˆæŠŠéœ€è¦çš„ç±»ç»™æ³¨å†Œåˆ°æ³¨å†Œå™¨ä¸­ã€‚æ‰€è°“æ³¨å†Œï¼Œæœ¬è´¨ä¸Šå°±æ˜¯æŠŠç±»æ”¾åˆ°æ³¨å†Œå™¨å†…çš„ä¸€ä¸ªå­—å…¸ `_module_dict` é‡Œï¼Œä¹‹åéœ€è¦çš„æ—¶å€™å–å‡ºï¼Œä½¿ç”¨é…ç½®æ–‡ä»¶è¿›è¡Œå®ä¾‹åŒ– `Registry.build(cfg)`ï¼Œå¦‚æœåªæƒ³è·å¾—ç±»æœ¬èº«ï¼Œå°±ç”¨ `Registry.get('key')` å³å¯

æ‰€æœ‰çš„æ³¨å†Œå™¨éƒ½æ”¾åœ¨äº† `mmdet.registry` å½“ä¸­ï¼Œéœ€è¦ç”¨å“ªä¸ªå°± `import` å“ªä¸ª

### Config

**é…ç½®æ–‡ä»¶å®šä¹‰äº†æ‰€ä½¿ç”¨çš„æ¨¡å‹ã€è®­ç»ƒã€æ•°æ®é›†**

ä½¿ç”¨ `Config` ç±»æ¥å®Œæˆå¯¹é…ç½®æ–‡ä»¶çš„å¤„ç†

```python
cfg = Config.fromfile('config.py')
```

 å³å¯ç”¨ `config.py` æ–‡ä»¶åˆ›å»ºä¸€ä¸ªé…ç½®ç±»ã€‚æ–‡ä»¶å³å¯ä»¥æ˜¯ `.py` ä¹Ÿå¯ä»¥æ˜¯ `.yaml`

`Config` ç±»å¯ä»¥é€šè¿‡å…³é”®å­—æˆ–è€…å±æ€§æ¥è°ƒç”¨é…ç½®æ–‡ä»¶å†…å®¹ï¼Œ`cfg.key` æˆ– `cfg['key']` éƒ½å¯è·å¾—å…¶ä¸­çš„å†…å®¹

**ä¸ºäº†æ„å»ºä¸€ä¸ªå±‚çº§çš„é…ç½®æ–‡ä»¶ï¼Œç»§æ‰¿æœºåˆ¶æ˜¯éå¸¸æœ‰å¿…è¦çš„**

é…ç½®æ–‡ä»¶å†…å¯ä»¥é€šè¿‡ `_base_` å…³é”®å­—æŒ‡å®šåŸºç¡€é…ç½®æ–‡ä»¶

```python
_base_ = ['list_of_base_configs.py',]
```

ä¿®æ”¹åŸºç¡€é…ç½®ä¸­çš„å€¼ä¹Ÿéå¸¸ç®€å•ï¼Œç›´æ¥åœ¨å½“å‰é…ç½®æ–‡ä»¶å¤¹ä¸­é‡æ–°å®šä¹‰å³å¯ï¼Œå¹¶ä¸”ä½ ä¸éœ€è¦æŠŠå­—å…¸æ‰€æœ‰çš„å…³é”®å­—éƒ½é‡æ–°å®šä¹‰ä¸€éï¼Œåªéœ€è¦å®šä¹‰ä¿®æ”¹çš„å…³é”®å­—å³å¯ã€‚å¦‚æœæƒ³è¦åˆ é™¤æ²¡æœ‰é‡æ–°å®šä¹‰çš„å…³é”®å­—éœ€è¦ä½¿ç”¨ `_delete_` å…³é”®å­—ï¼Œè¿™æ ·å°±ä»…å‰©ä¸‹æ–°å®šä¹‰çš„å†…å®¹

```python
_base_ = ['optimizer_cfg.py', 'runtime_cfg.py']
optimizer = dict(_delete_=True, type='SGD', lr=0.01)
```

**å…¶ä»–æŠ€å·§**

1. å¯ä»¥é€šè¿‡ `{{_base_.attr}}` æ¥å¼•ç”¨ä¸Šçº§é…ç½®ä¸­çš„å†…å®¹
2. å¯ä»¥é€šè¿‡ `cfg.dump('config.py')` æ¥è¾“å‡ºé…ç½®æ–‡ä»¶ï¼Œè¾“å‡ºå½¢å¼è¿˜å¯ä»¥æ˜¯ `.yaml`

### Runner

å…‰çœ‹æ–‡æ¡£å®Œå…¨æ²¡åŠæ³•ç†è§£æ€ä¹ˆç”¨ï¼Œè¿™é‡Œæˆ‘è¦æ ¹æ®ä»£ç æ¥è‡ªå·±æ•´ç†

1. runner åˆå§‹åŒ–

   1. deepcopy cfgï¼Œæ–°å»ºå±æ€§ self.cfg

   2. æ‰€è°“ lazy init å°±æ˜¯æŒ‡å…ˆç”¨ä¸€ä¸ªåˆ—è¡¨æ”¾ cfg æˆ–è€…ç›´æ¥ä¸º cfg æœ¬èº«ï¼Œåœ¨ä¹‹åéœ€è¦çš„æ—¶å€™ç”¨è¿™äº› cfg çœŸæ­£çš„ç”Ÿæˆå®ä¾‹

      ä½¿ç”¨ lazy init

   3. åˆ›å»ºå±æ€§ traininig_relatedï¼Œval_relatedï¼Œtest_relatedã€‚æ¯ä¸ª related list ä¸º `[xxx_dataloader, xxx_cfg, xxx_evaluator]`

   4. optim_wrapperï¼Œæ— æ“ä½œ

   5. launcherï¼Œå†³å®šåˆ†å¸ƒå¼ä¸å¦

   6. setup_envï¼Œåˆå§‹åŒ– dist ç¯å¢ƒï¼Œæ–°å»ºå±æ€§ rank å’Œ world_size

   7. set_random_seedï¼Œæ–°å»ºå±æ€§ seed å’Œ deterministicï¼Œé€šè¿‡ randomness=dict(seed=None) è®¾ç½®

   8. åˆ›å»º work_dir

   9. åˆ›å»º loggerï¼Œlogger æ­¤æ—¶è®°å½•ä¸‹ç¯å¢ƒä¿¡æ¯å’Œé…ç½®æ–‡ä»¶

   10. åˆ›å»ºå±æ€§ load_from å’Œ resume

   11. åˆ›å»ºå±æ€§ modelï¼Œbuild_model å®ä¾‹åŒ–

   12. æ‰“åŒ… model ä¸º MMDistributedDataParallelï¼Œå½“ç„¶ä¹Ÿå¯ä»¥æ‰“åŒ…ä¸º DDPã€‚MMDDP æ¯” DDP æ–°å®šä¹‰äº†ä¸‰åˆ†æ–¹æ³• tran_step, val_step, test_step

   13. æ³¨å†Œé’©å­

   14. ä¿å­˜ config

2. runner.train()

   1. æ£€æŸ¥ ori_model æ˜¯å¦æœ‰ _train_stepã€‚è¿™é‡Œæ˜¯å¯¹æ¨¡å‹çš„åŸºæœ¬è¦æ±‚ã€‚å¦‚æœæœ‰ _val_loopï¼Œä¹Ÿå¾—æ£€æŸ¥æ˜¯å¦æœ‰ _val_step

   2. build_train_loopï¼Œå¹¶åˆ›å»ºå±æ€§ train_loopã€‚å› ä¸ºä¹‹å‰æ˜¯ lazy init train loopï¼Œæ‰€ä»¥è¿™é‡Œè¦ build

      ä¸€ä¸ªç±»è¡¨æ˜ metaclass=ABCMeta è¡¨ç¤ºè¯¥ç±»ä¸ºæŠ½è±¡ç±»ï¼Œä¸èƒ½å¤Ÿå®ä¾‹åŒ–ï¼Œåªèƒ½ç”¨æ¥ç»§æ‰¿

      BaseLoopï¼Œæ‰€æœ‰ loop çš„åŸºç±»ï¼Œéœ€è¦ä¼ å…¥ runner å’Œ dataloaderï¼Œå¹¶ä¸”ç”±äºä¹‹å‰çš„ dataloader æ˜¯ lasy initï¼Œæ‰€ä»¥è¦ build dataloader, dataset, dataset sampler, batch sampler, å³çœŸæ­£çš„å®ä¾‹åŒ–

      pesudo collate å°±æ˜¯ default collate ä½†æ˜¯ä¸è½¬æ¢ä¸º tensor

      defaultsampler èƒ½å¤ŸåŒæ—¶å¤„ç†åˆ†å¸ƒå¼å’Œéåˆ†å¸ƒå¼é‡‡æ ·ï¼Œå†åŒ…ä¸€ä¸ª batchsampler å°±èƒ½å¤Ÿå¤„ç†æ‰¹é‡‡æ ·äº†

   3. build_optim_wrapperï¼Œåˆ›å»ºå±æ€§ optim_wrapperï¼Œå¹¶ä½¿ç”¨ auto_scale_lr

   4. build_param_schedulerï¼Œåˆ›å»ºå±æ€§ param_schedulersï¼Œè¿™æ˜¯å¯¹å­¦ä¹ ç‡çš„ç­–ç•¥é…ç½®

   5. build_val_loop

   6. call_hook('before_run')

   7. åˆå§‹åŒ–æ¨¡å‹æƒé‡ï¼Œå¦‚æœæœ‰é¢„è®­ç»ƒæƒé‡åˆ™ load

   8. self.train_loop.run()

   9. call_hook('after_run')

### train loop è¿è¡Œé€»è¾‘

BaseLoop æ˜¯ä¸€ä¸ªéå¸¸ç®€å•çš„ç±»ï¼Œåªéœ€è¦ runner å’Œ dataloader ä½œä¸ºåˆå§‹åŒ–å³å¯

EpochBasedTrainLoop ç»§æ‰¿ BaseLoop æ ¸å¿ƒé€»è¾‘åœ¨ run å‡½æ•°

run å°†å¾ªç¯è¿è¡Œ run_epochï¼Œå¹¶åœ¨ epoch ååˆ¤æ–­æ˜¯å¦éœ€è¦ eval

run_epoch æ˜¯ç”±å¾ªç¯ run_iter å®Œæˆï¼Œå¾ªç¯ä»¥ dataloader ä¸»å¯¼

run_iter ä¸­è¿è¡Œäº†æ¨¡å‹çš„ `train_step` æ­¥éª¤ï¼Œåœ¨ `train_step` ä¸­ä¼˜åŒ–æ­¥å·²ç»å®Œæˆäº†

ä¸‹é¢å†™ä¸€ä¸‹ç®€åŒ–ä»£ç ï¼Œå»é™¤é’©å­

```python
    def run(self) -> torch.nn.Module:
        """Launch training."""
        while self._epoch < self._max_epochs:
            self.run_epoch()
            if (self.runner.val_loop is not None and self._epoch >= self.val_begin and self._epoch % self.val_interval == 0):
                self.runner.val_loop.run()
        return self.runner.model

    def run_epoch(self) -> None:
        """Iterate one epoch."""
        self.runner.model.train()
        for idx, data_batch in enumerate(self.dataloader):
            self.run_iter(idx, data_batch)
        self._epoch += 1

    def run_iter(self, idx, data_batch: Sequence[dict]) -> None:
        outputs = self.runner.model.train_step(
            data_batch, optim_wrapper=self.runner.optim_wrapper)
        self._iter += 1
```

è‡ªå·±åœ¨å†™ä¸ªæ€§åŒ– Loops çš„æ—¶å€™æœ€å¥½è¦å°†è¿™äº›é’©å­éƒ½åŠ ä¸Šï¼Œä»¥ä¿è¯ç»“æœçš„æ­£ç¡®ï¼ä¾‹å¦‚ DistributedSampler çš„éšæœºç§å­è¦åœ¨å„ä¸ª epoch å¼€å§‹å‰é‡æ–°è®¾ç½®ï¼Œè¿™é‡Œéœ€è¦è°ƒç”¨ä¸€ä¸ª DistSamplerSeedHook å®Œæˆ

### train step è¿è¡Œé€»è¾‘

æ ¸å¿ƒä»£ç éå¸¸ç®€å•

```python
    def train_step(self, data: Union[dict, tuple, list],
                   optim_wrapper: OptimWrapper) -> Dict[str, torch.Tensor]:
        with optim_wrapper.optim_context(self):
            data = self.data_preprocessor(data, True)
            losses = self._run_forward(data, mode='loss')  # type: ignore
        parsed_losses, log_vars = self.parse_losses(losses)  # type: ignore
        optim_wrapper.update_params(parsed_losses)
        return log_vars

```

ç”±äº collate_fn ä½¿ç”¨çš„æ˜¯ä¸€ä¸ªéå¸¸ç®€å•çš„æ–¹æ³•ï¼Œæ‰€ä»¥**æ•°æ®é¢„å¤„ç†æ”¾åœ¨äº† DataPreprocessor ä¸­**ï¼Œå…¶åŠŸèƒ½åŒ…æ‹¬æŠŠæ•°æ®å‘é€åˆ° GPU ä¸Šï¼Œæ•°æ®æ‰“åŒ…ï¼Œå½’ä¸€åŒ–ï¼Œæœ€åè¿”å› data å­—å…¸ï¼ˆåŒ…å« data['inputs'] & data['data_sample']ï¼‰

### å¦‚ä½•è‡ªå·±å†™é…ç½®æ–‡ä»¶

å»ºè®®æ˜¯ä» `_base_` ä¸­å»ç»§æ‰¿ï¼Œç„¶åå†æŒ‘é€‰ä¿®æ”¹ã€‚æ€»ä½“æ¥è®²æ ¸å¿ƒå¦‚ä¸‹

```python
# dataset
train_pipeline = [dict(type='LoadImageFromFile')]
train_dataloader = dict(batch_size=, dataset=, pipline=train_pipline)

test_pipline = ...
val_dataloader = ...

val_evaluator = dict(type='CocoMetric', ann_file=...)

# model
model = dict(type='DETR',...)

# optimizer & scheduler
train_cfg = dict(type='EpochBasedTrainLoop', max_epochs=12, val_interval=1)
val_cfg = dict(type='ValLoop')

optim_wrapper = dict(type='OptimWrapper', optimizer=dict(tpye='SGD', lr=0.01))
param_scheduler = dict(type='LinearLR', start_factor=0.001, by_epoch=False, begin=0, end=500)

auto_scale_lr = dict(enable=False, base_batch_size=16)

# logs & hooks
default_hooks

log_processor = dict(type='LogProcessor', window_size=50, by_epoch=True)
log_level = 'INFO'

visualizer = dict(type='DetLocalVisualizer', vis_backends='LocalVisBackend', name='visualizer')
```

### DataLoader æ¥å£æ•´ç†

```python
DataLoader(dataset, 
           batch_size=1, shuffle=False, sampler=None, drop_last=False,
           batch_sampler=None, 
           collate_fn=None,
           num_workers=0, pin_memory=False)
```

æˆ‘æŠŠä¸Šé¢çš„å‚æ•°åˆ†æˆäº†4è¡Œï¼Œå…¶ä¸­**å‰ä¸¤è¡Œæ˜¯æ ¸å¿ƒé…ç½®ï¼Œæ§åˆ¶éšæœºæ€§å’Œ batch è¡Œä¸º**ï¼Œç¬¬ä¸‰è¡Œæ˜¯è‡ªå®šä¹‰æ‰“åŒ…æ–¹æ³•é…ç½®ï¼Œç¬¬å››è¡Œæ˜¯åŠ é€Ÿé…ç½®

1. Sampler å’Œ shuffle æ˜¯äº’æ–¥çš„ï¼Œæœ‰äº† sampler å shuffle å°†ä¸å†èµ·ä½œç”¨ã€‚**å®é™…ä¸Šå‡ ä¹å¯ä»¥ä¸ç”¨ sampler è¿™ä¸ªå‚æ•°**
2. batch_sampler æ˜¯ä»¥ä¸€ä¸ª Sampler ä½œä¸ºåŸºç¡€ï¼Œå†è¿›è¡Œ group æ“ä½œã€‚å½“ä¼ å…¥ batch_sampler åï¼Œå°±ä¸ç”¨ä¼ å…¥ sampler, batch_size, drop_last ä»¥åŠ shuffle å…³é”®å­—
3. num_workers ä¸ºè°ƒç”¨çº¿ç¨‹çš„æ•°é‡ï¼Œæ²¡æœ‰å›ºå®šè¯´æ³•è®¾ç½®å¤šå°‘æœ€å¥½ã€‚pin_memory å°±æ˜¯é”é¡µå†…å­˜ï¼Œåˆ›å»ºDataLoaderæ—¶ï¼Œè®¾ç½®pin_memory=Trueï¼Œåˆ™æ„å‘³ç€ç”Ÿæˆçš„Tensoræ•°æ®æœ€å¼€å§‹æ˜¯å±äºå†…å­˜ä¸­çš„é”é¡µå†…å­˜ï¼Œè¿™æ ·å°†å†…å­˜çš„Tensorè½¬ä¹‰åˆ°GPUçš„æ˜¾å­˜å°±ä¼šæ›´å¿«ä¸€äº›
4. ä¸ºäº†è¾ƒå¥½çš„å¯å¤ç°ï¼Œmmengine ä¸­è¿˜æ˜¯ç”¨äº† worker_init_fn æ¥ç»™æ¯ä¸ªçº¿ç¨‹è®¾ç½®éšæœºç§å­ï¼Œè¿™é‡Œä¸æ€»ç»“

**åœ¨åä¸¤è¡Œé…ç½®ä¸å˜æ—¶ï¼Œä»…é…ç½®å‰ä¸¤è¡Œå³å¯å®Œæˆå¯¹å•å¡å’Œå¤šå¡ï¼ˆåˆ†å¸ƒå¼ï¼‰çš„ DataLoader åˆ›å»º**

1. å•å¡ï¼Œç›´æ¥é…ç½®ç¬¬ä¸€è¡Œ

   ```python
   DataLoader(dataset, batch_size=2, shuffle=False, drop_last=False)
   ```

2. å¤šå¡ï¼Œç›´æ¥ä¸Š batch_sampler

   ```python
   sampler = DistributedSampler(dataset, seed=None, shuffle=False)
   batch_sampler = BatchSampler(sampler, batch_size=2, drop_last=False)
   DataLoader(dataset, batch_sampler=batch_sampler)
   ```

Sampler çš„æ ¸å¿ƒæ–¹æ³•æ˜¯ `__iter__`ï¼Œå³é€šè¿‡è¿­ä»£ä¸æ–­ç”Ÿæˆ indexï¼ŒDistributedSampler æŠŠæ•°æ®é›†çš„æ€» index åˆ†æˆäº†å¤šä¸ªä¸é‡å çš„å­é›†ï¼Œæ¯ä¸ªè¿›ç¨‹å¯¹åº”ä¸€ä¸ªå­é›†ï¼Œç„¶ååœ¨å„è‡ªçš„å­é›†ä¸­è¿­ä»£ç”Ÿæˆ indexã€‚è€Œ BatchSampler åˆ™æ˜¯ç”Ÿæˆä¸€ä¸ª batch_size é•¿åº¦çš„ index åºåˆ—

### Optimizer æ¥å£æ•´ç†

Pytorch å®ç°çš„ Optimizer çš„è¾“å…¥ä¸»è¦ç”± model.parameters() å’Œå…¶ä»–è¶…å‚æ•°ï¼ˆå¦‚ learning_rate, weight_decayï¼‰ã€‚å¦‚æœæƒ³è¦å¯¹ç‰¹å®šå±‚è®¾ç½®ï¼Œå¯å‚è€ƒ [StackOverflow](https://stackoverflow.com/questions/51801648/how-to-apply-layer-wise-learning-rate-in-pytorch)ï¼Œä¼ å…¥ä¸€ä¸ª list of dict å³å¯

mmengine å¯¹ pytorch ä¼˜åŒ–å™¨çš„åŒ…è£…è¿˜æ˜¯æ¯”è¾ƒè½»çš„ï¼Œé™¤äº† optimizer åŸæœ‰çš„æ¥å£å¤–ï¼ŒOptimWrapper ä¸»è¦å¤šäº†å‡ ä¸ªæ¥å£ï¼š

1. optim_wrapper.update_params(loss) æ›´æ–°å‚æ•°ï¼Œæ›¿ä»£ backward + step
2. optim_wrapper.get_lr() è·å¾—å­¦ä¹ ç‡ï¼Œæ›¿ä»£åŸæ¥çš„ `optimizer.param_groups[0]['lr']`
3. åŠ è½½ä¼˜åŒ–å™¨çŠ¶æ€å­—å…¸ä½¿ç”¨çš„åŸå§‹æ¥å£ `state_dict & load_state_dict`

mmengine ä¸­çš„ scheduler å’Œ pytorch ä¸­çš„ scheduler ä½¿ç”¨æ–¹æ³•å®Œå…¨ä¸€è‡´ï¼Œä½†æ‰©å±•äº† scheduler çš„ä½¿ç”¨èŒƒå›´ï¼Œä¸ä»…ä»…èƒ½å¤Ÿå¯¹ lr è¿›è¡Œç®¡ç†ï¼Œè¿˜èƒ½å¯¹ momentum è¿›è¡Œç®¡ç†ã€‚scheduler çš„æ¥å£åç§°å’Œ optimizer çš„æ¥å£åç§°åŸºæœ¬ä¸€è‡´ï¼Œä½¿ç”¨ `scheduler.step()` å³å¯

scheduler åŸç†æ˜¯æ ¹æ®å½“å‰æ­¥ï¼ˆlast_stepï¼‰å’Œç»™å®šå‚æ•°è®¾ç½®å­¦ä¹ ç‡ï¼ŒåŸºæœ¬ä¸Šä¸éœ€è¦è‡ªå·±è°ƒæ•´ï¼Œç›´æ¥å‚è€ƒæ–‡æ¡£ [mmengine.optim](https://mmengine.readthedocs.io/zh_CN/latest/api/optim.html) å†™é…ç½®æ–‡ä»¶å³å¯ã€‚è¦è‡ªå·±å®ç°ä¸ªæ€§åŒ–çš„ scheduler å¯ä»¥å‚è€ƒä¸€ä¸‹æºç 

### Dataset & DataSample

**BaseDataset å®ç°é€»è¾‘**

1. full_init() æ–¹æ³•
2. **load_data_list()ï¼Œéœ€è¦è‡ªå·±å†™ï¼Œreturn a list of dict**ï¼Œé€šå¸¸ä»…åŒ…å«æ ·æœ¬çš„è·¯å¾„å’Œæ ·æœ¬çš„æ ‡ç­¾

å…¶ä»–åŸºæœ¬ä¸Šå°±ä¸éœ€è¦äº†ï¼Œæ¥ä¸‹æ¥å°±æ˜¯ pipline çš„åŠŸèƒ½ï¼Œç”Ÿæˆå®Œæ•´çš„ä¸€ä¸ªæ ·æœ¬

é€šç”¨çš„å¢å¼ºè¾“å‡º PackxxInputsï¼Œéœ€è¦è¿›ä¸€æ­¥äº†è§£é€šç”¨æ•°æ®å…ƒç´ çš„è®¾è®¡

https://mmengine.readthedocs.io/zh_CN/latest/advanced_tutorials/data_element.html

åœ¨æ¨¡å‹çš„è®­ç»ƒ/æµ‹è¯•è¿‡ç¨‹ä¸­ï¼Œç»„ä»¶ä¹‹é—´å¾€å¾€æœ‰å¤§é‡çš„æ•°æ®ï¼ˆimagesï¼‰å’Œæ ‡ç­¾ï¼ˆlabelsï¼‰éœ€è¦ä¼ é€’ï¼Œä¸åŒçš„ç®—æ³•éœ€è¦ä¼ é€’çš„æ•°æ®å’Œæ ‡ç­¾å½¢å¼ç»å¸¸æ˜¯ä¸ä¸€æ ·çš„

```python
# detection
for img, img_metas, gt_bboxes, gt_labels in data_loader:
    loss = retinanet(img, img_metas, gt_bboxes, gt_labels)
# segmentation
for img, img_metas, gt_bboxes, gt_masks, gt_labels in data_loader:
     loss = mask_rcnn(img, img_metas, gt_bboxes, gt_masks, gt_labels)
```

ä¸ºäº†ç»Ÿä¸€æ•°æ®æ¥å£ mmengine å°±å¯¹è¿™**æ•°æ®**å’Œ**æ ‡ç­¾**åˆ†åˆ«è¿›è¡Œæ‰“åŒ…ï¼Œè¯¥åŠŸèƒ½ä½¿ç”¨ PackxxxInputs å®Œæˆï¼Œæœ€åè¾“å‡ºä¸¤ä¸ªå¯¹è±¡ img & data_sample

```python
for img, data_sample in dataloader:
    loss = model(img, data_sample)
```

åœ¨å®é™…å®ç°è¿‡ç¨‹ä¸­ï¼Œmmengine ä½¿ç”¨ DataSample ç±»æ¥å°è£…æ ‡ç­¾ã€é¢„æµ‹ç»“æœä¿¡æ¯ï¼ŒDataSample ç”±æ•°æ®å…ƒç´  xxxData æ„æˆï¼Œæ•°æ®å…ƒç´ ä¸ºæŸç§ç±»å‹çš„é¢„æµ‹æˆ–è€…æ ‡æ³¨ 

#### BaseDataElement

ä¸ºäº†æ›´å¥½çš„æ“ä½œæ•°æ®ï¼Œå®ç°äº† BaseDataElementï¼Œå…¶ä¸»è¦æœ‰å¦‚ä¸‹åŠŸèƒ½

1. BaseDataElement å°†æ•°æ®åˆ†ä¸º **data** å’Œ **metainfo** ä¸¤ä¸ªéƒ¨åˆ†ï¼Œé€šè¿‡ç±»çš„åˆå§‹åŒ–å°†è¿™ä¸¤ä¸ªéƒ¨åˆ†æ„å»ºåˆ° BaseDataElement ä¸­

   ```python
    def __init__(self, *, metainfo: Optional[dict] = None, **kwargs) -> None:
           # metainfo å¿…é¡»ä¸ºå­—å…¸
           # data åˆ™ä»¥å…³é”®å­— kwargs ç›´æ¥åŠ å…¥
   base_data = BaseDataElement(metainfo=dict(h=1,w=2), size=100)
   ```

   äºŒè€…éƒ½ä»¥ BaseDataElement ä¸­çš„å±æ€§ï¼ˆattrï¼‰å­˜åœ¨ï¼ŒåŒºåˆ«åœ¨äº metainfo ä¸èƒ½å¤Ÿç›´æ¥é€šè¿‡å±æ€§è®¾ç½®ï¼Œåªæœ‰ data å¯ä»¥ç›´æ¥é€šè¿‡å±æ€§è®¾ç½®ã€‚ä¿®æ”¹ metainfo éœ€è¦ä½¿ç”¨ set_metainfo æ–¹æ³•

   ```python
   base_data = BaseDataElement(metainfo=dict(h=1,w=2), size=100)
   base_data.h = 2		# no!!
   base_data.set_metainfo(dict(h=2))	# yes
   base_data.size = 2					# yes
   ```

   åˆ é™¤å±æ€§å¯ä»¥ç›´æ¥ä½¿ç”¨ pop æ–¹æ³•ï¼Œä¸ç®¡æ˜¯ metainfo è¿˜æ˜¯ data éƒ½ç®¡ç”¨

2. å®ç°äº† newï¼Œcloneï¼Œtoï¼Œnumpyï¼Œcudaï¼Œcpu è¿™äº›ç±»ä¼¼äºå¼ é‡ä¸­çš„æ–¹æ³•ï¼Œå¯ä»¥æ‰¹é‡å¯¹ data ä¸­çš„æ•°æ®ç›´æ¥æ“ä½œ

3. é€šè¿‡ print(BaseDataElement) èƒ½å¤Ÿç›´è§‚è·å¾—å…¶ä¸­çš„ data å’Œ metainfo

#### InstanceData

- å¯¹ `InstanceData` ä¸­ data æ‰€å­˜å‚¨çš„æ•°æ®è¿›è¡Œäº†é•¿åº¦æ ¡éªŒ
- data éƒ¨åˆ†æ”¯æŒç±»å­—å…¸è®¿é—®å’Œè®¾ç½®å®ƒçš„å±æ€§
- æ”¯æŒåŸºç¡€ç´¢å¼•ï¼Œåˆ‡ç‰‡ä»¥åŠé«˜çº§ç´¢å¼•åŠŸèƒ½
- æ”¯æŒå…·æœ‰**ç›¸åŒçš„ `key`** ä½†æ˜¯ä¸åŒ `InstanceData` çš„æ‹¼æ¥åŠŸèƒ½ã€‚ è¿™äº›æ‰©å±•åŠŸèƒ½é™¤äº†æ”¯æŒåŸºç¡€çš„æ•°æ®ç»“æ„ï¼Œ æ¯”å¦‚`torch.tensor`, `numpy.dnarray`, `list`, `str`, `tuple`, ä¹Ÿå¯ä»¥æ˜¯è‡ªå®šä¹‰çš„æ•°æ®ç»“æ„ï¼Œåªè¦è‡ªå®šä¹‰æ•°æ®ç»“æ„å®ç°äº† `__len__`, `__getitem__` and `cat`.

#### DataSample

æ•°æ®æ ·æœ¬ä½œä¸ºä¸åŒæ¨¡å—æœ€å¤–å±‚çš„æ¥å£ï¼Œæä¾›äº† xxxDataSample ç”¨äºå•ä»»åŠ¡ä¸­å„æ¨¡å—ä¹‹é—´ç»Ÿä¸€æ ¼å¼çš„ä¼ é€’ã€‚mmengine å¯¹ xxxDataSample çš„å±æ€§å‘½åä»¥åŠç±»å‹è¦è¿›è¡Œçº¦æŸå’Œç»Ÿä¸€ï¼Œä¿è¯å„æ¨¡å—æ¥å£çš„ç»Ÿä¸€æ€§

å¯¹å‘½åçš„çº¦æŸæ˜¯ä½¿ç”¨ @property è£…é¥°å™¨å®Œæˆï¼Œåˆ©ç”¨ property setter å¢åŠ å¯¹å±æ€§çš„æ›´æ”¹

### Default Hooks åŠŸèƒ½

1. IterTimerHook
2. LoggerHook
3. ParamSchedulerHook
4. CheckpointHook
5. DistSamplerSeedHook
6. DetVisualizationHookï¼Œonly works in test and val
7. RuntimeInfoHook

### æ—¥å¿—ç³»ç»Ÿ MessageHub & MMLogger

`MessageHub` çš„ä½œç”¨æ˜¯åœ¨å…¨å±€æ”¶é›†ä¿¡æ¯ã€‚æ”¶é›†çš„ä¿¡æ¯å­˜å‚¨åœ¨ HistoryBuffer é‡Œï¼Œè¿™ä¸ª buffer ç›¸å½“äºä¸€ä¸ªé˜Ÿåˆ—ï¼Œå…¶æœ€å¤§å®¹é‡ä¸º window sizeï¼Œå³æœ€å¤šç¼“å­˜å¤šå°‘æ¡æ•°æ®ï¼Œå¤šä½™è¿™ä¸ª window sizeï¼Œä¹‹å‰çš„æ•°æ®å°±ä¼šè¢«æŒ¤å‡ºå»

æ—¥å¿—ç³»ç»Ÿé€šå¸¸ä½¿ç”¨ä¸¤ä¸ªåŠŸèƒ½ï¼š

1. æ›´æ–° meesage hub

   ```python
   from mmengine.logging import MessageHub
   
   message_hub = MessageHub(name='name_for_message_hub')
   message_hub.update_scalar('train/loss', loss)
   # update with dict
   message_hub.update_scalrs(log_dict)
   ```

   update_scalar å¯ä»¥è‡ªåŠ¨å°†æ•°æ®è½¬æ¢æˆ python built-in ç±»å‹ã€‚è¦è·å–æ•°æ®å¯é€šè¿‡ä¸‹é¢æ–¹æ³•

   ```python
   buffer = message_hub.get_scalar('train/loss')	# è·å– buffer
   # buffer.data è¿”å›ä¸€ä¸ª tuple: (log_data, counts)
   # countsä»£è¡¨å¯¹åº”çš„æ•°æ®çš„é‡å¤æ¬¡æ•°
   # len(log_data) == len(counts)
   buffer.data[0]	# normally, an ndarray
   buffer.mean()
   buffer.max()
   buffer.min()
   buffer.current()
   ```

2. å‘æ–‡ä»¶å†™å…¥æ—¥å¿—

   ```python
   from mmengine.logging import MMLogger 
   
   logger = MMLogger.get_instance(name='mmengine', 
                                  log_level='INFO', log_file='tmp.log')
   logger.info(log_string)
   ```

**å…¨å±€æ€§è´¨çš„ç†è§£**

MMLogger å’Œ MessageHub éƒ½ç»§æ‰¿äº† ManagerMixinï¼Œè¿™ä¸ªç±»çš„ä¸»è¦åŠŸèƒ½å°±æ˜¯èƒ½å¤Ÿ**å…¨å±€è°ƒç”¨å®ä¾‹**ã€‚ä¸¾ä¸ªä¾‹å­ï¼Œå‡è®¾åœ¨æŸä¸ªåœ°æ–¹åˆ›å»ºäº†ä¸€ä¸ª MMLogger å®ä¾‹ï¼Œé‚£ä¹ˆé€šè¿‡ `ManagerMixin.get_instance()` èƒ½å¤Ÿåœ¨å…¶ä»–ä»»ä½•åœ°æ–¹éƒ½èƒ½å¤Ÿè·å–è¿™ä¸ª MMLogger å®ä¾‹ã€‚è¯¥åŠŸèƒ½çš„å®ç°éœ€è¦é€šè¿‡**å…ƒç±» meta class** å®Œæˆï¼Œæˆ‘ä¹Ÿä¸ç†è§£å…¶ä¸­ç»†èŠ‚ï¼Œæ¨¡ç³Šä¸€ç‚¹è¯´ï¼Œæˆ‘ä»¬æŠŠåˆ›å»ºçš„å®ä¾‹éƒ½ä¿å­˜åœ¨äº†å…ƒç±»çš„ä¸€ä¸ªå­—å…¸é‡Œé¢ï¼Œè€Œè¿™æ˜¯ä¸€ä¸ªå…¨å±€å¯è·å–çš„ç©ºé—´

### å¯è§†åŒ–ç³»ç»Ÿ Visualizer

mmengine çš„ visualizer æœ‰ä¸¤ä¸ªåŠŸèƒ½ï¼š

1. å¸¸è§„ç”»å›¾

   å¯è§†åŒ–å™¨æä¾›äº†å¸¸ç”¨å¯¹è±¡çš„ç»˜åˆ¶æ¥å£ï¼Œä¾‹å¦‚ç»˜åˆ¶**æ£€æµ‹æ¡†ã€ç‚¹ã€æ–‡æœ¬ã€çº¿ã€åœ†ã€å¤šè¾¹å½¢å’ŒäºŒå€¼æ©ç **ã€‚è¿™äº›åŸºç¡€ API æ”¯æŒä»¥ä¸‹ç‰¹æ€§ï¼š

   - å¯ä»¥å¤šæ¬¡è°ƒç”¨ï¼Œå®ç°å åŠ ç»˜åˆ¶éœ€æ±‚
   - å‡æ”¯æŒå¤šè¾“å…¥ï¼Œé™¤äº†è¦æ±‚æ–‡æœ¬è¾“å…¥çš„ç»˜åˆ¶æ¥å£å¤–ï¼Œå…¶ä½™æ¥å£åŒæ—¶æ”¯æŒ Tensor ä»¥åŠ Numpy array çš„è¾“å…¥

   ```python
   import mmcv
   from mmengine.visualization import Visualizer
   
   file = '/mmdetection/demo/demo.jpg'
   img = mmcv.imread(file, channel_order='rgb')
   vis = Visualizer(image=img)
   vis.show()
   
   visualizer.set_image(image=image)
   visualizer.draw_texts("cat and dog", torch.tensor([10, 20]))
   visualizer.draw_bboxes(torch.tensor([72, 13, 179, 147]), edge_colors='r', line_widths=3)
   ```

   ä¸ºäº†ä¸€äº› fancy çš„éœ€æ±‚è¿˜å¯ä»¥å°† [ç‰¹å¾å›¾å¯è§†åŒ–](https://mmengine.readthedocs.io/zh_CN/latest/advanced_tutorials/visualization.html#id3)

   ```python
   visualizer.draw_featmap(feat, channel_reduction='select_max')
   visualizer.draw_featmap(feat, image, channel_reduction='select_max')
   ```

   channel_reduction è¿˜æœ‰ squeeze_mean, None é€‰é¡¹ï¼Œä½¿ç”¨ None åˆ™éœ€è¦æ­é… topk å‚æ•°

2. æŠŠæ•°æ®å­˜å‚¨åˆ° backend ä¸­ï¼Œbackend ç›®å‰æœ‰ä¸‰ç§

   1. local backend
   2. tensorboard
   3. wandb

   ä½¿ç”¨æ—¶éœ€è¦åœ¨åˆå§‹åŒ–æ—¶æŒ‡å®š backend å’Œ save_dir å‚æ•°

   ```python
   visualizer = Visualizer(vis_backends=[dict(type='LocalVisBackend')], save_dir='temp_dir')
   ```

   å¯ä»¥å­˜å‚¨çš„æ•°æ®ç±»å‹æœ‰å¾ˆå¤š

   - add_config å†™é…ç½®åˆ°ç‰¹å®šå­˜å‚¨åç«¯ï¼Œconfig å¿…é¡»æ˜¯ Config ç±»
   - add_image å†™å›¾ç‰‡åˆ°ç‰¹å®šå­˜å‚¨åç«¯
   - add_scalar å†™æ ‡é‡åˆ°ç‰¹å®šå­˜å‚¨åç«¯
   - add_scalars ä¸€æ¬¡æ€§å†™å¤šä¸ªæ ‡é‡åˆ°ç‰¹å®šå­˜å‚¨åç«¯

## TODO

ä¾¿æ·çš„åˆ†å¸ƒå¼æ¥å£

Metric & Evaluator

coco api & coco metric