#   Train COCO on MMDetection

ç›®çš„ï¼Œèƒ½å¤Ÿè·‘é€š coco æ•°æ®é›†ï¼Œäº†è§£ coco æ ¼å¼

æ›´é‡è¦çš„æ˜¯çœ‹çœ‹ detr æ˜¯æ€ä¹ˆè·‘çš„

## ä¸‹è½½ COCO

è™½ç„¶ç™¾åº¦ç½‘ç›˜æå…¶ğŸ¶ï¼Œä½†æ˜¯è¿™é‡Œæˆ‘ä¾ç„¶ä½¿ç”¨äº†ç™¾åº¦ç½‘ç›˜ä¸‹è½½ï¼Œéœ€è¦å¼€å¯ä¸€ä¸‹é—²ç½®å¸¦å®½ä¼˜åŒ–ä¸‹è½½ã€‚åªè¦æ˜¯çƒ­é—¨èµ„æºä¸‹è½½é€Ÿåº¦éƒ½ä¼šæ¯”è¾ƒå¿«çš„

ä¸‹è½½å®Œåï¼Œè§£å‹æ”¾åœ¨å¦‚ä¸‹ä½ç½®

```txt
mmdetection
â”œâ”€â”€ mmdet
â”œâ”€â”€ tools
â”œâ”€â”€ configs
â”œâ”€â”€ data
â”‚   â”œâ”€â”€ coco
â”‚   â”‚   â”œâ”€â”€ annotations
â”‚   â”‚   â”œâ”€â”€ train2017
â”‚   â”‚   â”œâ”€â”€ val2017
â”‚   â”‚   â”œâ”€â”€ test2017
```

ä¸‹è½½å®Œ coco æ•°æ®é›†ç„¶åè§£å‹

## MMEngine

**è¿™é‡Œæ•´ç† MMEngine çš„æ ¸å¿ƒéƒ¨åˆ†**ï¼Œæˆ‘ä¹‹å‰çš„æ•´ç†éƒ½è¿‡äºéµä»äºå®˜æ–¹æ–‡æ¡£äº†ï¼Œå³å¤ªè¿‡äºå…³æ³¨ç»†èŠ‚ï¼Œä¾ç„¶æ²¡æœ‰å»ºç«‹èµ·æ•´ä½“çš„æ¶æ„

### Registry

**æ³¨å†Œå™¨çš„åŠŸèƒ½ï¼Œå°±æ˜¯åˆ©ç”¨é…ç½®æ–‡ä»¶æ„å»ºç±»çš„å®ä¾‹**

è¦åšåˆ°è¿™ä¸€ç‚¹ï¼Œå°±è¦å…ˆæŠŠéœ€è¦çš„ç±»ç»™æ³¨å†Œåˆ°æ³¨å†Œå™¨ä¸­ã€‚æ‰€è°“æ³¨å†Œï¼Œæœ¬è´¨ä¸Šå°±æ˜¯æŠŠç±»æ”¾åˆ°æ³¨å†Œå™¨å†…çš„ä¸€ä¸ªå­—å…¸ `_module_dict` é‡Œï¼Œä¹‹åéœ€è¦çš„æ—¶å€™å–å‡ºï¼Œä½¿ç”¨é…ç½®æ–‡ä»¶è¿›è¡Œå®ä¾‹åŒ– `Registry.build(cfg)`ï¼Œå¦‚æœåªæƒ³è·å¾—ç±»æœ¬èº«ï¼Œå°±ç”¨ `Registry.get('key')` å³å¯

æ‰€æœ‰çš„æ³¨å†Œå™¨éƒ½æ”¾åœ¨äº† `mmdet.registry` å½“ä¸­ï¼Œéœ€è¦ç”¨å“ªä¸ªå°± `import` å“ªä¸ª

**registry åœ¨ä½¿ç”¨çš„ä½¿ç”¨éœ€è¦æ³¨æ„ä¸€ä¸‹ scopeï¼Œscope æ˜¯æ ¹æ®æ¨¡å—æ‰€åœ¨çš„ package çš„åå­—ç¡®å®šçš„ï¼Œå¯ç”¨ `DefaultScope` æ¥å®Œæˆç›¸å…³æ“ä½œ**

### Config

**é…ç½®æ–‡ä»¶å®šä¹‰äº†æ‰€ä½¿ç”¨çš„æ¨¡å‹ã€è®­ç»ƒã€æ•°æ®é›†**

ä½¿ç”¨ `Config` ç±»æ¥å®Œæˆå¯¹é…ç½®æ–‡ä»¶çš„å¤„ç†

```python
cfg = Config.fromfile('config.py')
```

 å³å¯ç”¨ `config.py` æ–‡ä»¶åˆ›å»ºä¸€ä¸ªé…ç½®ç±»ã€‚æ–‡ä»¶å³å¯ä»¥æ˜¯ `.py` ä¹Ÿå¯ä»¥æ˜¯ `.yaml`

`Config` ç±»å¯ä»¥é€šè¿‡å…³é”®å­—æˆ–è€…å±æ€§æ¥è°ƒç”¨é…ç½®æ–‡ä»¶å†…å®¹ï¼Œ`cfg.key` æˆ– `cfg['key']` éƒ½å¯è·å¾—å…¶ä¸­çš„å†…å®¹

**ä¸ºäº†æ„å»ºä¸€ä¸ªå±‚çº§çš„é…ç½®æ–‡ä»¶ï¼Œç»§æ‰¿æœºåˆ¶æ˜¯éå¸¸æœ‰å¿…è¦çš„**

é…ç½®æ–‡ä»¶å†…å¯ä»¥é€šè¿‡ `_base_` å…³é”®å­—æŒ‡å®šåŸºç¡€é…ç½®æ–‡ä»¶

```python
_base_ = ['list_of_base_configs.py',]
```

ä¿®æ”¹åŸºç¡€é…ç½®ä¸­çš„å€¼ä¹Ÿéå¸¸ç®€å•ï¼Œç›´æ¥åœ¨å½“å‰é…ç½®æ–‡ä»¶å¤¹ä¸­é‡æ–°å®šä¹‰å³å¯ï¼Œå¹¶ä¸”ä½ ä¸éœ€è¦æŠŠå­—å…¸æ‰€æœ‰çš„å…³é”®å­—éƒ½é‡æ–°å®šä¹‰ä¸€éï¼Œåªéœ€è¦å®šä¹‰ä¿®æ”¹çš„å…³é”®å­—å³å¯ã€‚å¦‚æœæƒ³è¦åˆ é™¤æ²¡æœ‰é‡æ–°å®šä¹‰çš„å…³é”®å­—éœ€è¦ä½¿ç”¨ `_delete_` å…³é”®å­—ï¼Œè¿™æ ·å°±ä»…å‰©ä¸‹æ–°å®šä¹‰çš„å†…å®¹

```python
_base_ = ['optimizer_cfg.py', 'runtime_cfg.py']
optimizer = dict(_delete_=True, type='SGD', lr=0.01)
```

**å…¶ä»–æŠ€å·§**

1. å¯ä»¥é€šè¿‡ `{{_base_.attr}}` æ¥å¼•ç”¨ä¸Šçº§é…ç½®ä¸­çš„å†…å®¹
2. å¯ä»¥é€šè¿‡ `cfg.dump('config.py')` æ¥è¾“å‡ºé…ç½®æ–‡ä»¶ï¼Œè¾“å‡ºå½¢å¼è¿˜å¯ä»¥æ˜¯ `.yaml`

### Runner

å…‰çœ‹æ–‡æ¡£å®Œå…¨æ²¡åŠæ³•ç†è§£ runnerï¼Œè¿˜æ˜¯å¾—çœ‹çœ‹ä»£ç ã€‚è¿‡å®Œä¸€éåæ€»ç»“ï¼šRunner å°±æ˜¯ä¸€ä¸ªå¤§å·¥å‚ï¼Œæ‰€æœ‰çš„ç»„ä»¶éƒ½æ˜¯å…¶ä¸­çš„å±æ€§ï¼Œç»„ä»¶ä¸ç»„ä»¶ä¹‹é—´èƒ½å¤Ÿé€šè¿‡ runne è¿›è¡Œç›¸äº’é…åˆï¼Œå®Œæˆæ‰€æœ‰çš„æµç¨‹

#### Runner åˆå§‹åŒ–

runner çš„åˆå§‹åŒ–é‡‡ç”¨äº†ä¸€ä¸ª lazy init çš„ç­–ç•¥ã€‚æ‰€è°“ lazy init å°±æ˜¯æŒ‡å…ˆæŠŠ cfg èµ‹å€¼ç»™æŸä¸ªç»„ä»¶ï¼Œå¦‚ `self.dataloader = dataloader_cfg`ï¼Œåœ¨ä¹‹åéœ€è¦ç”¨è¿™ä¸ªç»„ä»¶çš„æ—¶å€™ï¼Œå†ç”¨ cfg æ„å»ºçœŸæ­£çš„å®ä¾‹

1. deepcopy cfgï¼Œæ–°å»ºå±æ€§ self.cfg
2. åˆ›å»ºå±æ€§ `self.traininig_related, self.val_related, self.test_related`ã€‚æ¯ä¸ª related ä¸º `[xxx_dataloader, xxx_cfg, xxx_evaluator]`
3. åˆ›å»ºå±æ€§ `self.optim_wrapper`
4. åˆ›å»ºå±æ€§ `self._launcher`ï¼Œå†³å®šæ˜¯å¦ä¸ºåˆ†å¸ƒå¼ï¼Œå¹¶åˆ›å»ºå±æ€§ `self._distributed`
5. `self.setup_env` åˆå§‹åŒ– dist ç¯å¢ƒï¼Œå¹¶æ–°å»ºå±æ€§ `self._rank, self._world_size`
6. `self.set_random_seed`ï¼Œæ–°å»ºå±æ€§ `self.seed, self.deterministic`ï¼Œå¯é€šè¿‡ `randomness=dict(seed=None)` é…ç½®éšæœºç§å­
7. åˆ›å»º `work_dir`
8. åˆ›å»ºå±æ€§ `self.logger`ï¼Œlogger æ­¤æ—¶è®°å½•ä¸‹ç¯å¢ƒä¿¡æ¯å’Œé…ç½®æ–‡ä»¶
9. åˆ›å»ºå±æ€§ `self.load_from, self.resume`
10. åˆ›å»ºå±æ€§ `self.model`ï¼Œå¹¶å°†æ¨¡å‹æ‰“åŒ…ï¼Œæ‰“åŒ…å®Œæˆçš„äº‹æƒ…å¦‚ä¸‹:
    1. æŠŠæ¨¡å‹é€åˆ°å¯¹åº”çš„è®¾å¤‡ä¸Š `model.to(device)`
    2. å¦‚æœä¸ºåˆ†å¸ƒå¼è®­ç»ƒåˆ™å°† model æ‰“åŒ…ä¸º `MMDistributedDataParallel`ï¼Œå½“ç„¶ä¹Ÿå¯ä»¥ä½¿ç”¨ pytorch çš„ `DistributedDataParallel`ï¼Œä¸è¿‡éœ€è¦å•ç‹¬è®¾ç½®ã€‚`MMDistributedDataParallel` ç»§æ‰¿äº DDPï¼Œå¹¶æ–°å®šä¹‰äº†ä¸‰åˆ†æ–¹æ³• `tran_step, val_step, test_step` æ¥è°ƒç”¨ model ä¸­å®šä¹‰çš„ `tran_step, val_step, test_step` 
11. æ³¨å†Œ hooksï¼Œå¹¶ä¿å­˜è¿›å±æ€§ `self._hooks`
12. è¾“å‡º configï¼Œ`cfg.dump(file_path)`

#### Runner.train()

1. æ£€æŸ¥ model æ˜¯å¦æœ‰ `train_step` å±æ€§/æ–¹æ³•ã€‚è¿™é‡Œæ˜¯å¯¹æ¨¡å‹çš„åŸºæœ¬è¦æ±‚ã€‚å¦‚æœæœ‰ `val_loop`ï¼Œä¹Ÿå¾—æ£€æŸ¥æ˜¯å¦æœ‰ `val_step`
2. åˆ›å»ºå±æ€§ `self.train_loop`ã€‚è¡¥å……çŸ¥è¯†ï¼šä¸€ä¸ªç±»å®šä¹‰æ—¶ä¼ å…¥å‚æ•° metaclass=ABCMeta è¡¨ç¤ºè¯¥ç±»ä¸ºæŠ½è±¡ç±»ï¼Œä¸èƒ½å¤Ÿå®ä¾‹åŒ–ï¼Œåªèƒ½ç”¨æ¥ç»§æ‰¿

3. åˆ›å»ºå±æ€§ `self.optim_wrapper`ï¼Œå¹¶ä½¿ç”¨ `scale_lr` è‡ªåŠ¨ç¼©æ”¾å­¦ä¹ ç‡
4. åˆ›å»ºå±æ€§ `self.param_schedulers`ï¼Œç®¡ç†å­¦ä¹ ç‡ç­–ç•¥
5. åˆ›å»ºå±æ€§ `self.val_loop`
6. è¿è¡Œé’©å­ `self.call_hook('before_run')`
7. åˆå§‹åŒ–æ¨¡å‹æƒé‡ï¼Œå¦‚æœæœ‰é¢„è®­ç»ƒæƒé‡åˆ™ load
8. è¿è¡Œè®­ç»ƒå¾ªç¯ `self.train_loop.run()`
9. è¿è¡Œé’©å­ `call_hook('after_run')`

### Runner ä¸­ train_loop é€»è¾‘

`BaseLoop` æ˜¯ä¸€ä¸ªéå¸¸ç®€å•çš„ç±»ï¼Œåªéœ€è¦ runner å’Œ dataloader ä½œä¸ºåˆå§‹åŒ–å³å¯ã€‚`EpochBasedTrainLoop` ç»§æ‰¿ `BaseLoop`ï¼Œå…¶æ ¸å¿ƒé€»è¾‘åœ¨ `run` æ–¹æ³•

`run` å°†å¾ªç¯è¿è¡Œ `run_epoch`ï¼Œå¹¶åœ¨ epoch ååˆ¤æ–­æ˜¯å¦éœ€è¦ eval

`run_epoch` æ˜¯ç”±å¾ªç¯ `run_iter` å®Œæˆï¼Œå¾ªç¯ä»¥ dataloader ä¸»å¯¼

run_iter ä¸­è¿è¡Œäº†æ¨¡å‹çš„ `train_step` æ­¥éª¤ï¼Œåœ¨ `train_step` ä¸­ä¼˜åŒ–æ­¥å·²ç»å®Œæˆäº†

ä¸‹é¢å†™ä¸€ä¸‹ç®€åŒ–ä»£ç ï¼Œå»é™¤é’©å­

```python
    def run(self) -> torch.nn.Module:
        """Launch training."""
        while self._epoch < self._max_epochs:
            self.run_epoch()
            if (self.runner.val_loop is not None and self._epoch >= self.val_begin and self._epoch % self.val_interval == 0):
                self.runner.val_loop.run()
        return self.runner.model

    def run_epoch(self) -> None:
        """Iterate one epoch."""
        self.runner.model.train()
        for idx, data_batch in enumerate(self.dataloader):
            self.run_iter(idx, data_batch)
        self._epoch += 1

    def run_iter(self, idx, data_batch: Sequence[dict]) -> None:
        outputs = self.runner.model.train_step(
            data_batch, optim_wrapper=self.runner.optim_wrapper)
        self._iter += 1
```

è‡ªå·±åœ¨å†™ä¸ªæ€§åŒ– Loops çš„æ—¶å€™æœ€å¥½è¦å°†è¿™äº›é’©å­éƒ½åŠ ä¸Šï¼Œä»¥ä¿è¯ç»“æœçš„æ­£ç¡®ï¼ä¾‹å¦‚ `DefaultSampler` çš„éšæœºç§å­è¦åœ¨å„ä¸ª epoch å¼€å§‹å‰é‡æ–°è®¾ç½®ï¼Œè¿™éœ€è¦è°ƒç”¨ `DistSamplerSeedHook` å®Œæˆ

### TODO: Runner ä¸­ val_loop é€»è¾‘

metric å¦‚ä½•è®¡ç®—ï¼Œå¦‚ä½•ä¼ é€’ï¼Œå¦‚ä½•ä¿å­˜

### Model ä¸­ train_step é€»è¾‘

æ ¸å¿ƒä»£ç éå¸¸ç®€å•ï¼šæ•°æ®é¢„å¤„ç†+å‰å‘æŸå¤±+æ›´æ–°å‚æ•°

```python
    def train_step(self, data: Union[dict, tuple, list],
                   optim_wrapper: OptimWrapper) -> Dict[str, torch.Tensor]:
        with optim_wrapper.optim_context(self):
            data = self.data_preprocessor(data, True)
            losses = self._run_forward(data, mode='loss')  # type: ignore
        parsed_losses, log_vars = self.parse_losses(losses)  # type: ignore
        optim_wrapper.update_params(parsed_losses)
        return log_vars
```

#### DataPreprocessor

ç”±äº collate_fn ä½¿ç”¨çš„æ˜¯ä¸€ä¸ªéå¸¸ç®€å•çš„æ–¹æ³•ï¼Œæ‰€ä»¥**æ•°æ®é¢„å¤„ç†æ”¾åœ¨äº† DataPreprocessor ä¸­**ï¼Œå…¶åŠŸèƒ½åŒ…æ‹¬æŠŠæ•°æ®å‘é€åˆ° GPU ä¸Šï¼Œæ•°æ®æ‰“åŒ…ï¼Œå½’ä¸€åŒ–ï¼Œæœ€åè¿”å› data å­—å…¸ï¼ˆåŒ…å« data['inputs'] & data['data_sample']ï¼‰

è¿™é‡Œè¯´æ˜ä¸€ä¸‹ DataPreprocessor **æŠŠæ•°æ®å‘é€åˆ° GPU ä¸Š** è¿™ä¸ªåŠŸèƒ½ï¼Œå†™å¾—æœ‰ç‚¹éšæ™¦ï¼šåœ¨ `BaseModel` é‡Œä¸ºè¿™ä¸€ä¸ªåŠŸèƒ½é‡å†™äº†æ¨¡å‹çš„ `to & cuda & cpu` è¿™å‡ ä¸ªæ–¹æ³•ï¼Œå°±æ˜¯ä¸ºäº†é¢å¤–è®¾ç½® DataPreprocessor çš„ `device` å±æ€§ï¼Œä¿è¯äº†å±äºä¸æ¨¡å‹çš„ `device` æ˜¯ç»Ÿä¸€çš„ï¼Œç›´æ¥ä½¿ç”¨ `model.to(device)` å³å¯

#### parse_losses

mmengine æœŸæœ›æ¨¡å‹åœ¨è®­ç»ƒæ—¶çš„è¾“å‡ºæ˜¯ä¸€ä¸ªå­—å…¸ï¼Œ`parse_losses` å°†è¾“å‡ºå­—å…¸ä¸­åŒ…å« `'loss'` é”®å€¼å¯¹å…¨éƒ½æ‰¾å‡ºæ¥æ”¾åˆ° `log_vars` ä¸­ï¼Œç„¶åå†æ±‚å’Œï¼Œå½¢æˆæœ€ç»ˆçš„ `loss`ï¼Œæœ€ç»ˆè¿”å› `loss & log_vars`ï¼Œå‰è€…ç”¨äºåå‘ä¼ æ’­ï¼Œåè€…ç”¨äºæ—¥å¿—è®°å½•

### å¦‚ä½•è‡ªå·±å†™ Config é…ç½®æ–‡ä»¶

å»ºè®®æ˜¯ä» `_base_` ä¸­å»ç»§æ‰¿ `default_runtime.py`ï¼Œç„¶åå†æŒ‘é€‰ä¿®æ”¹ã€‚æ€»ä½“æ¥è®²æ ¸å¿ƒå¦‚ä¸‹

```python
# dataset
dataset = dict(type='COCO')
train_pipeline = [dict(type='LoadImageFromFile')]
train_dataloader = dict(batch_size=16, dataset=dataset, sampler=, pipline=train_pipline)

test_pipline = ...
val_dataloader = ...

val_evaluator = dict(type='CocoMetric', ann_file=...)

# model
model = dict(type='DETR',...)
data_preprocessor = dict(type='BaseDataPreprocessosr')

# optimizer & scheduler
train_cfg = dict(type='EpochBasedTrainLoop', max_epochs=12, val_interval=1)
val_cfg = dict(type='ValLoop')

optim_wrapper = dict(type='OptimWrapper', optimizer=dict(tpye='SGD', lr=0.01))
param_scheduler = dict(type='LinearLR', start_factor=0.001, by_epoch=False, begin=0, end=500)

auto_scale_lr = dict(enable=False, base_batch_size=16)

# logs & hooks
default_hooks

log_processor = dict(type='LogProcessor', window_size=50, by_epoch=True)
log_level = 'INFO'

visualizer = dict(type='DetLocalVisualizer', vis_backends=[dict(type='LocalVisBackend')], name='visualizer')
```

### DataLoader æ¥å£æ•´ç†

```python
DataLoader(dataset, 
           batch_size=1, shuffle=False, sampler=None, drop_last=False,
           batch_sampler=None, 
           collate_fn=None,
           num_workers=0, pin_memory=False)
```

æˆ‘æŠŠä¸Šé¢çš„å‚æ•°åˆ†æˆäº†4è¡Œï¼Œå…¶ä¸­**å‰ä¸¤è¡Œæ˜¯æ ¸å¿ƒé…ç½®ï¼Œæ§åˆ¶éšæœºæ€§å’Œ batch è¡Œä¸º**ï¼Œç¬¬ä¸‰è¡Œæ˜¯è‡ªå®šä¹‰æ‰“åŒ…æ–¹æ³•é…ç½®ï¼Œç¬¬å››è¡Œæ˜¯åŠ é€Ÿé…ç½®

1. sampler å’Œ shuffle ä¸¤ä¸ªå‚æ•°æ˜¯äº’æ–¥çš„ï¼Œæœ‰äº† sampler å shuffle å°†ä¸å†èµ·ä½œç”¨ã€‚**å®é™…ä¸Šå‡ ä¹å¯ä»¥ä¸ç”¨ sampler è¿™ä¸ªå‚æ•°**
2. `batch_sampler` æ˜¯ä»¥ä¸€ä¸ª `Sampler` ä½œä¸ºåŸºç¡€ï¼Œå†è¿›è¡Œ group æ“ä½œã€‚å½“ä¼ å…¥ batch_sampler åï¼Œå°±ä¸ç”¨ä¼ å…¥ `sampler, batch_size, drop_last, shuffle` å…³é”®å­—
3. `num_workers` ä¸ºè°ƒç”¨çº¿ç¨‹çš„æ•°é‡ï¼Œæ²¡æœ‰å›ºå®šè¯´æ³•è®¾ç½®å¤šå°‘æœ€å¥½ã€‚`pin_memory` å°±æ˜¯é”é¡µå†…å­˜ï¼Œåˆ›å»º DataLoader æ—¶ï¼Œè®¾ç½® pin_memory=Trueï¼Œåˆ™æ„å‘³ç€ç”Ÿæˆçš„Tensoræ•°æ®æœ€å¼€å§‹æ˜¯å±äºå†…å­˜ä¸­çš„é”é¡µå†…å­˜ï¼Œè¿™æ ·å°†å†…å­˜çš„Tensorè½¬ä¹‰åˆ°GPUçš„æ˜¾å­˜å°±ä¼šæ›´å¿«ä¸€äº›
4. ä¸ºäº†è¾ƒå¥½çš„å¯å¤ç°ï¼Œmmengine ä¸­è¿˜æ˜¯ç”¨äº† `worker_init_fn` æ¥ç»™æ¯ä¸ªçº¿ç¨‹è®¾ç½®éšæœºç§å­ï¼Œè¿™é‡Œä¸æ€»ç»“

**åœ¨åä¸¤è¡Œé…ç½®ä¸å˜æ—¶ï¼Œä»…é…ç½®å‰ä¸¤è¡Œå³å¯å®Œæˆå¯¹å•å¡å’Œå¤šå¡ï¼ˆåˆ†å¸ƒå¼ï¼‰çš„ DataLoader åˆ›å»º**

1. å•å¡ï¼Œç›´æ¥é…ç½®ç¬¬ä¸€è¡Œ

   ```python
   DataLoader(dataset, batch_size=2, shuffle=False, drop_last=False)
   ```

2. å¤šå¡ï¼Œç›´æ¥ä¸Š batch_sampler

   ```python
   sampler = DistributedSampler(dataset, seed=None, shuffle=False)
   batch_sampler = BatchSampler(sampler, batch_size=2, drop_last=False)
   DataLoader(dataset, batch_sampler=batch_sampler)
   
   # before each epoch start
   sampler.set_epoch(epoch_number)
   ```

`Sampler` çš„æ ¸å¿ƒæ–¹æ³•æ˜¯ `__iter__`ï¼Œå³é€šè¿‡è¿­ä»£ä¸æ–­ç”Ÿæˆ indexï¼Œ`DistributedSampler` æŠŠæ•°æ®é›†çš„æ€» index åˆ†æˆäº†å¤šä¸ªä¸é‡å çš„å­é›†ï¼Œæ¯ä¸ªè¿›ç¨‹å¯¹åº”ä¸€ä¸ªå­é›†ï¼Œç„¶ååœ¨å„è‡ªçš„å­é›†ä¸­è¿­ä»£ç”Ÿæˆ indexã€‚è€Œ `BatchSampler` åˆ™æ˜¯ç”Ÿæˆä¸€ä¸ª `batch_size` é•¿åº¦çš„ index åºåˆ—

**mmengine ä¸­çš„ DefaultSampler èƒ½å¤ŸåŒæ—¶å¤„ç†åˆ†å¸ƒå¼å’Œéåˆ†å¸ƒå¼çš„é‡‡æ ·ï¼Œå†åŒ…ä¸€ä¸ª BatchSampler å°±èƒ½å¤Ÿå¤„ç†æ‰¹é‡‡æ ·äº†**ï¼Œä½¿ç”¨çš„ `collate_fn` ä¸º `pesudo_collate` å°±æ˜¯ pytorch é»˜è®¤çš„ [collate function](https://pytorch.org/docs/stable/data.html#torch.utils.data.default_collate) ä½†æ˜¯ä¸è½¬æ¢æ•°æ®ä¸º tensor

### Optimizer æ¥å£æ•´ç†

Pytorch å®ç°çš„ Optimizer çš„è¾“å…¥ä¸»è¦ç”± `model.parameters()` å’Œå…¶ä»–è¶…å‚æ•°ï¼ˆå¦‚ `lr, weight_decay`ï¼‰ã€‚å¦‚æœæƒ³è¦å¯¹ç‰¹å®šå±‚è®¾ç½®ï¼Œå¯å‚è€ƒ [StackOverflow](https://stackoverflow.com/questions/51801648/how-to-apply-layer-wise-learning-rate-in-pytorch)ï¼Œä¼ å…¥ä¸€ä¸ª list of dict å³å¯

mmengine å¯¹ pytorch ä¼˜åŒ–å™¨çš„åŒ…è£…è¿˜æ˜¯æ¯”è¾ƒè½»çš„ï¼Œé™¤äº† optimizer åŸæœ‰çš„æ¥å£å¤–ï¼Œ[OptimWrapper](https://mmengine.readthedocs.io/zh_CN/latest/tutorials/optim_wrapper.html) ä¸»è¦å¤šäº†å‡ ä¸ªæ¥å£ï¼š

1. `optim_wrapper.update_params(loss)` æ›´æ–°å‚æ•°ï¼Œæ›¿ä»£ backward + step
2. `optim_wrapper.get_lr()` è·å¾—å­¦ä¹ ç‡ï¼Œæ›¿ä»£åŸæ¥çš„ `optimizer.param_groups[0]['lr']`
3. åŠ è½½ä¼˜åŒ–å™¨çŠ¶æ€å­—å…¸ä½¿ç”¨çš„åŸå§‹æ¥å£ `state_dict & load_state_dict`

mmengine ä¸­çš„ scheduler å’Œ pytorch ä¸­çš„ scheduler ä½¿ç”¨æ–¹æ³•å®Œå…¨ä¸€è‡´ï¼Œä½†æ‰©å±•äº† scheduler çš„ä½¿ç”¨èŒƒå›´ï¼Œä¸ä»…ä»…èƒ½å¤Ÿå¯¹ lr è¿›è¡Œç®¡ç†ï¼Œè¿˜èƒ½å¯¹ momentum è¿›è¡Œç®¡ç†ã€‚scheduler çš„æ¥å£åç§°å’Œ optimizer çš„æ¥å£åç§°åŸºæœ¬ä¸€è‡´ï¼Œä½¿ç”¨ `scheduler.step()` å³å¯

scheduler åŸç†æ˜¯æ ¹æ®å½“å‰æ­¥ï¼ˆlast_stepï¼‰å’Œç»™å®šå‚æ•°è®¾ç½®å­¦ä¹ ç‡ï¼ŒåŸºæœ¬ä¸Šä¸éœ€è¦è‡ªå·±è°ƒæ•´ï¼Œç›´æ¥å‚è€ƒæ–‡æ¡£ [mmengine.optim](https://mmengine.readthedocs.io/zh_CN/latest/api/optim.html) å†™é…ç½®æ–‡ä»¶å³å¯ã€‚è¦è‡ªå·±å®ç°ä¸ªæ€§åŒ–çš„ scheduler å¯ä»¥å‚è€ƒä¸€ä¸‹æºç 

### Dataset & DataSample

#### BaseDataset å®ç°é€»è¾‘

å¦‚æœè¦è‡ªå·±å†™ä¸€ä¸ª dataset ä¸»è¦è€ƒè™‘é‡å†™ä¸¤ä¸ªæ–¹æ³•

1. `full_init()` æ–¹æ³•
2. **`load_data_list()`**ï¼Œéœ€è¦è‡ªå·±å†™ï¼Œreturn a list of dict å¹¶èµ‹ä¸ºå±æ€§ `self.data_list`ï¼Œé€šå¸¸ä»…åŒ…å«æ ·æœ¬çš„è·¯å¾„å’Œæ ·æœ¬çš„æ ‡ç­¾

å…¶ä»–åŸºæœ¬ä¸Šå°±ä¸éœ€è¦äº†ï¼Œæ¥ä¸‹æ¥å°±æ˜¯ç”¨ `__getitem__` é…åˆ `self.pipline`ï¼Œç”Ÿæˆå®Œæ•´çš„ä¸€ä¸ªæ ·æœ¬

```python
    def __getitem__(self, idx: int) -> dict:
        if not self._fully_initialized: self.full_init()

        data = self.prepare_data(idx)
        return data
    
    def prepare_data(self, idx) -> Any:
        data_info = self.get_data_info(idx)
        return self.pipeline(data_info)
    
    def get_data_info(self, idx: int) -> dict:
        data_info = copy.deepcopy(self.data_list[idx])
        return data_info
```

#### PackxxxInputs

é€šç”¨çš„å¢å¼ºè¾“å‡º PackxxInputsï¼Œéœ€è¦è¿›ä¸€æ­¥äº†è§£é€šç”¨æ•°æ®å…ƒç´ çš„è®¾è®¡

åœ¨æ¨¡å‹çš„è®­ç»ƒ/æµ‹è¯•è¿‡ç¨‹ä¸­ï¼Œç»„ä»¶ä¹‹é—´å¾€å¾€æœ‰å¤§é‡çš„æ•°æ®ï¼ˆimagesï¼‰å’Œæ ‡ç­¾ï¼ˆlabelsï¼‰éœ€è¦ä¼ é€’ï¼Œä¸åŒçš„ç®—æ³•éœ€è¦ä¼ é€’çš„æ•°æ®å’Œæ ‡ç­¾å½¢å¼ç»å¸¸æ˜¯ä¸ä¸€æ ·çš„

```python
# detection
for img, img_metas, gt_bboxes, gt_labels in data_loader:
    loss = retinanet(img, img_metas, gt_bboxes, gt_labels)
# segmentation
for img, img_metas, gt_bboxes, gt_masks, gt_labels in data_loader:
     loss = mask_rcnn(img, img_metas, gt_bboxes, gt_masks, gt_labels)
```

ä¸ºäº†ç»Ÿä¸€æ•°æ®æ¥å£ mmengine å°±å¯¹è¿™**æ•°æ®**å’Œ**æ ‡ç­¾**åˆ†åˆ«è¿›è¡Œæ‰“åŒ…ï¼Œè¯¥åŠŸèƒ½ä½¿ç”¨ `PackxxxInputs` å®Œæˆï¼Œæœ€åè¾“å‡ºçš„ data åªæœ‰ä¸¤ä¸ªå…³é”®å­— `inputs & data_sample`ï¼Œå…¶ä¸­ `inputs` ä¸€èˆ¬ä¸ºå›¾åƒæœ¬èº«ï¼Œè€Œ `data_sample` ä¸º gt æ ‡ç­¾ï¼Œç”± `DataSample` è¡¨ç¤º

```python
for img, data_sample in dataloader:
    loss = model(img, data_sample)
```

åœ¨å®é™…å®ç°è¿‡ç¨‹ä¸­ï¼Œmmengine ä½¿ç”¨ `DataSample` ç±»æ¥å°è£…æ ‡ç­¾ã€é¢„æµ‹ç»“æœä¿¡æ¯ï¼Œ`DataSample` ç”±æ•°æ®å…ƒç´  `xxxData` æ„æˆï¼Œæ•°æ®å…ƒç´ ä¸ºæŸç§ç±»å‹çš„é¢„æµ‹æˆ–è€…æ ‡æ³¨ï¼Œç»§æ‰¿äº BaseDataElement ç±»ã€‚ä¸‹é¢ä»ä¸‹åˆ°ä¸Šä»‹ç»ä»‹ç» `DataSample`

##### BaseDataElement

ä¸ºäº†æ›´å¥½çš„æ“ä½œæ•°æ®ï¼Œå®ç°äº† BaseDataElementï¼Œå…¶ä¸»è¦æœ‰å¦‚ä¸‹åŠŸèƒ½

1. BaseDataElement å°†æ•°æ®åˆ†ä¸º **data** å’Œ **metainfo** ä¸¤ä¸ªéƒ¨åˆ†ï¼Œé€šè¿‡ç±»çš„åˆå§‹åŒ–å°†è¿™ä¸¤ä¸ªéƒ¨åˆ†æ„å»ºåˆ° BaseDataElement ä¸­

   ```python
    def __init__(self, *, metainfo: Optional[dict] = None, **kwargs) -> None:
           # metainfo å¿…é¡»ä¸ºå­—å…¸
           # data åˆ™ä»¥å…³é”®å­— kwargs ç›´æ¥åŠ å…¥
   base_data = BaseDataElement(metainfo=dict(h=1,w=2), size=100)
   ```

   äºŒè€…éƒ½ä»¥ BaseDataElement ä¸­çš„å±æ€§ï¼ˆattrï¼‰å­˜åœ¨ï¼ŒåŒºåˆ«åœ¨äº metainfo ä¸èƒ½å¤Ÿç›´æ¥é€šè¿‡å±æ€§è®¾ç½®ï¼Œåªæœ‰ data å¯ä»¥ç›´æ¥é€šè¿‡å±æ€§è®¾ç½®ã€‚ä¿®æ”¹ metainfo éœ€è¦ä½¿ç”¨ set_metainfo æ–¹æ³•

   ```python
   base_data = BaseDataElement(metainfo=dict(h=1,w=2), size=100)
   base_data.h = 2		# no!!
   base_data.set_metainfo(dict(h=2))	# yes
   base_data.size = 2					# yes
   ```

   åˆ é™¤å±æ€§å¯ä»¥ç›´æ¥ä½¿ç”¨ pop æ–¹æ³•ï¼Œä¸ç®¡æ˜¯ metainfo è¿˜æ˜¯ data éƒ½ç®¡ç”¨

2. å®ç°äº† newï¼Œcloneï¼Œtoï¼Œnumpyï¼Œcudaï¼Œcpu è¿™äº›ç±»ä¼¼äºå¼ é‡ä¸­çš„æ–¹æ³•ï¼Œå¯ä»¥æ‰¹é‡å¯¹ data ä¸­çš„æ•°æ®ç›´æ¥æ“ä½œ

3. é€šè¿‡ print(BaseDataElement) èƒ½å¤Ÿç›´è§‚è·å¾—å…¶ä¸­çš„ data å’Œ metainfo

##### InstanceData

- å¯¹ `InstanceData` ä¸­ data æ‰€å­˜å‚¨çš„æ•°æ®è¿›è¡Œäº†é•¿åº¦æ ¡éªŒ
- data éƒ¨åˆ†æ”¯æŒç±»å­—å…¸è®¿é—®å’Œè®¾ç½®å®ƒçš„å±æ€§
- æ”¯æŒåŸºç¡€ç´¢å¼•ï¼Œåˆ‡ç‰‡ä»¥åŠé«˜çº§ç´¢å¼•åŠŸèƒ½
- æ”¯æŒå…·æœ‰**ç›¸åŒçš„ `key`** ä½†æ˜¯ä¸åŒ `InstanceData` çš„æ‹¼æ¥åŠŸèƒ½ã€‚ è¿™äº›æ‰©å±•åŠŸèƒ½é™¤äº†æ”¯æŒåŸºç¡€çš„æ•°æ®ç»“æ„ï¼Œ æ¯”å¦‚`torch.tensor`, `numpy.dnarray`, `list`, `str`, `tuple`, ä¹Ÿå¯ä»¥æ˜¯è‡ªå®šä¹‰çš„æ•°æ®ç»“æ„ï¼Œåªè¦è‡ªå®šä¹‰æ•°æ®ç»“æ„å®ç°äº† `__len__`, `__getitem__` and `cat`.

##### DataSample

æ•°æ®æ ·æœ¬ä½œä¸ºä¸åŒæ¨¡å—æœ€å¤–å±‚çš„æ¥å£ï¼Œæä¾›äº† xxxDataSample ç”¨äºå•ä»»åŠ¡ä¸­å„æ¨¡å—ä¹‹é—´ç»Ÿä¸€æ ¼å¼çš„ä¼ é€’ã€‚mmengine å¯¹ xxxDataSample çš„å±æ€§å‘½åä»¥åŠç±»å‹è¦è¿›è¡Œçº¦æŸå’Œç»Ÿä¸€ï¼Œä¿è¯å„æ¨¡å—æ¥å£çš„ç»Ÿä¸€æ€§

å¯¹å‘½åçš„çº¦æŸæ˜¯ä½¿ç”¨ @property è£…é¥°å™¨å®Œæˆï¼Œåˆ©ç”¨ property setter å¢åŠ å¯¹å±æ€§çš„æ›´æ”¹

### Default Hooks åŠŸèƒ½

1. IterTimerHookï¼Œè®°å½•æ¯ä¸€ä¸ª iteration å®ç”¨çš„æ—¶é—´

2. **LoggerHook**ï¼Œæ—¥å¿—å°†æ ¹æ® interval è¿›è¡Œé‡‡æ ·ï¼Œæœ€ç»ˆè¾“å‡ºåˆ° terminalï¼Œå¹¶ä¿å­˜åˆ°æ—¥å¿—æ–‡ä»¶å’Œ visualization backend ä¸­ï¼Œé€»è¾‘å¦‚ä¸‹

   ```python
           if self.every_n_inner_iters(batch_idx, self.interval):
               tag, log_str = runner.log_processor.get_log_after_iter(
                   runner, batch_idx, 'train')
           runner.logger.info(log_str)
           runner.visualizer.add_scalars(
               tag, step=runner.iter + 1, file_path=self.json_log_path)
   ```

   `log_processor` æ˜¯ä» message hub ä¸­è·å¾—ä¿¡æ¯ï¼Œç„¶åå°†ä¿¡æ¯æ ¼å¼åŒ–ä¾¿äºè¾“å‡ºï¼Œå…¶ä¸­ `tag` æ˜¯ä¸€ä¸ªå­—å…¸ï¼Œ`log_str` å°±æ˜¯å°† tag æ ¼å¼åŒ–åçš„å­—ç¬¦ä¸²

3. **ParamSchedulerHook**ï¼Œåœ¨æ¯ä¸€ä¸ª epoch or iter è¿‡åæ›´æ–°å­¦ä¹ ç‡

4. CheckpointHookï¼Œä¿å­˜æ¨¡å‹ï¼Œoptimizerï¼Œschedulerï¼Œä»¥åŠä¸€äº› meta ä¿¡æ¯ï¼ˆè¿è¡Œçš„ epoch or iteration ç­‰ï¼‰

5. **DistSamplerSeedHook**ï¼Œ`before_train_epoch` è®¾ç½®éšæœºç§å­ `set_epoch`

6. DetVisualizationHookï¼Œonly works in test and val

7. **RuntimeInfoHook**ï¼Œè¿™é‡Œä¼šå°†è¿è¡Œæ—¶çš„ä¿¡æ¯æ”¾å…¥ message hub å½“ä¸­ï¼ŒåŒ…æ‹¬ metaï¼Œlrï¼Œlossï¼Œmetrics

### æ—¥å¿—ç³»ç»Ÿ MessageHub & MMLogger

`MessageHub` çš„ä½œç”¨æ˜¯åœ¨å…¨å±€æ”¶é›†ä¿¡æ¯ã€‚æ”¶é›†çš„ä¿¡æ¯å­˜å‚¨åœ¨ HistoryBuffer é‡Œï¼Œè¿™ä¸ª buffer ç›¸å½“äºä¸€ä¸ªé˜Ÿåˆ—ï¼Œå…¶æœ€å¤§å®¹é‡ä¸º window sizeï¼Œå³æœ€å¤šç¼“å­˜å¤šå°‘æ¡æ•°æ®ï¼Œå¤šä½™è¿™ä¸ª window sizeï¼Œä¹‹å‰çš„æ•°æ®å°±ä¼šè¢«æŒ¤å‡ºå»

æ—¥å¿—ç³»ç»Ÿé€šå¸¸ä½¿ç”¨ä¸¤ä¸ªåŠŸèƒ½ï¼š

1. æ›´æ–° meesage hub

   ```python
   from mmengine.logging import MessageHub
   
   message_hub = MessageHub(name='name_for_message_hub')
   message_hub.update_scalar('train/loss', loss)
   # update with dict
   message_hub.update_scalrs(log_dict)
   ```

   `update_scalar` å¯ä»¥è‡ªåŠ¨å°†æ•°æ®è½¬æ¢æˆ python built-in ç±»å‹ã€‚è¦è·å–æ•°æ®å¯é€šè¿‡ä¸‹é¢æ–¹æ³•

   ```python
   buffer = message_hub.get_scalar('train/loss')	# è·å– buffer
   # buffer.data è¿”å›ä¸€ä¸ª tuple: (log_data, counts)
   # countsä»£è¡¨å¯¹åº”çš„æ•°æ®çš„é‡å¤æ¬¡æ•°
   # len(log_data) == len(counts)
   buffer.data[0]	# normally, an ndarray
   buffer.mean()
   buffer.max()
   buffer.min()
   buffer.current()
   ```

2. å‘æ–‡ä»¶å†™å…¥æ—¥å¿—

   ```python
   from mmengine.logging import MMLogger 
   
   logger = MMLogger.get_instance(name='mmengine', 
                                  log_level='INFO', log_file='tmp.log')
   logger.info(log_string)
   ```

**å…¨å±€æ€§è´¨çš„ç†è§£**

MMLogger å’Œ MessageHub éƒ½ç»§æ‰¿äº† ManagerMixinï¼Œè¿™ä¸ªç±»çš„ä¸»è¦åŠŸèƒ½å°±æ˜¯èƒ½å¤Ÿ**å…¨å±€è°ƒç”¨å®ä¾‹**ã€‚ä¸¾ä¸ªä¾‹å­ï¼Œå‡è®¾åœ¨æŸä¸ªåœ°æ–¹åˆ›å»ºäº†ä¸€ä¸ª MMLogger å®ä¾‹ï¼Œé‚£ä¹ˆé€šè¿‡ `ManagerMixin.get_instance()` èƒ½å¤Ÿåœ¨å…¶ä»–ä»»ä½•åœ°æ–¹éƒ½èƒ½å¤Ÿè·å–è¿™ä¸ª MMLogger å®ä¾‹ã€‚è¯¥åŠŸèƒ½çš„å®ç°éœ€è¦é€šè¿‡**å…ƒç±» meta class** å®Œæˆï¼Œæˆ‘ä¹Ÿä¸ç†è§£å…¶ä¸­ç»†èŠ‚ï¼Œæ¨¡ç³Šä¸€ç‚¹è¯´ï¼Œæˆ‘ä»¬æŠŠåˆ›å»ºçš„å®ä¾‹éƒ½ä¿å­˜åœ¨äº†å…ƒç±»çš„ä¸€ä¸ªå­—å…¸é‡Œé¢ï¼Œè€Œè¿™æ˜¯ä¸€ä¸ªå…¨å±€å¯è·å–çš„ç©ºé—´

### å¯è§†åŒ–ç³»ç»Ÿ Visualizer

mmengine çš„ visualizer æœ‰ä¸¤ä¸ªåŠŸèƒ½ï¼š

1. å¸¸è§„ç”»å›¾

   å¯è§†åŒ–å™¨æä¾›äº†å¸¸ç”¨å¯¹è±¡çš„ç»˜åˆ¶æ¥å£ï¼Œä¾‹å¦‚ç»˜åˆ¶**æ£€æµ‹æ¡†ã€ç‚¹ã€æ–‡æœ¬ã€çº¿ã€åœ†ã€å¤šè¾¹å½¢å’ŒäºŒå€¼æ©ç **ã€‚è¿™äº›åŸºç¡€ API æ”¯æŒä»¥ä¸‹ç‰¹æ€§ï¼š

   - å¯ä»¥å¤šæ¬¡è°ƒç”¨ï¼Œå®ç°å åŠ ç»˜åˆ¶éœ€æ±‚
   - å‡æ”¯æŒå¤šè¾“å…¥ï¼Œé™¤äº†è¦æ±‚æ–‡æœ¬è¾“å…¥çš„ç»˜åˆ¶æ¥å£å¤–ï¼Œå…¶ä½™æ¥å£åŒæ—¶æ”¯æŒ Tensor ä»¥åŠ Numpy array çš„è¾“å…¥

   ```python
   import mmcv
   from mmengine.visualization import Visualizer
   
   file = '/mmdetection/demo/demo.jpg'
   img = mmcv.imread(file, channel_order='rgb')
   vis = Visualizer(image=img)
   vis.show()
   
   visualizer.set_image(image=image)
   visualizer.draw_texts("cat and dog", torch.tensor([10, 20]))
   visualizer.draw_bboxes(torch.tensor([72, 13, 179, 147]), edge_colors='r', line_widths=3)
   ```

   ä¸ºäº†ä¸€äº› fancy çš„éœ€æ±‚è¿˜å¯ä»¥å°† [ç‰¹å¾å›¾å¯è§†åŒ–](https://mmengine.readthedocs.io/zh_CN/latest/advanced_tutorials/visualization.html#id3)

   ```python
   visualizer.draw_featmap(feat, channel_reduction='select_max')
   visualizer.draw_featmap(feat, image, channel_reduction='select_max')
   ```

   channel_reduction è¿˜æœ‰ squeeze_mean, None é€‰é¡¹ï¼Œä½¿ç”¨ None åˆ™éœ€è¦æ­é… topk å‚æ•°

2. æŠŠæ•°æ®å­˜å‚¨åˆ° backend ä¸­ï¼Œbackend ç›®å‰æœ‰ä¸‰ç§

   1. local backend
   2. tensorboard
   3. wandb

   ä½¿ç”¨æ—¶éœ€è¦åœ¨åˆå§‹åŒ–æ—¶æŒ‡å®š backend å’Œ save_dir å‚æ•°

   ```python
   visualizer = Visualizer(vis_backends=[dict(type='LocalVisBackend')], save_dir='temp_dir')
   ```

   å¯ä»¥å­˜å‚¨çš„æ•°æ®ç±»å‹æœ‰å¾ˆå¤š

   - add_config å†™é…ç½®åˆ°ç‰¹å®šå­˜å‚¨åç«¯ï¼Œconfig å¿…é¡»æ˜¯ Config ç±»
   - add_image å†™å›¾ç‰‡åˆ°ç‰¹å®šå­˜å‚¨åç«¯
   - add_scalar å†™æ ‡é‡åˆ°ç‰¹å®šå­˜å‚¨åç«¯
   - add_scalars ä¸€æ¬¡æ€§å†™å¤šä¸ªæ ‡é‡åˆ°ç‰¹å®šå­˜å‚¨åç«¯

### Metric & Evaluator

`Evaluator` æ˜¯ä¸€ä¸ª `Metric` å®¹å™¨ï¼ŒåŒ…å«å¤šä¸ª `Metric`ï¼Œå³å¯ä»¥è¿›è¡Œå¤šç§æŒ‡æ ‡çš„è¯„ä¼°ã€‚åŒæ—¶ `Evaluator` ä¹Ÿå¢åŠ äº†åˆ†å¸ƒå¼çš„åŠŸèƒ½ï¼Œèƒ½å¤Ÿå°†å¤šä¸ª GPU ä¸Šçš„æ¨ç†ç»“æœåˆå¹¶èµ·æ¥ï¼Œæœ€ç»ˆé€åˆ° CPU ä¸Šè¿›è¡Œè®¡ç®—

è‡ªå®šä¹‰çš„ `Metric` éœ€è¦å®ç°ä¸¤ä¸ªæ–¹æ³•

1. `process`ï¼Œè¿™ä¸ªæ–¹æ³•çš„åŠŸèƒ½å¾ˆç®€å•ï¼Œå°±æ˜¯å•çº¯çš„å­˜å‚¨é¢„æµ‹ç»“æœå’Œæ ‡ç­¾åˆ° `Metric` ä¸­çš„ `self.results` å½“ä¸­
2. `evaluate` è¿™ä¸ªæ–¹æ³•å°±æ˜¯å°† `self.results` ä¸­çš„ç»“æœè¿›è¡Œæ•´åˆè®¡ç®—ï¼Œæœ€ç»ˆè¾“å‡ºä¸€ä¸ªç»“æœ**å­—å…¸**

mmengine å®ç°äº†ä¸€ä¸ª `DumpResults` çš„ `Metric` ç±»ï¼Œå¦‚æœéœ€è¦å¯ä»¥å°†é¢„æµ‹çš„ç»“æœä¿å­˜ï¼Œåªéœ€è¦æŒ‡å®š `out_file_path` å³å¯

### BaseModel è®¾è®¡åŸåˆ™

ä¹‹å‰ä»‹ç»äº†æ¨¡å‹çš„ `train_step`ï¼Œå®é™…ä¸Š `BaseModel` æœ‰ä¸‰ä¸ªæ¥å£ï¼š

1. `train_step`
2. `val_step`
3. `test_step`

ä¸ç›´æ¥ä½¿ç”¨æ¨¡å‹çš„ `forward` æ–¹æ³•ï¼Œå› ä¸ºå„ä¸ª step ä¸­è¿˜åŒ…å«äº†å¯¹æ•°æ®çš„é¢„å¤„ç†ï¼Œä»¥åŠæ¨¡å‹å‚æ•°æ›´æ–°ã€‚æ‰€ä»¥æœ€å¥½æŠŠ `BaseModel` çœ‹ä½œå¯¹æ¨¡å‹çš„å°è£…ï¼Œè€Œä¸æ˜¯æ¨¡å‹æœ¬èº«ï¼

mmengine è¦æ±‚æ¨¡å‹çš„ `forward` æ–¹æ³•æ¥å—çš„å‚æ•°å³ä¸º `DataLoader` çš„è¾“å‡º `data_batch`ã€‚å¦‚æœ `DataLoader` è¿”å›å…ƒç»„ç±»å‹çš„æ•°æ® `data`ï¼Œ`forward` éœ€è¦èƒ½å¤Ÿæ¥å— `*data` çš„è§£åŒ…åçš„å‚æ•°ï¼›å¦‚æœè¿”å›å­—å…¸ç±»å‹çš„æ•°æ® `data`ï¼Œ`forward` éœ€è¦èƒ½å¤Ÿæ¥å— `**data` è§£åŒ…åçš„å‚æ•°ã€‚ `mode` å‚æ•°ç”¨äºæ§åˆ¶ `forward` çš„è¿”å›ç»“æœï¼Œé€šå¸¸ä¼šå†ä½¿ç”¨ä¸€ä¸ªçˆ¶ç±»æ¥å°è£…ä¸€å±‚

```python
    def forward(self,
                inputs: torch.Tensor,
                data_samples: OptSampleList = None,
                mode: str = 'tensor') -> ForwardResults:
        if mode == 'loss':
            return self.loss(inputs, data_samples)
        elif mode == 'predict':
            return self.predict(inputs, data_samples)
        elif mode == 'tensor':
            return self._forward(inputs, data_samples)
        else:
            raise RuntimeError(f'Invalid mode "{mode}". '
                               'Only supports loss, predict and tensor mode')
```

## TODO

ä¾¿æ·çš„åˆ†å¸ƒå¼æ¥å£

coco api & coco metric

einops for projectsï¼Œæˆ‘æŠŠ subway é¡¹ç›®çš„ä¸€äº›æ€»ç»“ä¹Ÿæ”¾åˆ°é‡Œé¢æ¥ï¼Œå› ä¸ºè¿™æ˜¯ä¸€ä¸ªå®Œæ•´çš„é¡¹ç›®

position embeddings

å¢åŠ ä¸€ä¸ªè®°å½• model ç»“æ„çš„ log